{
  "title": "Model Optimisation and Performance",
  "content": "- ### OntologyBlock\n  id:: model-optimisation-and-performance-ontology\n  collapsed:: true\n\t- ontology:: true\n\t- term-id:: mv-379008878873\n\t- preferred-term:: Model Optimisation and Performance\n\t- source-domain:: metaverse\n\t- status:: active\n\t- public-access:: true\n\t- definition:: A component of the metaverse ecosystem focusing on model optimisation and performance.\n\t- maturity:: mature\n\t- authority-score:: 0.85\n\t- owl:class:: mv:ModelOptimisationAndPerformance\n\t- owl:physicality:: ConceptualEntity\n\t- owl:role:: Concept\n\t- belongsToDomain:: [[MetaverseDomain]]\n\t- #### Relationships\n\t  id:: model-optimisation-and-performance-relationships\n\t\t- enables:: [[ImmersiveExperience]], [[Presence]], [[SpatialComputing]]\n\t\t- requires:: [[DisplayTechnology]], [[TrackingSystem]], [[RenderingEngine]]\n\t\t- bridges-to:: [[HumanComputerInteraction]], [[ComputerVision]], [[Robotics]]\n\n\t- #### OWL Axioms\n\t  id:: model-optimisation-and-performance-owl-axioms\n\t  collapsed:: true\n\t\t- ```clojure\n\t\t  Declaration(Class(mv:ModelOptimisationAndPerformance))\n\n\t\t  # Classification\n\t\t  SubClassOf(mv:ModelOptimisationAndPerformance mv:ConceptualEntity)\n\t\t  SubClassOf(mv:ModelOptimisationAndPerformance mv:Concept)\n\n\t\t  # Domain classification\n\t\t  SubClassOf(mv:ModelOptimisationAndPerformance\n\t\t    ObjectSomeValuesFrom(mv:belongsToDomain mv:MetaverseDomain)\n\t\t  )\n\n\t\t  # Annotations\n\t\t  AnnotationAssertion(rdfs:label mv:ModelOptimisationAndPerformance \"Model Optimisation and Performance\"@en)\n\t\t  AnnotationAssertion(rdfs:comment mv:ModelOptimisationAndPerformance \"A component of the metaverse ecosystem focusing on model optimisation and performance.\"@en)\n\t\t  AnnotationAssertion(dcterms:identifier mv:ModelOptimisationAndPerformance \"mv-379008878873\"^^xsd:string)\n\t\t  ```\n\npublic:: true\n\n- #Public page\n\t - automatically published\n- ## Quantization in Machine Learning Models\n\t- ![image.png](../assets/image_1707150720702_0.png)\n\t-\n\t- ### Introduction\n\t\t- Quantization refers to the process of reducing the precision of the numbers that represent the weights and activations of a machine learning model without significantly reducing its accuracy.\n\t\t- It is a critical technique for deploying models on resource-constrained devices like mobile phones, embedded systems, and IoT devices.\n\t\t- [Quantization (huggingface.co)](https://huggingface.co/docs/transformers/main/quantization)\n\t- ### Benefits of Quantization\n\t\t- **Memory Efficiency**: Reduces the model size, enabling it to fit in the limited memory of small devices.\n\t\t- **Computational Efficiency**: Lower precision operations are faster and consume less power.\n\t\t- **Bandwidth Reduction**: Smaller models require less data to be transferred when downloaded or updated.\n\t- ### Strategies for Quantization\n\t\t- #### Sparsification\n\t - **Description**: Involves reducing the number of non-zero elements in the model's weights, effectively compressing the model.\n\t - **Techniques**:\n\t\t\t\t- Weight Pruning: Removing weights that have little impact on the output.\n\t\t\t\t- Structured Pruning: Removing entire channels or filters that are not contributing significantly to the model's performance.\n\t - **References**:\n\t\t\t\t- [The Lottery Ticket Hypothesis](https://arxiv.org/abs/1803.03635)\n\t\t- #### Removal of Least Significant Bits (LSB)\n\t - **Description**: This strategy involves truncating the least significant bits from the weights' binary representation.\n\t - **Approach**:\n\t\t\t\t- Fixed-Point Quantization: Converts floating-point numbers to fixed-point format, removing the least significant bits.\n\t\t\t\t- Dynamic Quantization: Adjusts the quantization parameters dynamically based on the distribution of the parameters.\n\t - **Benefits**:\n\t\t\t\t- Reduces the precision of weights with minimal impact on accuracy.\n\t\t\t\t- Simplifies the hardware implementation of mathematical operations.\n\t - **References**:\n\t\t\t\t- [Post-Training Quantization](https://www.tensorflow.org/lite/performance/post_training_quantization)\n\t\t- #### Uniform and Non-Uniform Quantization\n\t - **Uniform Quantization**:\n\t\t\t\t- Applies the same quantization step size across all values.\n\t\t\t\t- Easier to implement but might not be optimal for all distributions of model parameters.\n\t - **Non-Uniform Quantization**:\n\t\t\t\t- Adapts the quantization step size according to the distribution of the parameters.\n\t\t\t\t- Can achieve better accuracy for the same level of compression.\n\t - **References**:\n\t\t\t\t- [Mixed Precision Training](https://arxiv.org/abs/1710.03740)\n\t- ### Tools and Frameworks for Quantization\n\t\t- **TensorFlow Lite**: Provides tools for post-training quantization and quantization-aware training.\n\t - [TensorFlow Lite Guide](https://www.tensorflow.org/lite)\n\t\t- **PyTorch Quantization**: Supports dynamic quantization, static quantization, and quantization-aware training.\n\t - [PyTorch Quantization](https://pytorch.org/docs/stable/quantization.html)\n\t\t- **ONNX Runtime**: Offers support for quantized models, enabling optimized inference on different hardware.\n\t - [ONNX Runtime Quantization](https://onnxruntime.ai/docs/performance/quantization.html)\n\t- ### Challenges and Considerations\n\t\t- **Accuracy Trade-offs**: Finding the right balance between model size reduction and accuracy preservation.\n\t\t- **Hardware Compatibility**: Ensuring quantized models are compatible with the target hardware's instruction set.\n\t\t- **Quantization Granularity**: Deciding between per-layer, per-channel, or per-tensor quantization for optimal performance.\n\t- **Quantized Neural Networks (QNNs)**\n\t- **Goal:**Â Reduce model size without sacrificing accuracy.\n\t- **Concept:**Â Lower precision representation of weights and activations (e.g.,Â from 32-bit floats to 8-bit integers).\n\t- ### Key Techniques\n\t- #### [Overview of GGUF quantization methods : LocalLLaMA (reddit.com)](https://www.reddit.com/r/LocalLLaMA/comments/1ba55rj/overview_of_gguf_quantization_methods/)\n\t- **Quantization:**\n\t\t- Rounding of weights and activations to lower precision representation.\n\t\t- **Example:**\n\t\t  \n\t\t  ```\n\t\t  Quantized Weight = Round(Original Weight / Scale)\n\t\t  ```\n\t- **Binary Quantization:**\n\t\t- Extremely aggressive quantization to binary values (1 or -1).\n\t\t- **Example:**\n\t\t  \n\t\t  ```\n\t\t  Binary Weight = Sign(Original Weight)\n\t\t  ```\n\t- **Ternary Quantization:**\n\t\t- Weights quantized to -1,Â 0,Â or 1.\n\t\t- Offers better information retention than binary quantization.\n\t- **Quantization-Aware Training (QAT):**\n\t\t- Integrate quantization effects into the training process for smoother transitions and less accuracy loss.\n\t\t  \n\t\t  **Quantization Schemes**\n\t- **Fixed-Point:**Â Quantization into fixed bit-width representations.\n\t- **Logarithmic:**Â Leverages logarithmic scale for wider dynamic range.\n\t- **Quantized Inference**\n\t- Running inference using the quantized model.\n\t- Often requires integer math operations,Â leading to computational efficiency gains.\n\t- **Dequantization:**Â Process of converting quantized output back to a familiar floating-point representation.\n\t-\n\t- ### Benefits of QNNs\n\t\t- **Smaller model sizes:**Â Ideal for memory-constrained devices.\n\t\t- **Faster inference:**Â Lower precision often leads to faster computations.\n\t\t- **Reduced power consumption:**Â Benefits embedded systems and mobile devices.\n\t\t- Mobile and edge devices\n\t\t- Real-time applications\n\t\t- Resource-constrained environments\n- ## Hyperparameter Tuning ([LinkedIn Thread](https://www.linkedin.com/posts/maryammiradi_machinelearning-ai-datascience-activity-7179427786799861760-WFtN/))\n\t- ğ‡ğ²ğ©ğğ«ğ©ğšğ«ğšğ¦ğğ­ğğ« ğğ©ğ­ğ¢ğ¦ğ¢ğ³ğšğ­ğ¢ğ¨ğ§: ğŸğŸ ğ“ğ¨ğ© ğğ²ğ­ğ¡ğ¨ğ§ ğ‹ğ¢ğ›ğ«ğšğ«ğ¢ğğ¬ ğŸğ¨ğ« ğ’ğğœğ«ğğ­ ğˆğ§ğ ğ«ğğğ¢ğğ§ğ­ ğ¢ğ§ ğŒğšğœğ¡ğ¢ğ§ğ ğ‹ğğšğ«ğ§ğ¢ğ§ğ  ğ’ğ®ğœğœğğ¬ğ¬\n\t- Hyperparameter optimization plays a crucial role in determining the performance of a machine learning model. They are one the 3 components of training.\n\t- ğŸ› â„‚ğ• ğ•ğ•¡ğ• ğ•Ÿğ•–ğ•Ÿğ•¥ğ•¤ ğ• ğ•— ğ•„ğ• ğ••ğ•–ğ•:\n\t- 1ï¸âƒ£ Training data: Training data is what the algorithm leverages (think: instructions to build a model) to identify patterns\n\t- 2ï¸âƒ£ Parameters: Algorithm 'learns' by adjusting parameters, such as weights, based on training data to make accurate predictions, which are saved as part of the final model.\n\t- 3ï¸âƒ£ Hyperparameters: Hyperparameters are variables that regulate the process of training and are constant during the training process.\n\t- ğ”»ğ•šğ•—ğ•—ğ•–ğ•£ğ•–ğ•Ÿğ•¥ ğ•‹ğ•ªğ•¡ğ•–ğ•¤ ğ• ğ•— ğ•Šğ•–ğ•’ğ•£ğ•”ğ•™:\n\t- ğŸ”Grid Search : Training models with every possible combination of the provided hyperparameter values a time-consuming process.\n\t- ğŸ”Random Search: Training models with randomly samples hyperparameter values from the defined distributions, a more effective search.\n\t- ğŸ” Having Grid Search: Training models with all values, and then repeatedly \"halving\" the search space by only considering the parameter values that performed the best in the previous round.\n\t- ğŸ” Bayesian Search: Starting with an initial guess of values, using performance of the model to the values. It's like how a detective might start with a list of suspects, then use new information to narrow down the list.\n\t- I found these ğŸğŸ ğ©ğ²ğ­ğ¡ğ¨ğ§ ğ¥ğ¢ğ›ğ«ğšğ«ğ¢ğğ¬ ğŸğ¨ğ« ğ‡ğ²ğ©ğğ«ğ©ğšğ«ğšğ¦ğğ­ğğ« ğğ©ğ­ğ¢ğ¦ğ¢ğ³ğšğ­ğ¢ğ¨ğ§:\n\t- ğŸ“š Optuna\n\t- You can tune estimators of almost any ML, DL package/framework, including Sklearn, PyTorch, TensorFlow, Keras, XGBoost, LightGBM, CatBoost, etc with a real-time Web Dashboard called optuna-dashboard.\n\t- ğŸ“šHyperopt\n\t- Optimizing using Bayesian optimization, including conditional dimensions.\n\t- ğŸ“š Scikit-learn\n\t- different searches such as GridSearchCV or HalvingGridSearchCV.\n\t- ğŸ“š Auto-Sklearn\n\t- AutoML and a drop-in replacement for a scikit-learn estimator.\n\t- ğŸ“š Hyperactive\n\t- Very easy to learn but extremly versatile providing intelligent optimization.\n\t- ğŸ“š Optunity\n\t- Provides distinct approaches such plethora of score functions.\n\t- ğŸ“š HyperparameterHunter\n\t- Automatic save/learn from Experiments for persistent optimization\n\t- ğŸ“š MLJAR\n\t- AutoML creating Markdown reports from ML pipeline\n\t- ğŸ“š KerasTuner\n\t- with Bayesian Optimization, Hyperband, and Random Search algorithms built-in\n\t- ğŸ“š Talos\n\t- Hyperparameter Optimization for TensorFlow, Keras and PyTorch\n\t- Extra:\n\t- ğŸ“š Sweeps\n\t- ğŸ“š Scikit-optimize\n\t- ğŸ“š PyCaret\n\t- ![No alternative text description for this image](https://media.licdn.com/dms/image/D4E22AQHw_nWSZpbsyQ/feedshare-shrink_800/0/1711708970372?e=1714608000&v=beta&t=ZQCj26yY9vyZLbOegFQ97DYGWAmZno_65zrwVm31X5g)\n\t-\n- [The Truth is in There: Improving Reasoning in Language Models with Layer-Selective Rank Reduction\n\t - Microsoft Research](https://www.microsoft.com/en-us/research/publication/the-truth-is-in-there-improving-reasoning-in-language-models-with-layer-selective-rank-reduction/)\n\t- [pratyushasharma/laser: The Truth Is In There: Improving Reasoning in Language Models with Layer-Selective Rank Reduction (github.com)](https://github.com/pratyushasharma/laser)\n- [huggingface/optimum-nvidia (github.com)](https://github.com/huggingface/optimum-nvidia)\n- [[width=0.06]./figs/logo EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty (arxiv.org)](https://arxiv.org/pdf/2401.15077.pdf)\n- [run-ai/llmperf (github.com)](https://github.com/run-ai/llmperf) Tensor vs serving frameworks\n- [[Bitnet and the rise of the 1bit model]]\n\t- [The Dawn of 1-Bit Large Language Models (substack.com)](https://emsime.substack.com/p/the-dawn-of-1-bit-large-language)\n\t- [[2402.17764] The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits (arxiv.org)](https://arxiv.org/abs/2402.17764)\n\t- [Advancing AI for humanity | Foundation of AI (thegenerality.com)](https://thegenerality.com/agi/)\n\t-\n\n## Current Landscape (2025)\n\n- Industry adoption and implementations\n  - Metaverse platforms continue to evolve with focus on interoperability and open standards\n  - Web3 integration accelerating with decentralised identity and asset ownership\n  - Enterprise adoption growing in virtual collaboration, training, and digital twins\n  - UK companies increasingly active in metaverse development and immersive technologies\n\n- Technical capabilities\n  - Real-time rendering at photorealistic quality levels\n  - Low-latency networking enabling seamless multi-user experiences\n  - AI-driven content generation and procedural world building\n  - Spatial audio and haptics enhancing immersion\n\n- UK and North England context\n  - Manchester: Digital Innovation Factory supports metaverse startups and research\n  - Leeds: Holovis leads in immersive experiences for entertainment and training\n  - Newcastle: University research in spatial computing and interactive systems\n  - Sheffield: Advanced manufacturing using digital twin technology\n\n- Standards and frameworks\n  - Metaverse Standards Forum driving interoperability protocols\n  - WebXR enabling browser-based immersive experiences\n  - glTF and USD for 3D asset interchange\n  - Open Metaverse Interoperability Group defining cross-platform standards\n\n## Metadata\n\n- **Last Updated**: 2025-11-16\n- **Review Status**: Automated remediation with 2025 context\n- **Verification**: Academic sources verified\n- **Regional Context**: UK/North England where applicable",
  "properties": {
    "id": "model-optimisation-and-performance-owl-axioms",
    "collapsed": "true",
    "- ontology": "true",
    "- term-id": "mv-379008878873",
    "- preferred-term": "Model Optimisation and Performance",
    "- source-domain": "metaverse",
    "- status": "active",
    "- public-access": "true",
    "- definition": "A component of the metaverse ecosystem focusing on model optimisation and performance.",
    "- maturity": "mature",
    "- authority-score": "0.85",
    "- owl:class": "mv:ModelOptimisationAndPerformance",
    "- owl:physicality": "ConceptualEntity",
    "- owl:role": "Concept",
    "- belongsToDomain": "[[MetaverseDomain]]",
    "- enables": "[[ImmersiveExperience]], [[Presence]], [[SpatialComputing]]",
    "- requires": "[[DisplayTechnology]], [[TrackingSystem]], [[RenderingEngine]]",
    "- bridges-to": "[[HumanComputerInteraction]], [[ComputerVision]], [[Robotics]]",
    "public": "true"
  },
  "backlinks": [
    "Prompt Engineering",
    "Flux"
  ],
  "wiki_links": [
    "TrackingSystem",
    "ImmersiveExperience",
    "ComputerVision",
    "RenderingEngine",
    "SpatialComputing",
    "Robotics",
    "HumanComputerInteraction",
    "Bitnet and the rise of the 1bit model",
    "MetaverseDomain",
    "DisplayTechnology",
    "Presence"
  ],
  "ontology": {
    "term_id": "mv-379008878873",
    "preferred_term": "Model Optimisation and Performance",
    "definition": "A component of the metaverse ecosystem focusing on model optimisation and performance.",
    "source_domain": "metaverse",
    "maturity_level": null,
    "authority_score": 0.85
  }
}