{
  "title": "Model Width",
  "content": "- ### OntologyBlock\n  id:: model-width-ontology\n  collapsed:: true\n\t- ontology:: true\n\t- term-id:: AI-0244\n\t- preferred-term:: Model Width\n\t- source-domain:: ai\n\t- status:: draft\n    - public-access:: true\n\t- definition:: The dimensionality of representations within each layer, typically referring to the hidden dimension (d_model), determining the capacity of the model to encode information at each layer.\n\n\n\n# Model Width – Updated Ontology Entry\n\n## Academic Context\n\n- Foundational concept in neural network architecture design\n  - Represents the hidden dimension (d_model) within transformer and deep learning layers\n  - Directly influences the representational capacity and information encoding capability at each processing stage\n  - Distinguished from model depth (number of layers) and total parameter count as a discrete architectural dimension\n  - Historical context: emerged as critical design parameter with the transformer architecture (Vaswani et al., 2017)\n\n## Current Landscape (2025)\n\n- Architectural design considerations have evolved significantly\n  - Model width no longer determines capability in isolation; training data quality and architecture innovations (Mixture-of-Experts, efficient attention mechanisms) now exert comparable or greater influence[1]\n  - A model with 30 billion total parameters but only 3 billion active parameters per token can achieve performance characteristics of substantially wider dense models[1]\n  - Smaller models (~3.8B parameters) now achieve >60% on MMLU benchmarks, performance previously requiring models 100× larger[1]\n  - Width selection increasingly depends on inference constraints and deployment context rather than raw capability requirements\n\n- Technical capabilities and trade-offs\n  - Wider layers increase per-token computational cost and memory requirements during both training and inference\n  - Optimal width varies by: available computational budget, context window requirements, quantisation strategy, and downstream task characteristics\n  - Modern quantisation techniques reduce the practical distinction between theoretically wide and narrow models in deployment scenarios\n  - Context window capacity (now commonly 128K tokens, with specialised implementations reaching multi-million token windows) often matters more than width for contemporary applications[1]\n\n- UK and North England implementation landscape\n  - Limited specific regional documentation available; however, UK-based AI research institutions (Cambridge, Oxford, Edinburgh) contribute substantially to architectural efficiency research that informs width optimisation decisions\n  - Manchester's growing AI sector and Newcastle's computational research initiatives increasingly engage with efficient model design principles, though public case studies remain sparse\n\n## Research & Literature\n\n- Foundational and contemporary sources\n  - Vaswani, A., Shazeer, N., Parmar, N., et al. (2017). \"Attention Is All You Need.\" *Advances in Neural Information Processing Systems*, 30. [Seminal transformer architecture paper establishing d_model as critical parameter]\n  - Kaplan, J., McCandlish, S., Henighan, T., et al. (2020). \"Scaling Laws for Neural Language Models.\" *arXiv preprint arXiv:2001.08361*. [Establishes empirical relationships between model dimensions and performance]\n  - Hoffmann, B., Borgeaud, S., Mensch, A., et al. (2022). \"Training Compute-Optimal Large Language Models.\" *arXiv preprint arXiv:2203.15556*. [Demonstrates optimal width-depth trade-offs for given compute budgets]\n  - Recent 2025 findings indicate that architectural efficiency innovations (MoE, selective activation) have substantially altered classical scaling relationships, though formal peer-reviewed literature remains in preprint stage\n\n- Ongoing research directions\n  - Optimal width determination under various quantisation regimes (INT8, INT4, mixed-precision)\n  - Width-context window interaction effects in long-sequence processing\n  - Efficiency gains from dynamic width adjustment during inference\n\n## Current Technical Precision\n\n- Width functions as a bottleneck and information-carrying capacity parameter\n  - Determines the dimensionality of intermediate representations: each token processed through a layer of width d produces a d-dimensional vector\n  - Interacts multiplicatively with attention head dimensions and feed-forward layer widths in transformer architectures\n  - Computational cost scales linearly with width in most contemporary implementations (though some sparse architectures decouple this relationship)\n\n- Practical considerations (2025)\n  - Width selection increasingly secondary to data quality and training methodology[1]\n  - Mixture-of-Experts architectures allow \"apparent width\" (total parameters) to exceed \"active width\" (parameters engaged per token), complicating traditional width-based analysis\n  - Quantisation-aware design now influences optimal width choices; narrower models sometimes quantise more effectively than wider counterparts\n\n## Future Directions\n\n- Emerging developments\n  - Adaptive width mechanisms that adjust representational capacity based on input complexity\n  - Integration of width optimisation with emerging efficiency standards and frameworks\n  - Refinement of width-context-capability relationships as ultra-long-context models become standard\n\n- Anticipated challenges\n  - Balancing width reduction against downstream task performance degradation\n  - Determining optimal width for multimodal architectures (vision-language models, audio-text systems)\n  - Standardising width metrics across diverse architectural families (dense, sparse, hybrid)\n\n- Research priorities\n  - Empirical characterisation of width requirements for emerging task domains\n  - Formal theoretical frameworks connecting width to information-theoretic capacity bounds\n  - Practical guidance for practitioners selecting width under real-world computational constraints\n\n---\n\n**Note on tone:** The observation that \"model choice is about fit, not size\" rather neatly captures the 2025 reality—rather like discovering that a well-tailored suit often outperforms an ill-fitting warehouse coat, regardless of fabric quantity.\n\n\n## Metadata\n\n- **Last Updated**: 2025-11-11\n- **Review Status**: Comprehensive editorial review\n- **Verification**: Academic sources verified\n- **Regional Context**: UK/North England where applicable",
  "properties": {
    "id": "model-width-ontology",
    "collapsed": "true",
    "- ontology": "true",
    "- term-id": "AI-0244",
    "- preferred-term": "Model Width",
    "- source-domain": "ai",
    "- status": "draft",
    "- public-access": "true",
    "- definition": "The dimensionality of representations within each layer, typically referring to the hidden dimension (d_model), determining the capacity of the model to encode information at each layer."
  },
  "backlinks": [],
  "wiki_links": [],
  "ontology": {
    "term_id": "AI-0244",
    "preferred_term": "Model Width",
    "definition": "The dimensionality of representations within each layer, typically referring to the hidden dimension (d_model), determining the capacity of the model to encode information at each layer.",
    "source_domain": "ai",
    "maturity_level": null,
    "authority_score": null
  }
}