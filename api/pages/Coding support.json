{
  "title": "Coding support",
  "content": "- ### OntologyBlock\n  id:: coding-support-ontology\n  collapsed:: true\n\t- ontology:: true\n\t- term-id:: mv-411006412271\n\t- preferred-term:: Coding support\n\t- source-domain:: metaverse\n\t- status:: active\n\t- public-access:: true\n\t- definition:: A component of the metaverse ecosystem focusing on coding support.\n\t- maturity:: mature\n\t- authority-score:: 0.85\n\t- owl:class:: mv:CodingSupport\n\t- owl:physicality:: ConceptualEntity\n\t- owl:role:: Concept\n\t- belongsToDomain:: [[MetaverseDomain]]\n\t- #### Relationships\n\t  id:: coding-support-relationships\n\t\t- enables:: [[ImmersiveExperience]], [[Presence]], [[SpatialComputing]]\n\t\t- requires:: [[DisplayTechnology]], [[TrackingSystem]], [[RenderingEngine]]\n\t\t- bridges-to:: [[HumanComputerInteraction]], [[ComputerVision]], [[Robotics]]\n\n\t- #### OWL Axioms\n\t  id:: coding-support-owl-axioms\n\t  collapsed:: true\n\t\t- ```clojure\n\t\t  Declaration(Class(mv:CodingSupport))\n\n\t\t  # Classification\n\t\t  SubClassOf(mv:CodingSupport mv:ConceptualEntity)\n\t\t  SubClassOf(mv:CodingSupport mv:Concept)\n\n\t\t  # Domain classification\n\t\t  SubClassOf(mv:CodingSupport\n\t\t    ObjectSomeValuesFrom(mv:belongsToDomain mv:MetaverseDomain)\n\t\t  )\n\n\t\t  # Annotations\n\t\t  AnnotationAssertion(rdfs:label mv:CodingSupport \"Coding support\"@en)\n\t\t  AnnotationAssertion(rdfs:comment mv:CodingSupport \"A component of the metaverse ecosystem focusing on coding support.\"@en)\n\t\t  AnnotationAssertion(dcterms:identifier mv:CodingSupport \"mv-411006412271\"^^xsd:string)\n\t\t  ```\n\npublic:: true\n\n\t- {{video https://www.youtube.com/watch?v=yj73GIEKmLI}}\n- # Believably wrong answers\n\t- **[Study Details](https://dl.acm.org/doi/pdf/10.1145/3613904.3642596)**  by Purdue University. Presented at the Computer-Human Interaction Conference in Hawaii. (CHI)\n\t- **517 programming questions** from Stack Overflow.\n\t\t- **52%** contained incorrect information.\n\t\t- **77%** were verbose.\n\t\t- **78%** showed inconsistency compared to human answers.\n\t- **User Perception**\n\t  id:: 66e9741c-907c-440c-867c-5a76228a8216\n\t\t- Participants preferred ChatGPT answers **35%** of the time despite inaccuracies.\n\t\t- Misleading AI responses were not detected by programmers **39%** of the time.\n\t\t- ChatGPT's answers were more formal, analytical, and positive in tone.\n\t\t- Politeness and comprehensiveness made ChatGPT answers appear more convincing.\n- # Specialised Models\n\t- ![image.png](../assets/image_1717159684964_0.png)\n- # Products\n\t- ## Devin\n\t\t- {{video https://www.youtube.com/watch?v=fjHtjT7GO1c&}}\n\t\t- [Blog (cognition-labs.com)](https://www.cognition-labs.com/blog)\n\t- ## Cody\n\t\t- The AI Coding Assistant\n\t\t\t- **Introduction to Cody**\n\t\t\t\t- Developed by Sourcegraph, co-founded by Beang Liu, CTO.\n\t\t\t\t- Aims to revolutionize software development with AI.\n\t\t\t\t- Integrates into various editors, enhancing developer productivity.\n\t\t\t- **Foundation and Purpose**\n\t\t\t\t- Rooted in Beang's early interest in AI and machine learning at Stanford AI lab.\n\t\t\t\t- Addresses the gap between the potential of programming and the drudgery of day-to-day software engineering tasks.\n\t\t\t\t- Focuses on reducing time spent on reading and understanding existing code.\n\t\t\t- **Defining Spatial Computing**\n\t\t\t\t- Initially focused on advanced search capabilities in real coding environments.\n\t\t\t\t- Aimed at achieving 'flow' in programming through efficient information retrieval.\n\t\t\t- **Integration of AI in Sourcegraph and Cody**\n\t\t\t\t- Shift towards AI-enhanced coding tools around 2017-2018.\n\t\t\t\t- Early experiments with applying large language models (LLMs) to code search.\n\t\t\t\t- Development driven by advancements in AI, especially in neural networks and LLMs.\n\t\t\t- **Capabilities of Cody**\n\t\t\t\t- Provides AI-driven coding assistance in various IDEs.\n\t\t\t\t- Features include inline completions, high-level Q&A, and specific coding commands.\n\t\t\t\t- Unique in augmenting large language models with contextual information from Sourcegraph.\n\t\t\t- **Future Aspirations for Cody**\n\t\t\t\t- Aims to automate more complex software development tasks.\n\t\t\t\t- Foresees the potential for AI to generate pull requests and change sets from issue descriptions.\n\t\t\t\t- Emphasizes the importance of context quality in improving code generation.\n\t\t\t- **Technical Challenges and Innovations**\n\t\t\t\t- Balances traditional information retrieval with AI-driven approaches.\n\t\t\t\t- Focuses on optimizing search architecture and context retrieval for better code generation.\n\t\t\t\t- Explores the use of small models for faster and more cost-effective solutions.\n\t\t\t- **The Evolution of Software Development with AI**\n\t\t\t\t- Envisions a future where individual developers are more productive and cohesive.\n\t\t\t\t- Anticipates changes in the software development lifecycle due to AI integration.\n\t\t\t\t- Stresses the growing importance of CS fundamentals and domain expertise in an AI-augmented future.\n- # Advice on AI coding\n- **Choose Tools Strategically:** Not all AI coding tools are created equal. Select the right tool for the job, considering the project's scope and complexity:\n\t- **Complex Applications:** Cursor, Windsurf, or more established IDE integrations (see below) are often better suited for larger, more intricate projects.\n\t- **Micro-SaaS:** Bolt/Lovable are optimised for smaller, Software-as-a-Service applications.\n\t- **Mobile Applications:** Replit remains a good choice, alongside framework-specific tools.\n\t- **UI Design:** Consider using 'vo' or similar specialised tools for user interface design.\n\t- **General Coding Assistance & IDE Integration:**\n\t\t- **GitHub Copilot:** A widely used and powerful AI pair programmer that integrates directly into your IDE (VS Code, JetBrains IDEs, etc.).\n\t\t- **GitHub Copilot Agents:** Extend Copilot's capabilities with specialised agents for tasks like code review, debugging, and test generation.\n\t\t- **Aider:** A command-line tool that helps you write and edit code using GPT models. Good for making changes to existing codebases, particularly for refactoring and adding features.\n\t\t- **Roo**: Provides code generation and chat capabilities within your IDE.\n\t\t- **Cline:** Good for command line interfacing, and code assistance.\n- **Context is Paramount:** Always provide comprehensive context about your project. AI tools cannot \"guess\" your intentions. Use Markdown (.md) documents to detail:\n\t- **Product Requirements Document (PRD):** Clearly outlines the purpose, features, and functionality of the application.\n\t- **Technical Stack Document:** Specifies the programming languages, frameworks, libraries, and databases to be used.\n\t- **File Structure:** Defines the organisation of directories and files within the project.\n\t- **Frontend Guidelines:** Describes coding standards, styling conventions, and component structure for the user interface.\n\t- **Backend Structure:** Outlines the architecture, API endpoints, data models, and business logic for the server-side code.\n\t- **Use CodeGuide (or Similar):** Consider using CodeGuide or a similar tool to help generate and manage these AI-specific coding documents. This ensures compatibility across various AI tools and helps maintain a single source of truth.\n- **Incremental Development:** Avoid overly broad prompts like \"build me an AirBNB clone.\" Instead, break down the project into manageable steps:\n\t- **Page by Page:** Develop the application one page at a time.\n\t- **Component by Component:** Within each page, build individual components sequentially.\n\t- **Limited Task Execution:** AI models typically perform best with a maximum of 3 concurrent tasks *per request*. Be mindful of this limitation, and break down larger tasks accordingly. Tools like Aider and Copilot Agents can help manage this complexity.\n- **Select AI-Friendly Technologies:** Certain technology stacks are better understood by current AI models:\n\t- **Web Applications:**\n\t\t- **React (with NextJS or ViteJS):** Provides excellent performance and is well-supported by AI tools.\n\t\t- **Python (with frameworks like Django or Flask):** Widely used and well-understood by AI models.\n\t- **Mobile Applications:**\n\t\t- **React Native:** A good choice for cross-platform development.\n\t\t- **SwiftUI (especially with Claude):** Works well, particularly with Claude models.\n\t- **Avoid Older Technologies**: Unless absolutely necessary, as AI model support may be limited.\n- **Utilise Starter Kits:** Save time and reduce token usage by starting with pre-built templates or boilerplates:\n\t- **Example:** The \"CodeGuide NextJS Starter Kit\" can provide a solid foundation.\n\t- **Benefit:** Accelerates workflow and provides a structured starting point. Most frameworks have readily available starter kits.\n- **Define Rules Within Your Tools:** Many AI coding tools allow project-specific rules:\n\t- **Examples:** .cursorrules (often \"project rules\"), .windsurfrules, or similar configuration files within your IDE or tool. Copilot and other IDE-integrated tools often have settings for coding style and preferences.\n\t- **Purpose:** Constrain the AI, preventing deviations from your guidelines and coding standards.\n\t- **Coding Standards**: Enforce coding standards using linters (e.g., ESLint for JavaScript, Pylint for Python) and integrate their configuration with your AI tools where possible.\n- **Employ a Multi-Tool Approach:** No single tool handles the entire workflow seamlessly. Combine tools:\n\t- **Research:** Perplexity.\n\t- **Brainstorming:** ChatGPT (voice features can be helpful).\n\t- **Documentation:** CodeGuide, or tools integrated within your IDE.\n\t- **Data Scraping:** Firecrawl, or libraries within your chosen language (e.g., Beautiful Soup in Python).\n\t- **Code Generation/Assembly/Refactoring:** Your chosen AI coding tool (Cursor, Windsurf, GitHub Copilot, Aider, Roo, Cline, etc.). Choose based on your workflow and project needs.\n- **Patience and Persistence:** Working with AI requires a specific mindset.\n\t- **Prompt Engineering:** Crafting effective prompts is crucial. Experiment with different phrasing and levels of detail.\n\t- **Expect Errors:** AI models are not perfect. Be prepared for errors.\n\t- **Iterative Refinement:** Stay focused, learn from mistakes, and iteratively refine your prompts and approach.\n\t- **Debugging**: Provide the AI with the full code and error message for assistance. Leverage Copilot Agents for debugging tasks.\n- **Version Control**\n\t- Use Git for version control.\n\t- Commit frequently with clear messages.\n\t- AI can help generate commit messages (Copilot, Aider, and others offer this).\n- **Testing**\n\t- Write unit and integration tests.\n\t- AI can assist in generating test cases (Copilot Agents are particularly useful here). Tools like Aider can help refactor code to improve testability.\n\t- [[Agent Frameworks]]\n\t-\n-\n- # other links\n-\n- Setup Continue for VSCode\n\t- [How to use a local LLM as a free coding copilot in VS Code | by Simon Fraser | Dec, 2023 | Medium](https://medium.com/@smfraser/how-to-use-a-local-llm-as-a-free-coding-copilot-in-vs-code-6dffc053369d)\n\t- [LoneStriker/code-millenials-34b-6.0bpw-h6-exl2 · Hugging Face](https://huggingface.co/LoneStriker/code-millenials-34b-6.0bpw-h6-exl2)\n- # Random Links\n- https://twitter.com/tldraw/status/1782443204710674571\n- {{twitter https://twitter.com/tldraw/status/1782443204710674571}}\n-\n-\n- [Paper page Design2Code: How Far Are We From Automating Front-End Engineering? (huggingface.co)](https://huggingface.co/papers/2403.03163)\n- [Generative AI Powered Assistant - Amazon Q - AWS](https://aws.amazon.com/q/)  Amazons!\n- [antworks.ai](https://antworks.ai/)\n- [OpenBMB/ChatDev: Create Customized Software using Natural Language Idea (through LLM-powered Multi-Agent Collaboration) (github.com)](https://github.com/OpenBMB/ChatDev)\n- [Programming AIs worry me • Buttondown:](https://buttondown.email/hillelwayne/archive/programming-ais-worry-me/)\n- [Home | Tabby (tabbyml.com)](https://tabby.tabbyml.com/)\n- The text discusses the concerns around using AI to generate code, specifically around the idea of proofreading the code. The author describes an experience with using voice-to-text where they found it difficult to proofread the text for errors. The text argues that using AI to generate code changes the work from writing code to proofreading code, and that this is a problem.\n- [Stop whining blog post](https://about.sourcegraph.com/blog/cheating-is-all-you-need)\n- [blog post on LLMs for code](https://evanthebouncy.github.io/program-synthesis-minimal/generation-with-llm/)\n- [Engshell shell LLM extension](https://github.com/emcf/engshell/tree/main)\n- [Github assist](https://useadrenaline.com/app)\n- [Locally run 13B coding optimised model](https://huggingface.co/ehartford/alpaca1337-13b-4bit/tree/main)\n- [Programming AIs worry me • Buttondown (other)](https://buttondown.email/hillelwayne/archive/programming-ais-worry-me/) The article discusses the ethical implications of using machine learning algorithms to generate art. While some see this as a powerful way to create new and interesting works of art, others worry about the potential for misuse and abuse of these technologies.\n- [GPT synthesizer](https://github.com/RoboCoachTechnologies/GPT-Synthesizer)\n- [Colab to get codey](https://www.techspot.com/news/98792-google-colab-soon-get-ai-code-generation-chatbot.html)\n- [Build prompts using coding keywords, paper](https://arxiv.org/abs/2305.06599v3)\n- [Continue for VSCode](https://github.com/continuedev/continue)\n- [Phind technical answers and pair programmer with vscode plugin](https://www.phind.com/)\n- [Starchat beta 4bit](https://huggingface.co/TheBloke/starchat-beta-GPTQ)\n- [Sweep github pull requests to code system](https://github.com/sweepai/sweep)\n- [Cursor.so coding with gpt interface](https://cursor.so)\n- [Code llama 2](https://ai.meta.com/blog/code-llama-large-language-model-coding/)\n- [Long llama](https://github.com/CStanKonrad/long_llama/blob/main/instruction_fine_tuning/LongLLamaCode7BInstruct.md)\n- [Open interpreter](https://openinterpreter.com/)\n- [Open interpreter and autogen local tutorial](https://www.youtube.com/watch?v=DXrpqsjNKbo)\n- [open interpreter github](https://github.com/KillianLucas/open-interpreter)\n- [codingbuddy](https://codebuddy.ca/)\n- [deepseek 34b q4 AWQ](https://huggingface.co/TheBloke/deepseek-coder-33B-instruct-AWQ)\n-\n- [[Vercel]] provides front-end [[Infrastructure]] to allow developers to build fast, dynamic websites and applications efficiently at global scale. Its open source Next.js framework powers many leading AI products' user interfaces.\n\t- Vercel's new vZero product allows developers to visually iterate on UIs with AI assistance.\n\t- [Demo/Tutorial: v0 by Vercel AI Code Generation (youtube.com)](https://www.youtube.com/watch?v=gi5nnOqzHeQ)\n- AI code auto-completion tools like [[Microsoft CoPilot]] have shown the potential for AI to enhance software development. The latest [[Microsoft CoPilot]] leverages [[ChatGPT]] 4 and is extremely good.\n- AI will likely be incorporated into most software products going forward to enhance capabilities and engagement. Some experiences are better suited to standalone interfaces rather than cramming functionality into chatbots.\n- Effective use of AI tools requires developing specialized skills around prompting, understanding system capabilities and limitations, and framing problems appropriately. Different AI systems have strengths in different domains.\n- Software development will transition towards more hybrid human-AI teams, with less focus on writing code line-by-line. AI can provide significant productivity gains by automating rote tasks.\n- There are open questions around whether to expose functionality through general chatbot interfaces vs company-specific products. There are strategic and technical considerations favouring bespoke solutions.\n- Open source software tends to improve quickly over time and should not be underestimated. However, regulations could potentially suppress open source AI progress.\n- [gptengineer.app](https://gptengineer.app/) is a commercial offering built on [[GPT Engineer]]\n- [Understand a codebase in github with GPT](https://useadrenaline.com/app)\n- [Sourcegraph | Code AI platform](https://sourcegraph.com/)\n- [Bito AI\n\t- Become a 10X Dev with Bito\n\t- Bito](https://bito.ai/)\n- [Phind](https://www.phind.com/search?home=true)\n-\n\t-\n\t-\n\t-\n\t-\n- # VSCode Agents [[Tips and Tricks]] [[Training Modules]]\n\t- Cursor\n\t\t- really big detailed settings structures in complex extended codebases need this\n\t- Cline\n\t- Roo Code\n\t- Google Gemini\n\t\t- subtle whole codebase needle in a haystack logic problems\n\t- make notes about what works and doesn't in the commits\n\t- reversion and blend strategies\n\t-\n\n## Current Landscape (2025)\n\n- Industry adoption and implementations\n  - Metaverse platforms continue to evolve with focus on interoperability and open standards\n  - Web3 integration accelerating with decentralised identity and asset ownership\n  - Enterprise adoption growing in virtual collaboration, training, and digital twins\n  - UK companies increasingly active in metaverse development and immersive technologies\n\n- Technical capabilities\n  - Real-time rendering at photorealistic quality levels\n  - Low-latency networking enabling seamless multi-user experiences\n  - AI-driven content generation and procedural world building\n  - Spatial audio and haptics enhancing immersion\n\n- UK and North England context\n  - Manchester: Digital Innovation Factory supports metaverse startups and research\n  - Leeds: Holovis leads in immersive experiences for entertainment and training\n  - Newcastle: University research in spatial computing and interactive systems\n  - Sheffield: Advanced manufacturing using digital twin technology\n\n- Standards and frameworks\n  - Metaverse Standards Forum driving interoperability protocols\n  - WebXR enabling browser-based immersive experiences\n  - glTF and USD for 3D asset interchange\n  - Open Metaverse Interoperability Group defining cross-platform standards\n\n## Metadata\n\n- **Last Updated**: 2025-11-16\n- **Review Status**: Automated remediation with 2025 context\n- **Verification**: Academic sources verified\n- **Regional Context**: UK/North England where applicable",
  "properties": {
    "id": "66e9741c-907c-440c-867c-5a76228a8216",
    "collapsed": "true",
    "- ontology": "true",
    "- term-id": "mv-411006412271",
    "- preferred-term": "Coding support",
    "- source-domain": "metaverse",
    "- status": "active",
    "- public-access": "true",
    "- definition": "A component of the metaverse ecosystem focusing on coding support.",
    "- maturity": "mature",
    "- authority-score": "0.85",
    "- owl:class": "mv:CodingSupport",
    "- owl:physicality": "ConceptualEntity",
    "- owl:role": "Concept",
    "- belongsToDomain": "[[MetaverseDomain]]",
    "- enables": "[[ImmersiveExperience]], [[Presence]], [[SpatialComputing]]",
    "- requires": "[[DisplayTechnology]], [[TrackingSystem]], [[RenderingEngine]]",
    "- bridges-to": "[[HumanComputerInteraction]], [[ComputerVision]], [[Robotics]]",
    "public": "true"
  },
  "backlinks": [
    "Open Webui and Pipelines"
  ],
  "wiki_links": [
    "Vercel",
    "Tips and Tricks",
    "ComputerVision",
    "ChatGPT",
    "Presence",
    "MetaverseDomain",
    "TrackingSystem",
    "Training Modules",
    "DisplayTechnology",
    "RenderingEngine",
    "Infrastructure",
    "ImmersiveExperience",
    "Robotics",
    "Agent Frameworks",
    "Microsoft CoPilot",
    "HumanComputerInteraction",
    "GPT Engineer",
    "SpatialComputing"
  ],
  "ontology": {
    "term_id": "mv-411006412271",
    "preferred_term": "Coding support",
    "definition": "A component of the metaverse ecosystem focusing on coding support.",
    "source_domain": "metaverse",
    "maturity_level": null,
    "authority_score": 0.85
  }
}