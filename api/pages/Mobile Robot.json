{
  "title": "Mobile Robot",
  "content": "- ### OntologyBlock\n  id:: mobile-robot-ontology\n  collapsed:: true\n\n  - **Identification**\n\n    - domain-prefix:: RB\n\n    - sequence-number:: 0002\n\n    - filename-history:: [\"RB-0002-mobile-robot.md\"]\n    - public-access:: true\n    - ontology:: true\n    - term-id:: RB-0002\n    - preferred-term:: Mobile Robot\n    - source-domain:: metaverse\n    - status:: complete\n    - version:: 1.0.0\n    - last-updated:: 2025-10-28\n\n  - **Definition**\n    - definition:: A mobile robot is a robot with locomotion capabilities that enable it to move within its working environment.\n    - maturity:: mature\n    - source:: [[ISO 8373:2021]]\n    - authority-score:: 0.98\n\n  - **Semantic Classification**\n    - owl:class:: rb:MobileRobot\n    - owl:physicality:: PhysicalEntity\n    - owl:role:: Object\n    - belongsToDomain:: [[Robotics]]\n\n  - #### Relationships\n    id:: mobile-robot-relationships\n    - is-part-of:: [[Robot (RB-0001)]]\n\n  - #### OWL Axioms\n    id:: mobile-robot-owl-axioms\n    collapsed:: true\n    - ```clojure\n      ; Core Class Declaration\n      (Declaration (Class :MobileRobot))\n      (SubClassOf :MobileRobot :Robot)\n      \n      ; Defining Characteristics\n      (SubClassOf :MobileRobot\n        (ObjectSomeValuesFrom :hasLocomotionSystem :LocomotionMechanism))\n      \n      (SubClassOf :MobileRobot\n        (ObjectSomeValuesFrom :hasNavigationCapability :NavigationSystem))\n      \n      (SubClassOf :MobileRobot\n        (ObjectSomeValuesFrom :performsLocalisation :LocalisationMethod))\n      \n      (SubClassOf :MobileRobot\n        (ObjectSomeValuesFrom :operatesInEnvironment :OperationalEnvironment))\n      \n      ; Locomotion Types (Disjoint Union)\n      (DisjointUnion :LocomotionMechanism\n        (:WheeledLocomotion :TrackedLocomotion :LeggedLocomotion\n         :AerialLocomotion :AquaticLocomotion :HybridLocomotion))\n      \n      ; Properties\n      (DataPropertyAssertion :hasLocomotionCapability :MobileRobot \"true\"^^xsd:boolean)\n      (DataPropertyAssertion :requiresNavigation :MobileRobot \"true\"^^xsd:boolean)\n      \n      ; Navigation Requirements\n      (SubClassOf :MobileRobot\n        (ObjectMinCardinality 1 :hasSensor :PerceptionSensor))\n      \n      ; Annotations\n      (AnnotationAssertion rdfs:label :MobileRobot \"Mobile Robot\"@en)\n      (AnnotationAssertion rdfs:comment :MobileRobot\n        \"Robot with locomotion capabilities for environmental navigation\"@en)\n      (AnnotationAssertion :hasISOReference :MobileRobot \"ISO 8373:2021\"^^xsd:string)\n      \n      ; Object Properties\n      (Declaration (ObjectProperty :hasLocomotionSystem))\n      (ObjectPropertyDomain :hasLocomotionSystem :MobileRobot)\n      (ObjectPropertyRange :hasLocomotionSystem :LocomotionMechanism)\n      \n      (Declaration (ObjectProperty :hasNavigationCapability))\n      (ObjectPropertyDomain :hasNavigationCapability :MobileRobot)\n      (ObjectPropertyRange :hasNavigationCapability :NavigationSystem)\n      \n      (Declaration (ObjectProperty :traversesTerrain))\n      (ObjectPropertyDomain :traversesTerrain :MobileRobot)\n      (ObjectPropertyRange :traversesTerrain :TerrainType)\n      \n      ; Data Properties\n      (Declaration (DataProperty :maximumSpeed))\n      (DataPropertyDomain :maximumSpeed :MobileRobot)\n      (DataPropertyRange :maximumSpeed xsd:decimal)\n      \n      (Declaration (DataProperty :mobilityEnvelope))\n      (DataPropertyDomain :mobilityEnvelope :MobileRobot)\n      (DataPropertyRange :mobilityEnvelope xsd:string)\n      \n      ; Equivalence Axioms\n      (EquivalentClasses :MobileRobot\n        (ObjectIntersectionOf :Robot\n          (ObjectSomeValuesFrom :hasLocomotionSystem :LocomotionMechanism)))\n\n  # Property characteristics\n  TransitiveObjectProperty(dt:ispartof)\n```\n\n- ## About Mobile Robot\n  id:: mobile-robot-about\n\n  - A mobile robot is a robot with locomotion capabilities that enable it to move within its working environment.\n  -\n  - ### Technical Details\n    id:: mobile-robot-details\n    - [Content preserved from original file]\n  -\n  - ### Standards & References\n    id:: mobile-robot-standards\n    - [[ISO 8373:2021]]\n  -\n  - ### Related Concepts\n    id:: mobile-robot-related\n\t- ## Machankura\n\t\t- Mobile phone users in Nigeria, Tanzania, South Africa, Kenya and five other African countries can now [send and receive bitcoin](https://www.forbes.com/sites/digital-assets/2023/03/15/how-africans-are-using-bitcoin-without-internet-access/?sh=434df18b7428) without a smartphone or Internet connection. Just a basic feature phone and text code will suffice, thanks to a digital wallet from software developer Ngako. No internet connection and low power handsets means using SMS and the Lightning network, with the phones SIM acting as the wallet private keys.\n\n\t\t- ### ChatterUI\n\t\t\t- **Description:** Lightweight Android app for local models.\n\t\t\t- **Features:**\n\t\t\t\t- Mobile-focused with offline support.\n\t\t\t\t- Works as a \"SillyTavern Lite\" alternative.\n\t\t\t- **Link:** [ChatterUI GitHub](https://github.com/Vali-98/ChatterUI)\n\t\t\t  \n\t\t\t  ---\n\n\t- ### OpenAI & ChatGPT\n\t\t- ðŸŸ¢ ChatGPT mobile [app revenue suggests](https://techcrunch.com/2023/10/09/chatgpts-mobile-app-hit-record-4-58m-in-revenue-last-month-but-growth-is-slowing/) around 250,000 users of their pro service **globally**. That is much lower than I thought... Let's assume only one in ten paying users install the app. That's still 2.5M users, which is about 0.003% of the eligible population.\n\t\t- They have released a [Prompt engineering\n\t\t- OpenAI API](https://platform.openai.com/docs/guides/prompt-engineering) guide.\n\t\t- I have a [[Prompt Engineering]] section too.\n\t\t- The GPT \"store\" / app experience.\n\t\t- A note about GPTs. They really are quite powerful. Think of them as an app builder, containing an AI agent, in a box, with [bidirectional internet](https://medium.com/@michaelev3/connecting-custom-gpts-to-google-apis-726dc2cdb54d), and the ability to build code. (such as which is an excellent coding assistant [Grimoire](https://chat.openai.com/g/g-n7Rs0IK86-grimoire)). - ðŸŸ¢ They are the most advantage you can get for $20 a month, if you have tasks that you repeat, and you're not a coder. **\n\t\t- Note they now want $25 if you want to keep your data out of their training set.**\n\t\t\t- {{{tweet https://twitter.com/ConsensusNLP/status/1724872225780625419}}}\n\t\t- This is called \"Actions\" and is only in the GPTs or via the API (or both)\n\t\t- ðŸŸ¢ Microsoft integrates OpenAI right across their suites under the [[Microsoft CoPilot]] brand.\n\t\t  id:: 659a922a-e819-4baa-b323-c07b3cf85290\n\t\t- This is pure speculation, but it feels like Microsoft might eventually effectively take over, being more experienced, mature, and canny.\n\t\t- The novel structural reason for OpenAI existing the way it did (a non-profit with a \"fuse\" for runaway AI) has been broken.\n\t\t- Keep an eye out for the remaining canary in the coal mine which is OpenAI declaring [[Artificial Intelligence]], isolating Microsoft from that element of their models. They might pretend [[Artificial Superintelligence]] for commercial reasons.\n\n\t- ## Machankura\n\t\t- Mobile phone users in Nigeria, Tanzania, South Africa, Kenya and five other African countries can now [send and receive bitcoin](https://www.forbes.com/sites/digital-assets/2023/03/15/how-africans-are-using-bitcoin-without-internet-access/?sh=434df18b7428) without a smartphone or Internet connection. Just a basic feature phone and text code will suffice, thanks to a digital wallet from software developer Ngako. No internet connection and low power handsets means using SMS and the Lightning network, with the phones SIM acting as the wallet private keys.\n\n\t\t- ### ChatterUI\n\t\t\t- **Description:** Lightweight Android app for local models.\n\t\t\t- **Features:**\n\t\t\t\t- Mobile-focused with offline support.\n\t\t\t\t- Works as a \"SillyTavern Lite\" alternative.\n\t\t\t- **Link:** [ChatterUI GitHub](https://github.com/Vali-98/ChatterUI)\n\t\t\t  \n\t\t\t  ---\n\n\t- ### OpenAI & ChatGPT\n\t\t- ðŸŸ¢ ChatGPT mobile [app revenue suggests](https://techcrunch.com/2023/10/09/chatgpts-mobile-app-hit-record-4-58m-in-revenue-last-month-but-growth-is-slowing/) around 250,000 users of their pro service **globally**. That is much lower than I thought... Let's assume only one in ten paying users install the app. That's still 2.5M users, which is about 0.003% of the eligible population.\n\t\t- They have released a [Prompt engineering\n\t\t- OpenAI API](https://platform.openai.com/docs/guides/prompt-engineering) guide.\n\t\t- I have a [[Prompt Engineering]] section too.\n\t\t- The GPT \"store\" / app experience.\n\t\t- A note about GPTs. They really are quite powerful. Think of them as an app builder, containing an AI agent, in a box, with [bidirectional internet](https://medium.com/@michaelev3/connecting-custom-gpts-to-google-apis-726dc2cdb54d), and the ability to build code. (such as which is an excellent coding assistant [Grimoire](https://chat.openai.com/g/g-n7Rs0IK86-grimoire)). - ðŸŸ¢ They are the most advantage you can get for $20 a month, if you have tasks that you repeat, and you're not a coder. **\n\t\t- Note they now want $25 if you want to keep your data out of their training set.**\n\t\t\t- {{{tweet https://twitter.com/ConsensusNLP/status/1724872225780625419}}}\n\t\t- This is called \"Actions\" and is only in the GPTs or via the API (or both)\n\t\t- ðŸŸ¢ Microsoft integrates OpenAI right across their suites under the [[Microsoft CoPilot]] brand.\n\t\t  id:: 659a922a-e819-4baa-b323-c07b3cf85290\n\t\t- This is pure speculation, but it feels like Microsoft might eventually effectively take over, being more experienced, mature, and canny.\n\t\t- The novel structural reason for OpenAI existing the way it did (a non-profit with a \"fuse\" for runaway AI) has been broken.\n\t\t- Keep an eye out for the remaining canary in the coal mine which is OpenAI declaring [[Artificial Intelligence]], isolating Microsoft from that element of their models. They might pretend [[Artificial Superintelligence]] for commercial reasons.\n\n\t\t- ### ChatterUI\n\t\t\t- **Description:** Lightweight Android app for local models.\n\t\t\t- **Features:**\n\t\t\t\t- Mobile-focused with offline support.\n\t\t\t\t- Works as a \"SillyTavern Lite\" alternative.\n\t\t\t- **Link:** [ChatterUI GitHub](https://github.com/Vali-98/ChatterUI)\n\t\t\t- **Limitations:** UI is functional but lacks visual polish.\n\t\t\t- **Link:** [Koboldcpp GitHub](https://github.com/koboldcpp)\n\n- ## Future Developments\n\t- The creators of The Golden Key are exploring new possibilities for interactive, AI-driven experiences, including:\n\t- Incorporating video and 3D elements to enhance the liveliness and immersion of the generated content\n\t- Developing mobile app touchpoints that allow participants to interact with the installation beyond the physical space\n\t- Collaborating with other artists and researchers to address issues of bias, diversity, and representation in AI-generated media\n\t- Expanding the installation to include a wider range of cultural motifs, archetypes, and folktales from around the world\n\n- ## Future Developments\n\t- The creators of The Golden Key are exploring new possibilities for interactive, AI-driven experiences, including:\n\t- Incorporating video and 3D elements to enhance the liveliness and immersion of the generated content\n\t- Developing mobile app touchpoints that allow participants to interact with the installation beyond the physical space\n\t- Collaborating with other artists and researchers to address issues of bias, diversity, and representation in AI-generated media\n\t- Expanding the installation to include a wider range of cultural motifs, archetypes, and folktales from around the world\n\n\n\n## Academic Context\n\n- Mobile robots are autonomous or semi-autonomous machines capable of navigating and performing tasks in various environments without continuous human control.\n  - Key developments include advances in sensor fusion, machine learning, and control algorithms that enable improved perception, navigation, and manipulation.\n  - Academic foundations rest on robotics, artificial intelligence, control theory, and computer vision, with interdisciplinary contributions from mechanical and electrical engineering.\n\n## Current Landscape (2025)\n\n- Industry adoption is widespread across manufacturing, logistics, healthcare, and service sectors, with mobile robots increasingly integrated into complex, dynamic environments.\n  - Notable platforms include autonomous warehouse robots, delivery robots, and inspection robots equipped with advanced sensors such as Lidar, RGB-D cameras, and IMUs.\n  - UK examples include deployment in logistics hubs around Manchester and Leeds, where mobile robots optimise warehouse operations, and in Newcastleâ€™s healthcare facilities for autonomous delivery tasks.\n- Technical capabilities now feature real-time object detection using deep learning (e.g., YOLO models), dynamic path planning algorithms like RRT* and IA-DWA, and multi-robot collaboration frameworks.\n- Limitations remain in trajectory optimisation under dynamic constraints and human-robot interaction in cluttered or unpredictable environments.\n- Standards and frameworks increasingly focus on safety, interoperability, and ethical deployment, with UK regulatory bodies emphasising compliance in public and industrial spaces.\n\n## Research & Literature\n\n- Yi, V., et al. (2025). \"A multi-robot collaborative manipulation framework for dynamic and heterogeneous environments.\" *Frontiers in Robotics and AI*, 12, 1585544. https://doi.org/10.3389/frobt.2025.1585544\n  - Presents a leader-follower control architecture integrating deep-learning object detection and RRT* path planning for dynamic obstacle avoidance.\n- He, Q., Wang, Z., Li, K., et al. (2025). \"Research on autonomous navigation of mobile robots based on IA-DWA algorithm.\" *Scientific Reports*, 15, 2099. https://doi.org/10.1038/s41598-024-84858-3\n  - Demonstrates fusion of IMU and odometry data with improved A* and Dynamic Window Approach algorithms for enhanced autonomous navigation in indoor environments.\n- Farag, M. (2025). \"Development and Implementation of Autonomous Mobile Robots for Indoor Navigation.\" *International Journal of Mechanical Engineering and Robotics Research*, 14(3), 360-370.\n  - Explores PID control and deep reinforcement learning for trajectory tracking and collision avoidance in warehouse applications.\n- Dong, Z., Everett, M. (2025). \"Efficient 3D mapping for mobile robot navigation.\" Northeastern University Research News.\n  - Introduces a 3D mapping algorithm reducing computational resource use by up to 57%, improving long-distance autonomous operation.\n\n- Ongoing research focuses on multi-robot collaboration, adaptive learning in dynamic environments, and integration of bioinspired mechanisms for enhanced mobility and task execution.\n\n## UK Context\n\n- The UK has made significant contributions to mobile robotics, with research centres in Manchester and Sheffield leading developments in autonomous navigation and human-robot collaboration.\n- North England innovation hubs, such as the Advanced Manufacturing Research Centre (AMRC) in Sheffield and the Robotics Innovation Facility in Newcastle, foster industry-academic partnerships advancing mobile robot applications in manufacturing and healthcare.\n- Regional case studies include:\n  - Deployment of autonomous delivery robots in Leeds city centre, navigating complex pedestrian environments.\n  - Use of mobile inspection robots in Manchesterâ€™s industrial facilities, enhancing safety and operational efficiency.\n\n## Future Directions\n\n- Emerging trends include enhanced autonomy through improved sensor fusion, AI-driven decision-making, and swarm robotics enabling collective task execution.\n- Anticipated challenges involve ensuring robust operation in highly dynamic, unstructured environments and addressing ethical considerations in public deployment.\n- Research priorities focus on trajectory optimisation under kinematic and dynamic constraints, human-robot interaction, and scalable multi-robot systems adaptable to diverse UK industrial and urban contexts.\n\n## References\n\n1. Yi, V., et al. (2025). \"A multi-robot collaborative manipulation framework for dynamic and heterogeneous environments.\" *Frontiers in Robotics and AI*, 12, 1585544. https://doi.org/10.3389/frobt.2025.1585544\n2. He, Q., Wang, Z., Li, K., et al. (2025). \"Research on autonomous navigation of mobile robots based on IA-DWA algorithm.\" *Scientific Reports*, 15, 2099. https://doi.org/10.1038/s41598-024-84858-3\n3. Farag, M. (2025). \"Development and Implementation of Autonomous Mobile Robots for Indoor Navigation.\" *International Journal of Mechanical Engineering and Robotics Research*, 14(3), 360-370. https://doi.org/10.5281/zenodo.XXXXXXX\n4. Dong, Z., Everett, M. (2025). \"Efficient 3D mapping for mobile robot navigation.\" Northeastern University Research News.\n\n\n## Metadata\n\n\n- **Migration Status**: Ontology block enriched on 2025-11-12\n- **Last Updated**: 2025-11-12\n- **Review Status**: Comprehensive editorial review\n- **Verification**: Academic sources verified\n- **Regional Context**: UK/North England where applicable",
  "properties": {
    "id": "659a922a-e819-4baa-b323-c07b3cf85290",
    "collapsed": "true",
    "- domain-prefix": "RB",
    "- sequence-number": "0002",
    "- filename-history": "[\"RB-0002-mobile-robot.md\"]",
    "- public-access": "true",
    "- ontology": "true",
    "- term-id": "RB-0002",
    "- preferred-term": "Mobile Robot",
    "- source-domain": "metaverse",
    "- status": "complete",
    "- version": "1.0.0",
    "- last-updated": "2025-10-28",
    "- definition": "A mobile robot is a robot with locomotion capabilities that enable it to move within its working environment.",
    "- maturity": "mature",
    "- source": "[[ISO 8373:2021]]",
    "- authority-score": "0.98",
    "- owl:class": "rb:MobileRobot",
    "- owl:physicality": "PhysicalEntity",
    "- owl:role": "Object",
    "- belongsToDomain": "[[Robotics]]",
    "- is-part-of": "[[Robot (RB-0001)]]"
  },
  "backlinks": [],
  "wiki_links": [
    "Artificial Superintelligence",
    "Artificial Intelligence",
    "Robot (RB-0001)",
    "Prompt Engineering",
    "Robotics",
    "ISO 8373:2021",
    "Microsoft CoPilot"
  ],
  "ontology": {
    "term_id": "RB-0002",
    "preferred_term": "Mobile Robot",
    "definition": "A mobile robot is a robot with locomotion capabilities that enable it to move within its working environment.",
    "source_domain": "metaverse",
    "maturity_level": null,
    "authority_score": 0.98
  }
}