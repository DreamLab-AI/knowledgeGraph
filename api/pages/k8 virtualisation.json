{
  "title": "LINSTOR on Bare Metal Kubernetes: Complete Setup Guide",
  "content": "- ### OntologyBlock\n  id:: linstor-on-bare-metal-kubernetes:-complete-setup-guide-ontology\n  collapsed:: true\n\t- ontology:: true\n\t- term-id:: mv-84505038949\n\t- preferred-term:: LINSTOR on Bare Metal Kubernetes: Complete Setup Guide\n\t- source-domain:: metaverse\n\t- status:: active\n\t- public-access:: true\n\t- definition:: A component of the metaverse ecosystem focusing on linstor on bare metal kubernetes: complete setup guide.\n\t- maturity:: mature\n\t- authority-score:: 0.85\n\t- owl:class:: mv:LinstorOnBareMetalKubernetesCompleteSetupGuide\n\t- owl:physicality:: ConceptualEntity\n\t- owl:role:: Concept\n\t- belongsToDomain:: [[MetaverseDomain]]\n\t- #### Relationships\n\t  id:: linstor-on-bare-metal-kubernetes:-complete-setup-guide-relationships\n\t\t- enables:: [[ImmersiveExperience]], [[Presence]], [[SpatialComputing]]\n\t\t- requires:: [[DisplayTechnology]], [[TrackingSystem]], [[RenderingEngine]]\n\t\t- bridges-to:: [[HumanComputerInteraction]], [[ComputerVision]], [[Robotics]]\n\n\t- #### OWL Axioms\n\t  id:: linstor-on-bare-metal-kubernetes:-complete-setup-guide-owl-axioms\n\t  collapsed:: true\n\t\t- ```clojure\n\t\t  Declaration(Class(mv:LinstorOnBareMetalKubernetesCompleteSetupGuide))\n\n\t\t  # Classification\n\t\t  SubClassOf(mv:LinstorOnBareMetalKubernetesCompleteSetupGuide mv:ConceptualEntity)\n\t\t  SubClassOf(mv:LinstorOnBareMetalKubernetesCompleteSetupGuide mv:Concept)\n\n\t\t  # Domain classification\n\t\t  SubClassOf(mv:LinstorOnBareMetalKubernetesCompleteSetupGuide\n\t\t    ObjectSomeValuesFrom(mv:belongsToDomain mv:MetaverseDomain)\n\t\t  )\n\n\t\t  # Annotations\n\t\t  AnnotationAssertion(rdfs:label mv:LinstorOnBareMetalKubernetesCompleteSetupGuide \"LINSTOR on Bare Metal Kubernetes: Complete Setup Guide\"@en)\n\t\t  AnnotationAssertion(rdfs:comment mv:LinstorOnBareMetalKubernetesCompleteSetupGuide \"A component of the metaverse ecosystem focusing on linstor on bare metal kubernetes: complete setup guide.\"@en)\n\t\t  AnnotationAssertion(dcterms:identifier mv:LinstorOnBareMetalKubernetesCompleteSetupGuide \"mv-84505038949\"^^xsd:string)\n\t\t  ```\n\n# LINSTOR on Bare Metal Kubernetes: Complete Setup Guide\n- ## Table of Contents\n- [Overview](https://claude.ai/chat/ca8cc5ff-885b-425e-8055-f69206bbe178#overview)\n- [Prerequisites](https://claude.ai/chat/ca8cc5ff-885b-425e-8055-f69206bbe178#prerequisites)\n- [Node Preparation](https://claude.ai/chat/ca8cc5ff-885b-425e-8055-f69206bbe178#node-preparation)\n- [Installing Piraeus Operator](https://claude.ai/chat/ca8cc5ff-885b-425e-8055-f69206bbe178#installing-piraeus-operator)\n- [Configuring LINSTOR Cluster](https://claude.ai/chat/ca8cc5ff-885b-425e-8055-f69206bbe178#configuring-linstor-cluster)\n- [Storage Pool Setup](https://claude.ai/chat/ca8cc5ff-885b-425e-8055-f69206bbe178#storage-pool-setup)\n- [StorageClass Configuration](https://claude.ai/chat/ca8cc5ff-885b-425e-8055-f69206bbe178#storageclass-configuration)\n- [Validation and Testing](https://claude.ai/chat/ca8cc5ff-885b-425e-8055-f69206bbe178#validation-and-testing)\n- [Operations and Maintenance](https://claude.ai/chat/ca8cc5ff-885b-425e-8055-f69206bbe178#operations-and-maintenance)\n- [Troubleshooting](https://claude.ai/chat/ca8cc5ff-885b-425e-8055-f69206bbe178#troubleshooting)\n- [Advanced Configurations](https://claude.ai/chat/ca8cc5ff-885b-425e-8055-f69206bbe178#advanced-configurations)\n- ## Overview\n  \n  This guide provides a complete walkthrough for deploying LINSTOR (Linux Storage) via the Piraeus Operator on bare metal Kubernetes clusters. LINSTOR provides replicated block storage using DRBD (Distributed Replicated Block Device) technology, offering high-performance, highly available storage for Kubernetes workloads.\n- ### Architecture Components\n- **LINSTOR Controller**: Central management component\n- **LINSTOR Satellites**: Node-level storage managers\n- **DRBD**: Kernel module for block replication\n- **CSI Driver**: Kubernetes storage interface\n- **Piraeus Operator**: Kubernetes operator for lifecycle management\n- ## Prerequisites\n- ### Hardware Requirements\n- Minimum 3 worker nodes for redundancy\n- Dedicated storage devices (NVMe/SSD recommended)\n- 10GbE+ network for storage traffic (recommended)\n- 8GB+ RAM per node (16GB+ recommended)\n- ### Software Requirements\n- Kubernetes 1.21+ cluster\n- Linux kernel 4.14+ (5.x recommended)\n- kubectl CLI tool\n- helm 3.x (optional)\n- ### Network Requirements\n- Nodes must be able to communicate on ports:\n\t- 3366-3370 (LINSTOR)\n\t- 7000-7999 (DRBD)\n\t- 9942-9943 (Prometheus metrics)\n- ## Node Preparation\n- ### 1. Verify Kernel Compatibility\n  \n  ```\n  # Check kernel version\n  uname -r\n  \n  # Should be 4.14 or higher\n  # Example output: 5.15.0-91-generic\n  ```\n- ### 2. Install Required Packages\n  \n  **On Ubuntu/Debian:**\n  \n  ```\n  sudo apt-get update\n  sudo apt-get install -y \\\n  lvm2 \\\n  thin-provisioning-tools \\\n  xfsprogs \\\n  nvme-cli\n  ```\n  \n  **On RHEL/Rocky/AlmaLinux:**\n  \n  ```\n  sudo dnf install -y \\\n  lvm2 \\\n  device-mapper-persistent-data \\\n  xfsprogs \\\n  nvme-cli\n  ```\n- ### 3. Configure Storage Devices\n  \n  Identify available storage devices:\n  \n  ```\n  # List all block devices\n  lsblk -d\n  \n  # For NVMe devices\n  nvme list\n  \n  # Example output:\n  # NAME        MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT\n  # nvme0n1     259:0    0   1.8T  0 disk\n  # nvme1n1     259:1    0   1.8T  0 disk\n  ```\n- ### 4. Label Storage Nodes\n  \n  ```\n  # Label nodes that will provide storage\n  kubectl label node node-1 node-role.kubernetes.io/storage=true\n  kubectl label node node-2 node-role.kubernetes.io/storage=true\n  kubectl label node node-3 node-role.kubernetes.io/storage=true\n  \n  # Add topology labels for zone awareness\n  kubectl label node node-1 topology.kubernetes.io/zone=zone-a\n  kubectl label node node-2 topology.kubernetes.io/zone=zone-b\n  kubectl label node node-3 topology.kubernetes.io/zone=zone-c\n  ```\n- ### 5. Configure Kernel Modules\n  \n  Create module loading configuration:\n  \n  ```\n  # Ensure DRBD modules load on boot\n  echo \"drbd\" | sudo tee /etc/modules-load.d/drbd.conf\n  echo \"drbd_transport_tcp\" | sudo tee -a /etc/modules-load.d/drbd.conf\n  \n  # Load modules immediately\n  sudo modprobe drbd\n  sudo modprobe drbd_transport_tcp\n  ```\n  \n  **For Secure Boot Systems:**\n  \n  If Secure Boot is enabled, you'll need to sign the DRBD modules:\n  \n  ```\n  # Check Secure Boot status\n  mokutil --sb-state\n  \n  # If enabled, follow your distribution's module signing process\n  # Or use Piraeus Operator's automatic module injection\n  ```\n- ## Installing Piraeus Operator\n- ### 1. Create Namespace\n  \n  ```\n  kubectl create namespace piraeus-datastore\n  ```\n- ### 2. Install via Kustomize (Recommended)\n  \n  ```\n  # Get the latest version\n  PIRAEUS_VERSION=$(curl -s https://api.github.com/repos/piraeusdatastore/piraeus-operator/releases/latest | grep '\"tag_name\":' | sed -E 's/.*\"v([^\"]+)\".*/\\1/')\n  \n  # Apply the operator\n  kubectl apply -k \"https://github.com/piraeusdatastore/piraeus-operator//config/default?ref=v${PIRAEUS_VERSION}\"\n  ```\n- ### 3. Verify Installation\n  \n  ```\n  # Check operator deployment\n  kubectl -n piraeus-datastore get deployment piraeus-operator\n  \n  # Check CRDs\n  kubectl get crd | grep linstor\n  \n  # Expected CRDs:\n  # linstorclusters.linstor.io\n  # linstorsatellites.linstor.io\n  # linstorcontrollers.linstor.io\n  ```\n- ### 4. Install kubectl-linstor Plugin (Optional but Recommended)\n  \n  ```\n  # Download the plugin\n  curl -LO \"https://github.com/piraeusdatastore/kubectl-linstor/releases/latest/download/kubectl-linstor-linux-amd64.tar.gz\"\n  \n  # Extract and install\n  tar -xzf kubectl-linstor-linux-amd64.tar.gz\n  sudo mv kubectl-linstor /usr/local/bin/\n  \n  # Verify\n  kubectl linstor --version\n  ```\n- ## Configuring LINSTOR Cluster\n- ### 1. Basic Cluster Configuration\n  \n  Create `linstor-cluster.yaml`:\n  \n  ```\n  apiVersion: linstor.io/v1\n  kind: LinstorCluster\n  metadata:\n  name: linstorcluster\n  namespace: piraeus-datastore\n  spec:\n  # Empty spec creates basic cluster with defaults\n  {}\n  ```\n  \n  Apply the configuration:\n  \n  ```\n  kubectl apply -f linstor-cluster.yaml\n  ```\n- ### 2. Production Cluster Configuration\n  \n  For production environments, create `linstor-cluster-prod.yaml`:\n  \n  ```\n  apiVersion: linstor.io/v1\n  kind: LinstorCluster\n  metadata:\n  name: linstorcluster\n  namespace: piraeus-datastore\n  spec:\n  nodeAffinity:\n    requiredDuringSchedulingIgnoredDuringExecution:\n      nodeSelectorTerms:\n      - matchExpressions:\n        - key: node-role.kubernetes.io/storage\n          operator: Exists\n  \n  linstorController:\n    replicas: 3\n    dbConnectionURL: \"k8s\"\n    resources:\n      requests:\n        cpu: \"500m\"\n        memory: \"1Gi\"\n      limits:\n        cpu: \"2\"\n        memory: \"2Gi\"\n    tolerations:\n    - key: \"node-role.kubernetes.io/control-plane\"\n      operator: \"Exists\"\n      effect: \"NoSchedule\"\n    \n  linstorSatellite:\n    automaticStorageType: None\n    kernelModuleInjectionMode: \"Module\"\n    resources:\n      requests:\n        cpu: \"1\"\n        memory: \"1Gi\"\n      limits:\n        cpu: \"4\"\n        memory: \"4Gi\"\n    \n  linstorCSI:\n    enabled: true\n    controllerReplicas: 3\n    nodeDriverRegistrar:\n      resources:\n        requests:\n          cpu: \"100m\"\n          memory: \"100Mi\"\n    \n  monitoring:\n    enabled: true\n    \n  security:\n    enabled: true\n  ```\n  \n  Apply the production configuration:\n  \n  ```\n  kubectl apply -f linstor-cluster-prod.yaml\n  ```\n- ### 3. Wait for Cluster Ready\n  \n  ```\n  # Watch cluster status\n  kubectl -n piraeus-datastore get linstorcluster -w\n  \n  # Check all pods are running\n  kubectl -n piraeus-datastore get pods\n  \n  # Expected pods:\n  # - piraeus-operator-*\n  # - linstor-controller-*\n  # - linstor-satellite-*\n  # - linstor-csi-controller-*\n  # - linstor-csi-node-*\n  ```\n- ### 4. Configure DRBD Module Loader (if needed)\n  \n  For systems with Secure Boot or custom kernels:\n  \n  ```\n  apiVersion: v1\n  kind: ConfigMap\n  metadata:\n  name: drbd-module-loader-config\n  namespace: piraeus-datastore\n  data:\n  LB_HOW: \"compile\"  # or \"shipped\" for pre-compiled modules\n  ---\n  apiVersion: apps/v1\n  kind: DaemonSet\n  metadata:\n  name: drbd-module-loader\n  namespace: piraeus-datastore\n  spec:\n  selector:\n    matchLabels:\n      app: drbd-module-loader\n  template:\n    metadata:\n      labels:\n        app: drbd-module-loader\n    spec:\n      hostNetwork: true\n      hostPID: true\n      hostIPC: true\n      containers:\n      - name: drbd-module-loader\n        image: quay.io/piraeusdatastore/drbd-module-loader:v9.2.6\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - name: lib-modules\n          mountPath: /lib/modules\n        - name: usr-src\n          mountPath: /usr/src\n        - name: etc\n          mountPath: /etc\n        envFrom:\n        - configMapRef:\n            name: drbd-module-loader-config\n      volumes:\n      - name: lib-modules\n        hostPath:\n          path: /lib/modules\n      - name: usr-src\n        hostPath:\n          path: /usr/src\n      - name: etc\n        hostPath:\n          path: /etc\n  ```\n- ## Storage Pool Setup\n- ### 1. Prepare Physical Volumes\n  \n  On each storage node:\n  \n  ```\n  # Example using /dev/nvme1n1\n  # WARNING: This will destroy all data on the device!\n  \n  # Create physical volume\n  sudo pvcreate /dev/nvme1n1\n  \n  # Create volume group\n  sudo vgcreate linstor_vg /dev/nvme1n1\n  \n  # Verify\n  sudo vgdisplay linstor_vg\n  ```\n- ### 2. Create LVM Thin Pools\n  \n  ```\n  # Create thin pool using 95% of VG\n  sudo lvcreate -l 95%VG --thinpool linstor_thinpool linstor_vg\n  \n  # Verify\n  sudo lvs\n  ```\n- ### 3. Register Storage Pools with LINSTOR\n  \n  ```\n  # List LINSTOR nodes\n  kubectl linstor node list\n  \n  # Create storage pool on each node\n  kubectl linstor storage-pool create lvmthin \\\n  node-1 linstor-pool linstor_vg/linstor_thinpool\n  \n  kubectl linstor storage-pool create lvmthin \\\n  node-2 linstor-pool linstor_vg/linstor_thinpool\n  \n  kubectl linstor storage-pool create lvmthin \\\n  node-3 linstor-pool linstor_vg/linstor_thinpool\n  \n  # Verify storage pools\n  kubectl linstor storage-pool list\n  ```\n- ### 4. Create Resource Groups\n  \n  ```\n  # Create a resource group for 2-way replication\n  kubectl linstor resource-group create replicated-2 \\\n  --storage-pool linstor-pool \\\n  --place-count 2\n  \n  # Create a resource group for 3-way replication\n  kubectl linstor resource-group create replicated-3 \\\n  --storage-pool linstor-pool \\\n  --place-count 3\n  \n  # Set properties\n  kubectl linstor resource-group set-property replicated-2 \\\n  DrbdOptions/auto-quorum suspend-io\n  \n  kubectl linstor resource-group set-property replicated-3 \\\n  DrbdOptions/auto-quorum suspend-io\n  ```\n- ## StorageClass Configuration\n- ### 1. Basic Replicated Storage\n  \n  Create `storageclass-basic.yaml`:\n  \n  ```\n  apiVersion: storage.k8s.io/v1\n  kind: StorageClass\n  metadata:\n  name: linstor-replicated-2\n  annotations:\n    storageclass.kubernetes.io/is-default-class: \"true\"\n  provisioner: linstor.csi.linbit.com\n  allowVolumeExpansion: true\n  reclaimPolicy: Delete\n  volumeBindingMode: WaitForFirstConsumer\n  parameters:\n  linstor.csi.linbit.com/storagePool: \"linstor-pool\"\n  linstor.csi.linbit.com/resourceGroup: \"replicated-2\"\n  property.linstor.csi.linbit.com/DrbdOptions/auto-quorum: suspend-io\n  property.linstor.csi.linbit.com/DrbdOptions/Resource/on-no-data-accessible: suspend-io\n  property.linstor.csi.linbit.com/DrbdOptions/Resource/on-suspended-primary-outdated: force-secondary\n  csi.storage.k8s.io/fstype: ext4\n  ```\n- ### 2. High-Performance Storage\n  \n  Create `storageclass-performance.yaml`:\n  \n  ```\n  apiVersion: storage.k8s.io/v1\n  kind: StorageClass\n  metadata:\n  name: linstor-nvme-performance\n  provisioner: linstor.csi.linbit.com\n  allowVolumeExpansion: true\n  reclaimPolicy: Delete\n  volumeBindingMode: Immediate\n  parameters:\n  linstor.csi.linbit.com/storagePool: \"linstor-pool\"\n  linstor.csi.linbit.com/resourceGroup: \"replicated-2\"\n  linstor.csi.linbit.com/replicasOnSame: \"kubernetes.io/hostname\"\n  linstor.csi.linbit.com/replicasOnDifferent: \"topology.kubernetes.io/zone\"\n  property.linstor.csi.linbit.com/DrbdOptions/Net/max-buffers: \"10000\"\n  property.linstor.csi.linbit.com/DrbdOptions/Net/max-epoch-size: \"10000\"\n  property.linstor.csi.linbit.com/DrbdOptions/Net/sndbuf-size: \"1048576\"\n  property.linstor.csi.linbit.com/DrbdOptions/Net/rcvbuf-size: \"1048576\"\n  property.linstor.csi.linbit.com/DrbdOptions/Disk/c-plan-ahead: \"10\"\n  property.linstor.csi.linbit.com/DrbdOptions/Disk/c-max-rate: \"100M\"\n  property.linstor.csi.linbit.com/DrbdOptions/Disk/disk-flushes: \"no\"\n  property.linstor.csi.linbit.com/DrbdOptions/Disk/md-flushes: \"no\"\n  csi.storage.k8s.io/fstype: xfs\n  mountOptions:\n    - noatime\n    - nodiratime\n  ```\n- ### 3. Zone-Aware Storage\n  \n  Create `storageclass-zone-aware.yaml`:\n  \n  ```\n  apiVersion: storage.k8s.io/v1\n  kind: StorageClass\n  metadata:\n  name: linstor-zone-redundant\n  provisioner: linstor.csi.linbit.com\n  allowVolumeExpansion: true\n  parameters:\n  linstor.csi.linbit.com/storagePool: \"linstor-pool\"\n  linstor.csi.linbit.com/resourceGroup: \"replicated-3\"\n  linstor.csi.linbit.com/replicasOnDifferent: \"topology.kubernetes.io/zone\"\n  linstor.csi.linbit.com/allowRemoteVolumeAccess: \"false\"\n  linstor.csi.linbit.com/placementPolicy: \"AutoPlace\"\n  ```\n  \n  Apply all StorageClasses:\n  \n  ```\n  kubectl apply -f storageclass-basic.yaml\n  kubectl apply -f storageclass-performance.yaml\n  kubectl apply -f storageclass-zone-aware.yaml\n  ```\n- ## Validation and Testing\n- ### 1. Basic Functionality Test\n  \n  Create `test-pvc.yaml`:\n  \n  ```\n  apiVersion: v1\n  kind: PersistentVolumeClaim\n  metadata:\n  name: test-pvc\n  spec:\n  accessModes:\n    - ReadWriteOnce\n  storageClassName: linstor-replicated-2\n  resources:\n    requests:\n      storage: 5Gi\n  ---\n  apiVersion: v1\n  kind: Pod\n  metadata:\n  name: test-pod\n  spec:\n  containers:\n  - name: test\n    image: nginx:alpine\n    volumeMounts:\n    - name: data\n      mountPath: /data\n  volumes:\n  - name: data\n    persistentVolumeClaim:\n      claimName: test-pvc\n  ```\n  \n  Deploy and verify:\n  \n  ```\n  # Create PVC and Pod\n  kubectl apply -f test-pvc.yaml\n  \n  # Check PVC is bound\n  kubectl get pvc test-pvc\n  \n  # Check pod is running\n  kubectl get pod test-pod\n  \n  # Verify LINSTOR resources\n  kubectl linstor volume list\n  \n  # Write test data\n  kubectl exec test-pod -- sh -c \"echo 'test data' > /data/test.txt\"\n  \n  # Clean up\n  kubectl delete -f test-pvc.yaml\n  ```\n- ### 2. Performance Testing\n  \n  Create `performance-test.yaml`:\n  \n  ```\n  apiVersion: batch/v1\n  kind: Job\n  metadata:\n  name: storage-benchmark\n  spec:\n  template:\n    spec:\n      containers:\n      - name: fio\n        image: wallnerryan/fio-test\n        command: [\"fio\"]\n        args:\n        - \"--name=randwrite\"\n        - \"--ioengine=libaio\"\n        - \"--rw=randwrite\"\n        - \"--bs=4k\"\n        - \"--direct=1\"\n        - \"--size=1G\"\n        - \"--numjobs=4\"\n        - \"--time_based\"\n        - \"--runtime=30\"\n        - \"--group_reporting\"\n        - \"--filename=/data/test\"\n        volumeMounts:\n        - name: data\n          mountPath: /data\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: benchmark-pvc\n      restartPolicy: Never\n  ---\n  apiVersion: v1\n  kind: PersistentVolumeClaim\n  metadata:\n  name: benchmark-pvc\n  spec:\n  accessModes:\n    - ReadWriteOnce\n  storageClassName: linstor-nvme-performance\n  resources:\n    requests:\n      storage: 10Gi\n  ```\n  \n  Run performance test:\n  \n  ```\n  # Deploy benchmark\n  kubectl apply -f performance-test.yaml\n  \n  # Watch job progress\n  kubectl logs -f job/storage-benchmark\n  \n  # Clean up\n  kubectl delete -f performance-test.yaml\n  ```\n- ### 3. Failover Testing\n  \n  Test node failure scenarios:\n  \n  ```\n  # Create a test workload\n  kubectl apply -f test-pvc.yaml\n  \n  # Find which nodes have the volume\n  kubectl linstor resource list | grep pvc\n  \n  # Simulate node failure\n  kubectl cordon node-2\n  kubectl drain node-2 --ignore-daemonsets --delete-emptydir-data\n  \n  # Verify pod migrates and data is accessible\n  kubectl get pod test-pod -o wide\n  kubectl exec test-pod -- cat /data/test.txt\n  \n  # Restore node\n  kubectl uncordon node-2\n  ```\n- ## Operations and Maintenance\n- ### 1. Monitoring Setup\n  \n  Enable Prometheus monitoring:\n  \n  ```\n  apiVersion: v1\n  kind: ServiceMonitor\n  metadata:\n  name: linstor-metrics\n  namespace: piraeus-datastore\n  spec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: linstor\n  endpoints:\n  - port: metrics\n    interval: 30s\n    path: /metrics\n  ```\n- ### 2. Backup Procedures\n  \n  Backup LINSTOR configuration:\n  \n  ```\n  # Backup LINSTOR database\n  kubectl -n piraeus-datastore exec -it linstor-controller-0 -- \\\n  linstor backup create /tmp/linstor-backup.tar\n  \n  # Copy backup locally\n  kubectl -n piraeus-datastore cp \\\n  linstor-controller-0:/tmp/linstor-backup.tar ./linstor-backup.tar\n  \n  # Backup Kubernetes resources\n  kubectl -n piraeus-datastore get linstorcluster -o yaml > linstor-cluster-backup.yaml\n  kubectl get storageclass -o yaml > storageclasses-backup.yaml\n  ```\n- ### 3. Capacity Management\n  \n  Monitor storage usage:\n  \n  ```\n  # Check pool utilization\n  kubectl linstor storage-pool list\n  \n  # Get detailed volume information\n  kubectl linstor volume list\n  \n  # Check thin pool usage on nodes\n  kubectl -n piraeus-datastore exec -it linstor-satellite-xxxxx -- \\\n  lvs -o lv_name,vg_name,lv_size,data_percent\n  ```\n- ### 4. Maintenance Mode\n  \n  For node maintenance:\n  \n  ```\n  # Set node to maintenance\n  kubectl linstor node set-property node-1 AutoplaceTarget false\n  \n  # Evacuate resources\n  kubectl linstor resource-definition auto-place <resource> 3\n  \n  # Perform maintenance\n  # ...\n  \n  # Restore node\n  kubectl linstor node set-property node-1 AutoplaceTarget true\n  ```\n- ## Troubleshooting\n- ### Common Issues and Solutions\n- #### 1. DRBD Module Not Loading\n  \n  ```\n  # Check module status\n  lsmod | grep drbd\n  \n  # Check dmesg for errors\n  dmesg | grep -i drbd\n  \n  # Manual module load\n  sudo modprobe drbd\n  sudo modprobe drbd_transport_tcp\n  \n  # For version mismatches\n  kubectl -n piraeus-datastore logs -l app=drbd-module-loader\n  ```\n- #### 2. Storage Pool Issues\n  \n  ```\n  # Check pool status\n  kubectl linstor storage-pool list\n  \n  # Get pool errors\n  kubectl linstor error-report show\n  \n  # Check LVM on node\n  kubectl -n piraeus-datastore exec -it linstor-satellite-xxxxx -- \\\n  vgdisplay linstor_vg\n  ```\n- #### 3. PVC Stuck in Pending\n  \n  ```\n  # Check PVC events\n  kubectl describe pvc <pvc-name>\n  \n  # Check CSI driver logs\n  kubectl -n piraeus-datastore logs -l app.kubernetes.io/name=linstor-csi \\\n  -c linstor-csi-plugin\n  \n  # Check available resources\n  kubectl linstor resource list\n  kubectl linstor storage-pool list\n  ```\n- #### 4. Performance Issues\n  \n  ```\n  # Check DRBD connection status\n  kubectl linstor resource list-volumes\n  \n  # Check network latency between nodes\n  kubectl -n piraeus-datastore exec -it linstor-satellite-xxxxx -- \\\n  ping -c 10 <other-node-ip>\n  \n  # Check DRBD sync status\n  kubectl -n piraeus-datastore exec -it linstor-satellite-xxxxx -- \\\n  drbdadm status\n  ```\n- ### Debug Commands\n  \n  ```\n  # Enable debug logging\n  kubectl linstor controller set-property DebugConsole true\n  \n  # Get detailed resource information\n  kubectl linstor resource list-volumes -r <resource-name>\n  \n  # Show DRBD configuration\n  kubectl -n piraeus-datastore exec -it linstor-satellite-xxxxx -- \\\n  drbdadm dump <resource-name>\n  \n  # Check system logs\n  kubectl -n piraeus-datastore logs -l app.kubernetes.io/component=linstor-controller\n  kubectl -n piraeus-datastore logs -l app.kubernetes.io/component=linstor-satellite\n  ```\n- ## Advanced Configurations\n- ### 1. Encryption at Rest\n  \n  Enable LUKS encryption:\n  \n  ```\n  apiVersion: storage.k8s.io/v1\n  kind: StorageClass\n  metadata:\n  name: linstor-encrypted\n  provisioner: linstor.csi.linbit.com\n  parameters:\n  linstor.csi.linbit.com/storagePool: \"linstor-pool\"\n  linstor.csi.linbit.com/resourceGroup: \"encrypted\"\n  property.linstor.csi.linbit.com/Encrypted: \"true\"\n  csi.storage.k8s.io/node-stage-secret-namespace: piraeus-datastore\n  csi.storage.k8s.io/node-stage-secret-name: linstor-encryption-key\n  ```\n- ### 2. Snapshot Support\n  \n  Enable volume snapshots:\n  \n  ```\n  apiVersion: snapshot.storage.k8s.io/v1\n  kind: VolumeSnapshotClass\n  metadata:\n  name: linstor-snapshots\n  driver: linstor.csi.linbit.com\n  deletionPolicy: Delete\n  ```\n  \n  Create a snapshot:\n  \n  ```\n  apiVersion: snapshot.storage.k8s.io/v1\n  kind: VolumeSnapshot\n  metadata:\n  name: pvc-snapshot\n  spec:\n  volumeSnapshotClassName: linstor-snapshots\n  source:\n    persistentVolumeClaimName: test-pvc\n  ```\n- ### 3. Multi-Network Configuration\n  \n  For dedicated storage network:\n  \n  ```\n  apiVersion: linstor.io/v1\n  kind: LinstorSatellite\n  metadata:\n  name: storage-network\n  spec:\n  # Configure dedicated network interface for DRBD\n  properties:\n  - name: \"PrefNic\"\n    value: \"eth1\"\n  - name: \"PortRange\"\n    value: \"7000-7999\"\n  ```\n- ### 4. Performance Tuning\n  \n  System-level optimizations:\n  \n  ```\n  # CPU frequency scaling\n  echo performance | sudo tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor\n  \n  # Increase network buffers\n  sudo sysctl -w net.core.rmem_max=134217728\n  sudo sysctl -w net.core.wmem_max=134217728\n  sudo sysctl -w net.ipv4.tcp_rmem=\"4096 87380 134217728\"\n  sudo sysctl -w net.ipv4.tcp_wmem=\"4096 65536 134217728\"\n  \n  # Disable transparent huge pages\n  echo never | sudo tee /sys/kernel/mm/transparent_hugepage/enabled\n  ```\n- ## Best Practices\n- **Resource Planning**\n\t- Plan for 20-30% overhead in storage pools\n\t- Use thin provisioning for better utilization\n\t- Monitor pool usage regularly\n- **Network Configuration**\n\t- Use dedicated network for storage traffic\n\t- Enable jumbo frames (MTU 9000) if possible\n\t- Consider RDMA for ultra-low latency\n- **Security**\n\t- Enable encryption for sensitive data\n\t- Use NetworkPolicies to restrict traffic\n\t- Regular security updates\n- **Disaster Recovery**\n\t- Regular backups of LINSTOR configuration\n\t- Test restore procedures\n\t- Document runbooks\n- **Monitoring**\n\t- Set up alerts for pool utilization\n\t- Monitor DRBD sync status\n\t- Track performance metrics\n- ## Conclusion\n  \n  This guide provides a comprehensive approach to deploying LINSTOR on bare metal Kubernetes. Key takeaways:\n- Proper node preparation is crucial\n- Start simple and add complexity gradually\n- Monitor and tune based on workload requirements\n- Regular maintenance prevents issues\n  \n  For additional support and documentation:\n- [LINSTOR Documentation](https://linbit.com/drbd-user-guide/linstor-guide-1_0-en/)\n- [Piraeus Datastore GitHub](https://github.com/piraeusdatastore/piraeus-operator)\n- [LINBIT Support](https://linbit.com/support/)\n-\n\n## Current Landscape (2025)\n\n- Industry adoption and implementations\n  - Metaverse platforms continue to evolve with focus on interoperability and open standards\n  - Web3 integration accelerating with decentralised identity and asset ownership\n  - Enterprise adoption growing in virtual collaboration, training, and digital twins\n  - UK companies increasingly active in metaverse development and immersive technologies\n\n- Technical capabilities\n  - Real-time rendering at photorealistic quality levels\n  - Low-latency networking enabling seamless multi-user experiences\n  - AI-driven content generation and procedural world building\n  - Spatial audio and haptics enhancing immersion\n\n- UK and North England context\n  - Manchester: Digital Innovation Factory supports metaverse startups and research\n  - Leeds: Holovis leads in immersive experiences for entertainment and training\n  - Newcastle: University research in spatial computing and interactive systems\n  - Sheffield: Advanced manufacturing using digital twin technology\n\n- Standards and frameworks\n  - Metaverse Standards Forum driving interoperability protocols\n  - WebXR enabling browser-based immersive experiences\n  - glTF and USD for 3D asset interchange\n  - Open Metaverse Interoperability Group defining cross-platform standards\n\n## Metadata\n\n- **Last Updated**: 2025-11-16\n- **Review Status**: Automated remediation with 2025 context\n- **Verification**: Academic sources verified\n- **Regional Context**: UK/North England where applicable",
  "properties": {
    "id": "linstor-on-bare-metal-kubernetes:-complete-setup-guide-owl-axioms",
    "collapsed": "true",
    "- ontology": "true",
    "- term-id": "mv-84505038949",
    "- preferred-term": "LINSTOR on Bare Metal Kubernetes: Complete Setup Guide",
    "- source-domain": "metaverse",
    "- status": "active",
    "- public-access": "true",
    "- definition": "A component of the metaverse ecosystem focusing on linstor on bare metal kubernetes: complete setup guide.",
    "- maturity": "mature",
    "- authority-score": "0.85",
    "- owl:class": "mv:LinstorOnBareMetalKubernetesCompleteSetupGuide",
    "- owl:physicality": "ConceptualEntity",
    "- owl:role": "Concept",
    "- belongsToDomain": "[[MetaverseDomain]]",
    "- enables": "[[ImmersiveExperience]], [[Presence]], [[SpatialComputing]]",
    "- requires": "[[DisplayTechnology]], [[TrackingSystem]], [[RenderingEngine]]",
    "- bridges-to": "[[HumanComputerInteraction]], [[ComputerVision]], [[Robotics]]"
  },
  "backlinks": [],
  "wiki_links": [
    "TrackingSystem",
    "ImmersiveExperience",
    "ComputerVision",
    "RenderingEngine",
    "SpatialComputing",
    "Robotics",
    "HumanComputerInteraction",
    "MetaverseDomain",
    "DisplayTechnology",
    "Presence"
  ],
  "ontology": {
    "term_id": "mv-84505038949",
    "preferred_term": "LINSTOR on Bare Metal Kubernetes: Complete Setup Guide",
    "definition": "A component of the metaverse ecosystem focusing on linstor on bare metal kubernetes: complete setup guide.",
    "source_domain": "metaverse",
    "maturity_level": null,
    "authority_score": 0.85
  }
}