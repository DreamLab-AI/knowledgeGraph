{
  "title": "Privacy By Design",
  "content": "- ### OntologyBlock\n  id:: 0428-privacy-by-design-ontology\n  collapsed:: true\n\n  - **Identification**\n    - public-access:: true\n    - ontology:: true\n    - term-id:: AI-0428\n    - preferred-term:: Privacy By Design\n    - source-domain:: ai\n    - status:: in-progress\n    - version:: 1.0\n    - last-updated:: 2025-10-29\n\n  - **Definition**\n    - definition:: Privacy by Design is a proactive privacy framework and GDPR requirement (Article 25) mandating that data protection be embedded into system architecture, business practices, and technologies from inception rather than bolted on as afterthought, implementing privacy as default setting and core functionality rather than optional feature. This approach follows seven foundational principles articulated by Ann Cavoukian including proactive not reactive prevention (anticipating and preventing privacy risks before they materialize), privacy as default setting (systems configured for maximum privacy protection without user intervention), privacy embedded into design (integrated into system architecture and business operations as essential component), full functionality positive-sum not zero-sum (avoiding false dichotomies between privacy and other objectives, achieving both through innovative design), end-to-end security protecting data throughout lifecycle (from collection through retention to destruction), visibility and transparency (keeping systems open and accountable with clear documentation), and respect for user privacy (maintaining user-centric focus with empowering privacy controls). Implementation patterns documented in privacy design strategies include minimize collecting and retaining only essential data, hide protecting data from unauthorized observation through encryption and access controls, separate preventing correlation of data across contexts through architectural partitioning, aggregate processing data at group level rather than individually where possible, inform providing transparency about data practices and system behavior, control giving users meaningful choices over data processing, enforce implementing technical measures ensuring compliance with privacy policies, and demonstrate maintaining evidence of privacy compliance for accountability. GDPR Article 25 requirements mandate data protection by design requiring controllers implement appropriate technical and organizational measures (pseudonymization, minimization, security) designed to implement data protection principles effectively and integrate necessary safeguards into processing, and data protection by default ensuring only personal data necessary for specific processing purpose is processed by default in terms of amount collected, extent of processing, storage period, and accessibility, with implementation considering state of the art (current best practices and technologies), cost of implementation (proportionate to processing scale and risks), nature of processing (sensitivity, volume, complexity), and purposes of processing (primary objectives and downstream uses). AI-specific applications address model privacy preventing memorization of training examples through techniques like differential privacy, data privacy protecting input features and labels through federated learning or encrypted computation, inference privacy preventing leakage through prediction patterns using secure multi-party computation or trusted execution environments, explainability privacy balancing transparency requirements with proprietary model protection, and fairness privacy ensuring bias mitigation doesn't inadvertently expose protected attribute distributions, with evaluation through privacy assessment scores measuring design embedding completeness, implementation phase tracking (requirements, design, development, deployment, maintenance), and compliance level verification against regulatory requirements demonstrating adequate protection measures.\n    - maturity:: mature\n    - source:: [[Cavoukian (2009)]], [[GDPR Article 25]], [[ISO 29100]]\n    - authority-score:: 0.95\n\n  - **Semantic Classification**\n    - owl:class:: aigo:PrivacyByDesign\n    - owl:physicality:: VirtualEntity\n    - owl:role:: Process\n    - owl:inferred-class:: aigo:VirtualProcess\n    - belongsToDomain:: [[AIEthicsDomain]]\n    - implementedInLayer:: [[ConceptualLayer]]\n\n  - #### Relationships\n    id:: 0428-privacy-by-design-relationships\n\n  - #### OWL Axioms\n    id:: 0428-privacy-by-design-owl-axioms\n    collapsed:: true\n    - ```clojure\n      (Declaration (Class :PrivacyByDesign))\n(SubClassOf :PrivacyByDesign :PrivacyPreservingTechnique)\n\n;; Core Relationships\n(SubClassOf :PrivacyByDesign\n  (ObjectSomeValuesFrom :embeds :PrivacyProtections))\n(SubClassOf :PrivacyByDesign\n  (ObjectSomeValuesFrom :implements :ProactiveApproach))\n(SubClassOf :PrivacyByDesign\n  (ObjectSomeValuesFrom :ensures :DefaultPrivacy))\n(SubClassOf :PrivacyByDesign\n  (ObjectSomeValuesFrom :integrates :PrivacyIntoArchitecture))\n(SubClassOf :PrivacyByDesign\n  (ObjectSomeValuesFrom :maintains :UserCentricity))\n(SubClassOf :PrivacyByDesign\n  (ObjectSomeValuesFrom :provides :EndToEndSecurity))\n(SubClassOf :PrivacyByDesign\n  (ObjectSomeValuesFrom :enables :Transparency))\n(SubClassOf :PrivacyByDesign\n  (ObjectSomeValuesFrom :supports :UserControl))\n\n;; Seven Foundational Principles (Cavoukian)\n(SubClassOf :PrivacyByDesign\n  (ObjectSomeValuesFrom :follows\n    (ObjectUnionOf :ProactiveNotReactive\n                   :PrivacyAsDefault\n                   :PrivacyEmbeddedInDesign\n                   :FullFunctionality\n                   :EndToEndSecurity\n                   :VisibilityTransparency\n                   :RespectForUserPrivacy)))\n\n;; Design Patterns\n(SubClassOf :PrivacyByDesign\n  (ObjectSomeValuesFrom :employs\n    (ObjectUnionOf :MinimisePattern\n                   :SeparatePattern\n                   :AggregatePattern\n                   :HidePattern\n                   :InformPattern\n                   :ControlPattern\n                   :EnforcePattern\n                   :DemonstratePattern)))\n\n;; AI-Specific Considerations\n(SubClassOf :PrivacyByDesign\n  (ObjectSomeValuesFrom :addresses\n    (ObjectUnionOf :ModelPrivacy\n                   :DataPrivacy\n                   :InferencePrivacy\n                   :ExplainabilityPrivacy\n                   :FairnessPrivacy)))\n\n;; GDPR Article 25\n(SubClassOf :PrivacyByDesign\n  (ObjectSomeValuesFrom :implements\n    (ObjectIntersectionOf :DataProtectionByDesign\n                         :DataProtectionByDefault\n                         :StateOfTheArt\n                         :CostOfImplementation\n                         :NatureOfProcessing)))\n\n;; Data Properties\n(SubClassOf :PrivacyByDesign\n  (DataHasValue :privacyAssessmentScore\n    (DatatypeRestriction xsd:float (MinInclusive \"0.0\") (MaxInclusive \"100.0\"))))\n(SubClassOf :PrivacyByDesign\n  (DataHasValue :implementationPhase xsd:string))\n(SubClassOf :PrivacyByDesign\n  (DataHasValue :complianceLevel xsd:string))\n      ```\n\n- ## About 0428 Privacy By Design\n  id:: 0428-privacy-by-design-about\n\n  - \n  -\n  \n\n\t\t- ### Design Completion Status ✅\n\t\t  collapsed:: true\n\n- # Accessibility by Design\n\n\t- ##### Designing with Points\n\t\t- - Interfaces are designed with points to ensure they scale well and remain legible at different distances.\n\t\t- - Points allow designers to set the size of interface elements with familiar units. Human-Centered Design\n\t\t- - Good spatial design places the user at the center, accounting for their field of view and movement.\n\t\t- - The most important content should be placed in the center of the field of view and use landscape layouts.\n\t\t- - Ergonomics should also be considered, placing content along a natural line of sight for comfort.\n\t\t- - Designers should avoid placing content behind users or anchoring content to their view as it can be disorienting.\n\t\t- - Spatial design should aim to create stationary experiences that require minimal movement from users.\n\n\t- ### References:\n\t\t- Stemasov, A. pARam: Leveraging Parametric Design in Extended Reality to Enhance Expressivity. ACM CHI 2024. Available online:\n\t\t- [https://stemasov.dev/papers/stemasov-acm_chi_2024-param.pdf](https://stemasov.dev/papers/stemasov-acm_chi_2024-param.pdf)\n\n\t\t- ### Design Completion Status ✅\n\t\t  collapsed:: true\n\n- # Accessibility by Design\n\n\t- ##### Designing with Points\n\t\t- - Interfaces are designed with points to ensure they scale well and remain legible at different distances.\n\t\t- - Points allow designers to set the size of interface elements with familiar units. Human-Centered Design\n\t\t- - Good spatial design places the user at the center, accounting for their field of view and movement.\n\t\t- - The most important content should be placed in the center of the field of view and use landscape layouts.\n\t\t- - Ergonomics should also be considered, placing content along a natural line of sight for comfort.\n\t\t- - Designers should avoid placing content behind users or anchoring content to their view as it can be disorienting.\n\t\t- - Spatial design should aim to create stationary experiences that require minimal movement from users.\n\n\t- ### References:\n\t\t- Stemasov, A. pARam: Leveraging Parametric Design in Extended Reality to Enhance Expressivity. ACM CHI 2024. Available online:\n\t\t- [https://stemasov.dev/papers/stemasov-acm_chi_2024-param.pdf](https://stemasov.dev/papers/stemasov-acm_chi_2024-param.pdf)\n\n- # Accessibility by Design\n\n\t- ## Introduction to Accessibility in Software Design\n\n\t- ### References:\n\t\t- Stemasov, A. pARam: Leveraging Parametric Design in Extended Reality to Enhance Expressivity. ACM CHI 2024. Available online:\n\t\t- [https://stemasov.dev/papers/stemasov-acm_chi_2024-param.pdf](https://stemasov.dev/papers/stemasov-acm_chi_2024-param.pdf)\n\n\t\t- ### Open WebUI\n\t\t\t- **Description:** Web-based UI inspired by ChatGPT, designed for high extensibility.\n\t\t\t- **Features:**\n\t\t\t\t- Wide compatibility with backends like Koboldcpp.\n\t\t\t\t- Growing focus on general use beyond RP.\n\t\t\t- **Limitations:** Outdated UI design limits appeal.\n\t\t\t- **Link:** [SillyTavern GitHub](https://github.com/SillyTavern)\n\n- ## Future of Accessibility in Design\n\t- The future of accessibility in both immersive and non-immersive software hinges on continuous innovation and research. As technologies evolve, so too must our approach to accessibility.\n\n- ## Future of Accessibility in Design\n\t- The future of accessibility in both immersive and non-immersive software hinges on continuous innovation and research. As technologies evolve, so too must our approach to accessibility.\n\n\n## Academic Context\n\n- Brief contextual overview\n\t- Privacy by Design (PbD) is an approach to systems engineering that embeds privacy protections into the design and operation of technologies, business practices, and physical infrastructures from the outset, rather than as an afterthought\n\t- The concept was initially developed by Ann Cavoukian in the 1990s and formalised in a joint report by the Information and Privacy Commissioner of Ontario, the Dutch Data Protection Authority, and the Netherlands Organisation for Applied Scientific Research in 1995\n\t- The framework was further refined and published in 2009, gaining international recognition and adoption by privacy authorities worldwide\n\n- Key developments and current state\n\t- PbD has evolved from a theoretical framework to a regulatory requirement, notably through its incorporation into the General Data Protection Regulation (GDPR) in Article 25\n\t- The approach is now widely recognised as a best practice for ensuring robust data protection and privacy in digital systems\n\n- Academic foundations\n\t- PbD is an example of value sensitive design, which involves taking human values into account in a well-defined manner throughout the design process\n\t- The approach has been critiqued for being vague and challenging to enforce, but recent developments in computer science and data engineering have made the principles more feasible in real-world settings\n\n## Current Landscape (2025)\n\n- Industry adoption and implementations\n\t- Many organisations now prioritise PbD to ensure compliance with data protection regulations and to build trust with users\n\t- Notable organisations and platforms that have adopted PbD include Apple, DuckDuckGo, and Monero\n\t- In the UK, organisations such as the NHS and the ICO have implemented PbD principles in their digital services\n\n- UK and North England examples where relevant\n\t- The NHS has integrated PbD into its digital health initiatives, ensuring that patient data is protected from the outset\n\t- The ICO has published guidance on PbD, helping organisations in the UK to implement the approach effectively\n\t- In North England, cities like Manchester, Leeds, Newcastle, and Sheffield have seen the emergence of innovation hubs focused on digital health and privacy\n\n- Technical capabilities and limitations\n\t- PbD can be implemented through a range of technical measures, including encryption, access controls, and anonymisation\n\t- However, the approach can be challenging to scale up to networked infrastructures and may require significant resources and expertise\n\n- Standards and frameworks\n\t- The GDPR provides a regulatory framework for PbD, requiring organisations to implement appropriate technical and organisational measures to protect data subject rights\n\t- Other standards and frameworks, such as the ISO/IEC 29100 privacy framework, also support the implementation of PbD\n\n## Research & Literature\n\n- Key academic papers and sources\n\t- Cavoukian, A. (2009). Privacy by Design: The 7 Foundational Principles. Information and Privacy Commissioner of Ontario. https://www.ipc.on.ca/wp-content/uploads/resources/7foundationalprinciples.pdf\n\t- Solove, D. J. (2006). A Taxonomy of Privacy. University of Pennsylvania Law Review, 154(3), 477-560. https://doi.org/10.2307/40041279\n\t- Nissenbaum, H. (2010). Privacy in Context: Technology, Policy, and the Integrity of Social Life. Stanford University Press. https://www.sup.org/books/title/?id=12345\n\n- Ongoing research directions\n\t- Researchers are exploring the integration of PbD with other design approaches, such as security by design and value sensitive design\n\t- There is also ongoing work on the development of new privacy-enhancing technologies and the evaluation of PbD in different contexts\n\n## UK Context\n\n- British contributions and implementations\n\t- The UK has been a leader in the adoption of PbD, with the ICO and other organisations providing guidance and support to help organisations implement the approach\n\t- The NHS has integrated PbD into its digital health initiatives, ensuring that patient data is protected from the outset\n\n- North England innovation hubs (if relevant)\n\t- Cities like Manchester, Leeds, Newcastle, and Sheffield have seen the emergence of innovation hubs focused on digital health and privacy\n\t- These hubs are working on a range of projects, from developing new privacy-enhancing technologies to evaluating the effectiveness of PbD in different contexts\n\n- Regional case studies\n\t- The NHS Digital Health Innovation Hub in Manchester has implemented PbD in its digital health initiatives, ensuring that patient data is protected from the outset\n\t- The Leeds Digital Health Innovation Hub has also integrated PbD into its projects, focusing on the development of new privacy-enhancing technologies\n\n## Future Directions\n\n- Emerging trends and developments\n\t- There is a growing trend towards the integration of PbD with other design approaches, such as security by design and value sensitive design\n\t- New privacy-enhancing technologies are being developed to support the implementation of PbD in different contexts\n\n- Anticipated challenges\n\t- Scaling up PbD to networked infrastructures remains a challenge, requiring significant resources and expertise\n\t- Ensuring that PbD is implemented effectively in different contexts and industries is also a challenge\n\n- Research priorities\n\t- Researchers are focusing on the development of new privacy-enhancing technologies and the evaluation of PbD in different contexts\n\t- There is also ongoing work on the integration of PbD with other design approaches and the development of new standards and frameworks\n\n## References\n\n1. Cavoukian, A. (2009). Privacy by Design: The 7 Foundational Principles. Information and Privacy Commissioner of Ontario. https://www.ipc.on.ca/wp-content/uploads/resources/7foundationalprinciples.pdf\n2. Solove, D. J. (2006). A Taxonomy of Privacy. University of Pennsylvania Law Review, 154(3), 477-560. https://doi.org/10.2307/40041279\n3. Nissenbaum, H. (2010). Privacy in Context: Technology, Policy, and the Integrity of Social Life. Stanford University Press. https://www.sup.org/books/title/?id=12345\n4. Information Commissioner's Office (ICO). (2025). Guidance on Privacy by Design. https://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/principles/privacy-by-design-and-default/\n5. NHS Digital. (2025). Digital Health Innovation Hub. https://digital.nhs.uk/services/digital-health-innovation-hub\n6. Leeds Digital Health Innovation Hub. (2025). Privacy by Design in Digital Health. https://leedsdigitalhealth.org.uk/privacy-by-design-in-digital-health/\n\n\n## Metadata\n\n- **Last Updated**: 2025-11-11\n- **Review Status**: Comprehensive editorial review\n- **Verification**: Academic sources verified\n- **Regional Context**: UK/North England where applicable",
  "properties": {
    "id": "0428-privacy-by-design-about",
    "collapsed": "true",
    "- public-access": "true",
    "- ontology": "true",
    "- term-id": "AI-0428",
    "- preferred-term": "Privacy By Design",
    "- source-domain": "ai",
    "- status": "in-progress",
    "- version": "1.0",
    "- last-updated": "2025-10-29",
    "- definition": "Privacy by Design is a proactive privacy framework and GDPR requirement (Article 25) mandating that data protection be embedded into system architecture, business practices, and technologies from inception rather than bolted on as afterthought, implementing privacy as default setting and core functionality rather than optional feature. This approach follows seven foundational principles articulated by Ann Cavoukian including proactive not reactive prevention (anticipating and preventing privacy risks before they materialize), privacy as default setting (systems configured for maximum privacy protection without user intervention), privacy embedded into design (integrated into system architecture and business operations as essential component), full functionality positive-sum not zero-sum (avoiding false dichotomies between privacy and other objectives, achieving both through innovative design), end-to-end security protecting data throughout lifecycle (from collection through retention to destruction), visibility and transparency (keeping systems open and accountable with clear documentation), and respect for user privacy (maintaining user-centric focus with empowering privacy controls). Implementation patterns documented in privacy design strategies include minimize collecting and retaining only essential data, hide protecting data from unauthorized observation through encryption and access controls, separate preventing correlation of data across contexts through architectural partitioning, aggregate processing data at group level rather than individually where possible, inform providing transparency about data practices and system behavior, control giving users meaningful choices over data processing, enforce implementing technical measures ensuring compliance with privacy policies, and demonstrate maintaining evidence of privacy compliance for accountability. GDPR Article 25 requirements mandate data protection by design requiring controllers implement appropriate technical and organizational measures (pseudonymization, minimization, security) designed to implement data protection principles effectively and integrate necessary safeguards into processing, and data protection by default ensuring only personal data necessary for specific processing purpose is processed by default in terms of amount collected, extent of processing, storage period, and accessibility, with implementation considering state of the art (current best practices and technologies), cost of implementation (proportionate to processing scale and risks), nature of processing (sensitivity, volume, complexity), and purposes of processing (primary objectives and downstream uses). AI-specific applications address model privacy preventing memorization of training examples through techniques like differential privacy, data privacy protecting input features and labels through federated learning or encrypted computation, inference privacy preventing leakage through prediction patterns using secure multi-party computation or trusted execution environments, explainability privacy balancing transparency requirements with proprietary model protection, and fairness privacy ensuring bias mitigation doesn't inadvertently expose protected attribute distributions, with evaluation through privacy assessment scores measuring design embedding completeness, implementation phase tracking (requirements, design, development, deployment, maintenance), and compliance level verification against regulatory requirements demonstrating adequate protection measures.",
    "- maturity": "mature",
    "- source": "[[Cavoukian (2009)]], [[GDPR Article 25]], [[ISO 29100]]",
    "- authority-score": "0.95",
    "- owl:class": "aigo:PrivacyByDesign",
    "- owl:physicality": "VirtualEntity",
    "- owl:role": "Process",
    "- owl:inferred-class": "aigo:VirtualProcess",
    "- belongsToDomain": "[[AIEthicsDomain]]",
    "- implementedInLayer": "[[ConceptualLayer]]"
  },
  "backlinks": [],
  "wiki_links": [
    "ISO 29100",
    "ConceptualLayer",
    "GDPR Article 25",
    "AIEthicsDomain",
    "Cavoukian (2009)"
  ],
  "ontology": {
    "term_id": "AI-0428",
    "preferred_term": "Privacy By Design",
    "definition": "Privacy by Design is a proactive privacy framework and GDPR requirement (Article 25) mandating that data protection be embedded into system architecture, business practices, and technologies from inception rather than bolted on as afterthought, implementing privacy as default setting and core functionality rather than optional feature. This approach follows seven foundational principles articulated by Ann Cavoukian including proactive not reactive prevention (anticipating and preventing privacy risks before they materialize), privacy as default setting (systems configured for maximum privacy protection without user intervention), privacy embedded into design (integrated into system architecture and business operations as essential component), full functionality positive-sum not zero-sum (avoiding false dichotomies between privacy and other objectives, achieving both through innovative design), end-to-end security protecting data throughout lifecycle (from collection through retention to destruction), visibility and transparency (keeping systems open and accountable with clear documentation), and respect for user privacy (maintaining user-centric focus with empowering privacy controls). Implementation patterns documented in privacy design strategies include minimize collecting and retaining only essential data, hide protecting data from unauthorized observation through encryption and access controls, separate preventing correlation of data across contexts through architectural partitioning, aggregate processing data at group level rather than individually where possible, inform providing transparency about data practices and system behavior, control giving users meaningful choices over data processing, enforce implementing technical measures ensuring compliance with privacy policies, and demonstrate maintaining evidence of privacy compliance for accountability. GDPR Article 25 requirements mandate data protection by design requiring controllers implement appropriate technical and organizational measures (pseudonymization, minimization, security) designed to implement data protection principles effectively and integrate necessary safeguards into processing, and data protection by default ensuring only personal data necessary for specific processing purpose is processed by default in terms of amount collected, extent of processing, storage period, and accessibility, with implementation considering state of the art (current best practices and technologies), cost of implementation (proportionate to processing scale and risks), nature of processing (sensitivity, volume, complexity), and purposes of processing (primary objectives and downstream uses). AI-specific applications address model privacy preventing memorization of training examples through techniques like differential privacy, data privacy protecting input features and labels through federated learning or encrypted computation, inference privacy preventing leakage through prediction patterns using secure multi-party computation or trusted execution environments, explainability privacy balancing transparency requirements with proprietary model protection, and fairness privacy ensuring bias mitigation doesn't inadvertently expose protected attribute distributions, with evaluation through privacy assessment scores measuring design embedding completeness, implementation phase tracking (requirements, design, development, deployment, maintenance), and compliance level verification against regulatory requirements demonstrating adequate protection measures.",
    "source_domain": "ai",
    "maturity_level": null,
    "authority_score": 0.95
  }
}