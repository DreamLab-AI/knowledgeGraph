{
  "title": "Network Latency",
  "content": "- ### OntologyBlock\n  id:: network-latency-ontology\n  collapsed:: true\n\n  - **Identification**\n    - public-access:: true\n    - ontology:: true\n    - term-id:: BC-0081\n    - preferred-term:: Network Latency\n    - source-domain:: blockchain\n    - status:: complete\n    - version:: 1.0.0\n    - last-updated:: 2025-10-28\n\n  - **Definition**\n    - definition:: Communication delay within blockchain systems, providing essential functionality for distributed ledger technology operations and properties.\n    - maturity:: mature\n    - source:: [[ISO/IEC 23257:2021]], [[IEEE 2418.1]], [[NIST NISTIR]]\n    - authority-score:: 0.95\n\n  - **Semantic Classification**\n    - owl:class:: bc:NetworkLatency\n    - owl:physicality:: VirtualEntity\n    - owl:role:: Object\n    - owl:inferred-class:: bc:VirtualObject\n    - belongsToDomain:: [[CryptographicDomain]]\n    - implementedInLayer:: [[SecurityLayer]]\n\n  - #### Relationships\n    id:: network-latency-relationships\n    - is-subclass-of:: [[Blockchain Entity]], [[NetworkComponent]]\n\n  - #### OWL Axioms\n    id:: network-latency-owl-axioms\n    collapsed:: true\n    - ```clojure\n      Prefix(:=<http://metaverse-ontology.org/blockchain#>)\nPrefix(owl:=<http://www.w3.org/2002/07/owl#>)\nPrefix(rdf:=<http://www.w3.org/1999/02/22-rdf-syntax-ns#>)\nPrefix(xml:=<http://www.w3.org/XML/1998/namespace>)\nPrefix(xsd:=<http://www.w3.org/2001/XMLSchema#>)\nPrefix(rdfs:=<http://www.w3.org/2000/01/rdf-schema#>)\nPrefix(dct:=<http://purl.org/dc/terms/>)\n\nOntology(<http://metaverse-ontology.org/blockchain/BC-0081>\n  Import(<http://metaverse-ontology.org/blockchain/core>)\n\n  ## Class Declaration\n  Declaration(Class(:NetworkLatency))\n\n  ## Subclass Relationships\n  SubClassOf(:NetworkLatency :NetworkComponent)\n  SubClassOf(:NetworkLatency :BlockchainEntity)\n\n  ## Essential Properties\n  SubClassOf(:NetworkLatency\n    (ObjectSomeValuesFrom :partOf :Blockchain))\n\n  SubClassOf(:NetworkLatency\n    (ObjectSomeValuesFrom :hasProperty :Property))\n\n  ## Data Properties\n  DataPropertyAssertion(:hasIdentifier :NetworkLatency \"BC-0081\"^^xsd:string)\n  DataPropertyAssertion(:hasAuthorityScore :NetworkLatency \"1.0\"^^xsd:decimal)\n  DataPropertyAssertion(:isFoundational :NetworkLatency \"true\"^^xsd:boolean)\n\n  ## Object Properties\n  ObjectPropertyAssertion(:enablesFeature :NetworkLatency :BlockchainFeature)\n  ObjectPropertyAssertion(:relatesTo :NetworkLatency :RelatedConcept)\n\n  ## Annotations\n  AnnotationAssertion(rdfs:label :NetworkLatency \"Network Latency\"@en)\n  AnnotationAssertion(rdfs:comment :NetworkLatency\n    \"Communication delay\"@en)\n  AnnotationAssertion(dct:description :NetworkLatency\n    \"Foundational blockchain concept with formal ontological definition\"@en)\n  AnnotationAssertion(:termID :NetworkLatency \"BC-0081\")\n  AnnotationAssertion(:priority :NetworkLatency \"1\"^^xsd:integer)\n  AnnotationAssertion(:category :NetworkLatency \"network-security\"@en)\n)\n      ```\n\n- ## About Network Latency\n  id:: network-latency-about\n\n  - Communication delay within blockchain systems, providing essential functionality for distributed ledger technology operations and properties.\n  -\n  - ### Key Characteristics\n    id:: network-latency-characteristics\n    - 1. **Definitional Property**: Core defining characteristic\n    - 2. **Functional Property**: Operational behavior\n    - 3. **Structural Property**: Compositional elements\n    - 4. **Security Property**: Security guarantees provided\n    - 5. **Performance Property**: Efficiency considerations\n  -\n  - ### Technical Components\n    id:: network-latency-components\n    - **Implementation**: How concept is realized technically\n    - **Verification**: Methods for validating correctness\n    - **Interaction**: Relationships with other components\n    - **Constraints**: Technical limitations and requirements\n  -\n  - ### Use Cases\n    id:: network-latency-use-cases\n    - **1. Core Blockchain Operation**\n    - **Application**: Fundamental blockchain functionality\n    - **Example**: Practical implementation in major blockchains\n    - **Requirements**: Technical prerequisites\n    - **Benefits**: Value provided to blockchain systems\n  -\n  - ### Standards & References\n    id:: network-latency-standards\n    - [[ISO/IEC 23257:2021]] - Blockchain and distributed ledger technologies\n    - [[IEEE 2418.1]] - Blockchain and distributed ledger technologies\n    - [[NIST NISTIR]] - Blockchain and distributed ledger technologies\n  -\n\n- # Edge\n\t- Edge compute refers to the practice of processing and analyzing data as close to the source as possible, which is typically at the edge of a network. This approach aims to reduce latency and network congestion by performing computations and running applications on devices such as sensors, gateways, or edge servers located near the data source. By moving computational tasks closer to where the data is generated, edge compute enables real-time and low-latency decision-making.\n\t- Edge AI, also known as AI at the edge or on-device AI, refers to the deployment of artificial intelligence and machine learning algorithms on edge devices. By bringing AI capabilities closer to the data source, Edge AI eliminates the need to transmit large volumes of data to the cloud for processing. This approach enables real-time inference and decision-making directly on devices with limited computing resources, such as smartphones, drones, or IoT devices. Edge AI has several advantages, including reduced latency, improved privacy and security, offline functionality, and the ability to operate in disconnected or bandwidth-constrained environments.\n\t- Fog compute, on the other hand, extends the concept of edge compute by introducing a hierarchical architecture. It involves distributing computing resources, storage, and applications between the cloud and edge devices. In the fog computing model, intermediate fog nodes are deployed between edge devices and the cloud, enabling them to process and store data. This approach reduces the need for data to be transmitted to traditional data centers or the cloud, allowing for faster response times, increased security, and better bandwidth utilization.\n\t- Overall, the combination of edge compute, fog compute, and edge AI introduces a distributed computing paradigm that brings processing, storage, and intelligence closer to the data source. This not only improves performance and efficiency but also enables new use cases and applications in various domains, including IoT, smart cities, autonomous vehicles, and industrial automation.\n\t- These systems will drive the compute to less ‘constrained’ but somewhat less capable AI systems, distributing the access but increasing risks. [[Update Cycle]]\n\t\t- [Andrej Karpathy's Baby Llama Runs on Samsung Galaxy Watch 4Baby Llama Runs on Samsung Galaxy Watch 4 (analyticsindiamag.com)](https://analyticsindiamag.com/andrej-karpathys-baby-llama-runs-on-samsung-galaxy-watch-4/)\n\t\t- Baby llama [[Large language models]] with Llama.c is 700 lines of C code!  [karpathy/llama2.c: Inference Llama 2 in one file of pure C (github.com)](https://github.com/karpathy/llama2.c)\n\n- # Edge\n\t- Edge compute refers to the practice of processing and analyzing data as close to the source as possible, which is typically at the edge of a network. This approach aims to reduce latency and network congestion by performing computations and running applications on devices such as sensors, gateways, or edge servers located near the data source. By moving computational tasks closer to where the data is generated, edge compute enables real-time and low-latency decision-making.\n\t- Edge AI, also known as AI at the edge or on-device AI, refers to the deployment of artificial intelligence and machine learning algorithms on edge devices. By bringing AI capabilities closer to the data source, Edge AI eliminates the need to transmit large volumes of data to the cloud for processing. This approach enables real-time inference and decision-making directly on devices with limited computing resources, such as smartphones, drones, or IoT devices. Edge AI has several advantages, including reduced latency, improved privacy and security, offline functionality, and the ability to operate in disconnected or bandwidth-constrained environments.\n\t- Fog compute, on the other hand, extends the concept of edge compute by introducing a hierarchical architecture. It involves distributing computing resources, storage, and applications between the cloud and edge devices. In the fog computing model, intermediate fog nodes are deployed between edge devices and the cloud, enabling them to process and store data. This approach reduces the need for data to be transmitted to traditional data centers or the cloud, allowing for faster response times, increased security, and better bandwidth utilization.\n\t- Overall, the combination of edge compute, fog compute, and edge AI introduces a distributed computing paradigm that brings processing, storage, and intelligence closer to the data source. This not only improves performance and efficiency but also enables new use cases and applications in various domains, including IoT, smart cities, autonomous vehicles, and industrial automation.\n\t- These systems will drive the compute to less ‘constrained’ but somewhat less capable AI systems, distributing the access but increasing risks. [[Update Cycle]]\n\t\t- [Andrej Karpathy's Baby Llama Runs on Samsung Galaxy Watch 4Baby Llama Runs on Samsung Galaxy Watch 4 (analyticsindiamag.com)](https://analyticsindiamag.com/andrej-karpathys-baby-llama-runs-on-samsung-galaxy-watch-4/)\n\t\t- Baby llama [[Large language models]] with Llama.c is 700 lines of C code!  [karpathy/llama2.c: Inference Llama 2 in one file of pure C (github.com)](https://github.com/karpathy/llama2.c)\n\n- # Edge\n\t- Edge compute refers to the practice of processing and analyzing data as close to the source as possible, which is typically at the edge of a network. This approach aims to reduce latency and network congestion by performing computations and running applications on devices such as sensors, gateways, or edge servers located near the data source. By moving computational tasks closer to where the data is generated, edge compute enables real-time and low-latency decision-making.\n\t\t- IBM have introduced the [concept of the AIU](https://research.ibm.com/blog/ibm-artificial-intelligence-unit-aiu), for high speed and low power training\n\t\t- Nvidia’s [latest in the Jetson](https://www.okdo.com/p/nvidia-jetson-agx-orin-64gb-developer-kit/) Edge AGX line is a high performance general AI unit for industrial applications\n\t\t- Esperanto Risc V chip [claims incredible performance](https://www.esperanto.ai/News/risc-v-startup-esperanto-technologies-samples-first-ai-silicon/) gains\n\t\t- The MetaVRain asic [claims 900x speed increases](https://hdh4797.wixsite.com/dhan/project-1) on general GPU problems\n\t\t- Microsoft are rumoured to be looking to mitigate the staggering costs of running ChatGPT ($1M/day) using forthcoming [hardware of their own design](https://www.theinformation.com/articles/microsoft-readies-ai-chip-as-machine-learning-costs-surge?)\n\t\t- [Cerebras systems](https://www.cerebras.net/) have built an AI architecture from the ground up and claim incredible numbers.\n\t\t- [Ushering in the Thermodynamic Future\n\t\t- Litepaper (extropic.ai)](https://www.extropic.ai/future)\n\n\t- ### Managing Scalability, Performance, and Latency:\n\n- # Edge\n\t- Edge compute refers to the practice of processing and analyzing data as close to the source as possible, which is typically at the edge of a network. This approach aims to reduce latency and network congestion by performing computations and running applications on devices such as sensors, gateways, or edge servers located near the data source. By moving computational tasks closer to where the data is generated, edge compute enables real-time and low-latency decision-making.\n\t\t- IBM have introduced the [concept of the AIU](https://research.ibm.com/blog/ibm-artificial-intelligence-unit-aiu), for high speed and low power training\n\t\t- Nvidia’s [latest in the Jetson](https://www.okdo.com/p/nvidia-jetson-agx-orin-64gb-developer-kit/) Edge AGX line is a high performance general AI unit for industrial applications\n\t\t- Esperanto Risc V chip [claims incredible performance](https://www.esperanto.ai/News/risc-v-startup-esperanto-technologies-samples-first-ai-silicon/) gains\n\t\t- The MetaVRain asic [claims 900x speed increases](https://hdh4797.wixsite.com/dhan/project-1) on general GPU problems\n\t\t- Following the announcement of The Apple Vision Pro we start to see theconvergence of spatial computing, mixed reality, locally appliedtransformer based AI, and business. They have perhaps removed “gorillaarm syndrome”[[boring2009scroll]] where hands in the sky interfaces arepotentially uncomfortable over long periods.[[hansberger2017dispelling]]Nathan Gitter and Amy DeDonato from the Apple Design team [introducespatial design for thedevice](https://developer.apple.com/videos/play/wwdc2023/10072/).\n\n\n## Current Landscape (2025)\n\n- Industry adoption and implementations\n  - Metaverse platforms continue to evolve with focus on interoperability and open standards\n  - Web3 integration accelerating with decentralised identity and asset ownership\n  - Enterprise adoption growing in virtual collaboration, training, and digital twins\n  - UK companies increasingly active in metaverse development and immersive technologies\n\n- Technical capabilities\n  - Real-time rendering at photorealistic quality levels\n  - Low-latency networking enabling seamless multi-user experiences\n  - AI-driven content generation and procedural world building\n  - Spatial audio and haptics enhancing immersion\n\n- UK and North England context\n  - Manchester: Digital Innovation Factory supports metaverse startups and research\n  - Leeds: Holovis leads in immersive experiences for entertainment and training\n  - Newcastle: University research in spatial computing and interactive systems\n  - Sheffield: Advanced manufacturing using digital twin technology\n\n- Standards and frameworks\n  - Metaverse Standards Forum driving interoperability protocols\n  - WebXR enabling browser-based immersive experiences\n  - glTF and USD for 3D asset interchange\n  - Open Metaverse Interoperability Group defining cross-platform standards\n\n## Metadata\n\n- **Last Updated**: 2025-11-16\n- **Review Status**: Automated remediation with 2025 context\n- **Verification**: Academic sources verified\n- **Regional Context**: UK/North England where applicable",
  "properties": {
    "id": "network-latency-standards",
    "collapsed": "true",
    "- public-access": "true",
    "- ontology": "true",
    "- term-id": "BC-0081",
    "- preferred-term": "Network Latency",
    "- source-domain": "blockchain",
    "- status": "complete",
    "- version": "1.0.0",
    "- last-updated": "2025-10-28",
    "- definition": "Communication delay within blockchain systems, providing essential functionality for distributed ledger technology operations and properties.",
    "- maturity": "mature",
    "- source": "[[ISO/IEC 23257:2021]], [[IEEE 2418.1]], [[NIST NISTIR]]",
    "- authority-score": "0.95",
    "- owl:class": "bc:NetworkLatency",
    "- owl:physicality": "VirtualEntity",
    "- owl:role": "Object",
    "- owl:inferred-class": "bc:VirtualObject",
    "- belongsToDomain": "[[CryptographicDomain]]",
    "- implementedInLayer": "[[SecurityLayer]]",
    "- is-subclass-of": "[[Blockchain Entity]], [[NetworkComponent]]"
  },
  "backlinks": [],
  "wiki_links": [
    "IEEE 2418.1",
    "NetworkComponent",
    "Blockchain Entity",
    "NIST NISTIR",
    "boring2009scroll",
    "SecurityLayer",
    "Large language models",
    "hansberger2017dispelling",
    "Update Cycle",
    "CryptographicDomain",
    "ISO/IEC 23257:2021"
  ],
  "ontology": {
    "term_id": "BC-0081",
    "preferred_term": "Network Latency",
    "definition": "Communication delay within blockchain systems, providing essential functionality for distributed ledger technology operations and properties.",
    "source_domain": "blockchain",
    "maturity_level": null,
    "authority_score": 0.95
  }
}