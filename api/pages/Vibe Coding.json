{
  "title": "Vibe Coding",
  "content": "- ### OntologyBlock\n  id:: vibe-coding-ontology\n  collapsed:: true\n\t- ontology:: true\n\t- term-id:: mv-200277278747\n\t- preferred-term:: Vibe Coding\n\t- source-domain:: metaverse\n\t- status:: active\n\t- public-access:: true\n\t- definition:: A component of the metaverse ecosystem focusing on vibe coding.\n\t- maturity:: mature\n\t- authority-score:: 0.85\n\t- owl:class:: mv:VibeCoding\n\t- owl:physicality:: ConceptualEntity\n\t- owl:role:: Concept\n\t- belongsToDomain:: [[MetaverseDomain]]\n\t- #### Relationships\n\t  id:: vibe-coding-relationships\n\t\t- enables:: [[ImmersiveExperience]], [[Presence]], [[SpatialComputing]]\n\t\t- requires:: [[DisplayTechnology]], [[TrackingSystem]], [[RenderingEngine]]\n\t\t- bridges-to:: [[HumanComputerInteraction]], [[ComputerVision]], [[Robotics]]\n\n\t- #### OWL Axioms\n\t  id:: vibe-coding-owl-axioms\n\t  collapsed:: true\n\t\t- ```clojure\n\t\t  Declaration(Class(mv:VibeCoding))\n\n\t\t  # Classification\n\t\t  SubClassOf(mv:VibeCoding mv:ConceptualEntity)\n\t\t  SubClassOf(mv:VibeCoding mv:Concept)\n\n\t\t  # Domain classification\n\t\t  SubClassOf(mv:VibeCoding\n\t\t    ObjectSomeValuesFrom(mv:belongsToDomain mv:MetaverseDomain)\n\t\t  )\n\n\t\t  # Annotations\n\t\t  AnnotationAssertion(rdfs:label mv:VibeCoding \"Vibe Coding\"@en)\n\t\t  AnnotationAssertion(rdfs:comment mv:VibeCoding \"A component of the metaverse ecosystem focusing on vibe coding.\"@en)\n\t\t  AnnotationAssertion(dcterms:identifier mv:VibeCoding \"mv-200277278747\"^^xsd:string)\n\t\t  ```\n\n- Start like a Project Manager, not a Prompt Monkey\n  \n  Before you do anything, write a real PRD.\n  \n  ‚Ä¢ Describe what you‚Äôre building, why, and with what tools (Supabase, Vercel, GitHub, etc.) ‚Ä¢ Keep it in your root as product.md or instructions.md. Reference it constantly. ‚Ä¢ AI loses context fast ‚Äî this is your compass.\n  \n  2. Add a deployment manual. Yesterday.\n  \n  Document exactly how to ship your project. Which branch, which env vars, which server, where the bodies are buried.\n  \n  You will forget. Cursor will forget. This file saves you at 2am.\n  \n  3. Git or die trying.\n  \n  Cursor will break something critical.\n  \n  ‚Ä¢ Use version control. ‚Ä¢ Use local changelogs per folder (frontend/backend). ‚Ä¢ Saves tokens and gives your AI breadcrumbs to follow.\n  \n  4. Short chats > Smart chats\n  \n  Don‚Äôt hoard one 400-message Cursor chat. Start new ones per issue.\n  \n  ‚Ä¢ Keep context small, scoped, and aggressive. ‚Ä¢ Always say: ‚ÄúFix X only. Don‚Äôt change anything else.‚Äù ‚Ä¢ AI is smart, but it‚Äôs also a toddler with scissors.\n  \n  5. Don‚Äôt touch anything until you‚Äôve scoped the feature\n  \n  Your AI works better when you plan.\n  \n  ‚Ä¢ Write out the full feature flow in GPT/Claude first. ‚Ä¢ Get suggestions. ‚Ä¢ Choose one approach. ‚Ä¢ Then go to Cursor. You‚Äôre not brainstorming in Cursor. You‚Äôre executing.\n  \n  6. Clean your house weekly\n  \n  Run a weekly codebase cleanup.\n  \n  ‚Ä¢ Delete temp files. ‚Ä¢ Reorganize folder structure. ‚Ä¢ AI thrives in clean environments. So do you.\n  \n  7. Don‚Äôt ask Cursor to build the whole thing\n  \n  It‚Äôs not your intern. It‚Äôs a tool. Use it for: ‚Ä¢ UI stubs ‚Ä¢ Small logic blocks ‚Ä¢ Controlled refactors\n  \n  Asking for an entire app in one go is like asking a blender to cook your dinner.\n  \n  8. Ask before you fix\n  \n  When debugging: ‚Ä¢ Ask the model to investigate first. ‚Ä¢ Then have it suggest multiple solutions. ‚Ä¢ Then pick one.\n  \n  Only then ask it to implement. This sequence saves you hours of recursive hell.\n  \n  9. Tech debt builds at AI speed\n  \n  You‚Äôll MVP fast, but the mess scales faster than you.\n  \n  ‚Ä¢ Keep architecture clean. ‚Ä¢ Pause every few sprints to refactor. ‚Ä¢ You can vibe-code fast, but you can‚Äôt scale spaghetti.\n  \n  10. Your job is to lead the machine\n  \n  Cursor isn‚Äôt ‚Äúcoding for you.‚Äù It‚Äôs co-piloting. You‚Äôre still the captain.\n  \n  ‚Ä¢ Use .cursorrules to define project rules. ‚Ä¢ Use git checkpoints. ‚Ä¢ Use your brain for system thinking and product intuition.\n  \n  p.s. I‚Äôm putting together 20+ more hard-earned insights in a doc ‚Äî including specific prompts, scoped examples, debug flows, and mini PRD templates.\n  \n  If that sounds valuable, let me know and I‚Äôll drop it.\n  \n  Stay caffeinated. Lead the machines.\n-\n- Four week rolling schedule\n\t- High level concepts\n\t- Choosing tools\n\t- Setting up\n\t- Planning your project\n\t- Implement\n\t- Iterate\n\t- Refine\n\t- Productionise\n\t-\n- High level concepts from programming that remain important in vibe coding\n\t- Gated Debug\n\t- Understanding client server\n\t- Understanding code layout and structure\n- Tips and Tricks\n\t- Build messy then strip back with gemini\n\t- roll back then peek forward with git\n\t-\n- Managing and understanding tokens\n\t- API keys\n\t- context windows and efficient practice\n- Tools\n\t- VSCode\n\t- Aider\n\t- Cursor\n\t- Continue\n\t- Augment\n\t- Windsurf\n- Multiple AI tools\n\t- Gemini AI studio\n\t- Claude 3.7\n\t- Soon co-pilot for both?\n- Github\n\t- Git Show\n\t- branches\n- Yaml files\n- Docs\n\t- README\n\t- docs directory\n\t- Diagrams as code\n- Contacts to pick up\n\t- [James Patterson](https://www.linkedin.com/in/ACoAABtIa0YBJHS-UQbBV5mChJwA2O0GwBu4ufY)¬†(He/Him)¬†¬†6:08 PM\n\t\t- Hey John! üëã Hope things are well with you, just saw the post from Dreamlab about vibe coding/agent workshops. Would love to know if/how I could get involved, I‚Äôve been working on some personal projects in v0 and Cursor and keen to learn more\n\t- Derek Hales\n\t- Pip\n\t- Kat Cooke\n\t-\n\t-\n\n## Current Landscape (2025)\n\n- Industry adoption and implementations\n  - Metaverse platforms continue to evolve with focus on interoperability and open standards\n  - Web3 integration accelerating with decentralised identity and asset ownership\n  - Enterprise adoption growing in virtual collaboration, training, and digital twins\n  - UK companies increasingly active in metaverse development and immersive technologies\n\n- Technical capabilities\n  - Real-time rendering at photorealistic quality levels\n  - Low-latency networking enabling seamless multi-user experiences\n  - AI-driven content generation and procedural world building\n  - Spatial audio and haptics enhancing immersion\n\n- UK and North England context\n  - Manchester: Digital Innovation Factory supports metaverse startups and research\n  - Leeds: Holovis leads in immersive experiences for entertainment and training\n  - Newcastle: University research in spatial computing and interactive systems\n  - Sheffield: Advanced manufacturing using digital twin technology\n\n- Standards and frameworks\n  - Metaverse Standards Forum driving interoperability protocols\n  - WebXR enabling browser-based immersive experiences\n  - glTF and USD for 3D asset interchange\n  - Open Metaverse Interoperability Group defining cross-platform standards\n\n## Metadata\n\n- **Last Updated**: 2025-11-16\n- **Review Status**: Automated remediation with 2025 context\n- **Verification**: Academic sources verified\n- **Regional Context**: UK/North England where applicable",
  "properties": {
    "id": "vibe-coding-owl-axioms",
    "collapsed": "true",
    "- ontology": "true",
    "- term-id": "mv-200277278747",
    "- preferred-term": "Vibe Coding",
    "- source-domain": "metaverse",
    "- status": "active",
    "- public-access": "true",
    "- definition": "A component of the metaverse ecosystem focusing on vibe coding.",
    "- maturity": "mature",
    "- authority-score": "0.85",
    "- owl:class": "mv:VibeCoding",
    "- owl:physicality": "ConceptualEntity",
    "- owl:role": "Concept",
    "- belongsToDomain": "[[MetaverseDomain]]",
    "- enables": "[[ImmersiveExperience]], [[Presence]], [[SpatialComputing]]",
    "- requires": "[[DisplayTechnology]], [[TrackingSystem]], [[RenderingEngine]]",
    "- bridges-to": "[[HumanComputerInteraction]], [[ComputerVision]], [[Robotics]]"
  },
  "backlinks": [],
  "wiki_links": [
    "TrackingSystem",
    "ImmersiveExperience",
    "ComputerVision",
    "RenderingEngine",
    "SpatialComputing",
    "Robotics",
    "HumanComputerInteraction",
    "MetaverseDomain",
    "DisplayTechnology",
    "Presence"
  ],
  "ontology": {
    "term_id": "mv-200277278747",
    "preferred_term": "Vibe Coding",
    "definition": "A component of the metaverse ecosystem focusing on vibe coding.",
    "source_domain": "metaverse",
    "maturity_level": null,
    "authority_score": 0.85
  }
}