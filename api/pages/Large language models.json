{
  "title": "Large Language Models",
  "content": "- ### OntologyBlock\n  id:: large-language-models-ontology\n  collapsed:: true\n\n  - **Identification**\n    - ontology:: true\n    - term-id:: AI-0850\n    - preferred-term:: Large Language Models\n    - source-domain:: ai\n    - status:: complete\n    - public-access:: true\n    - version:: 2.0.0\n    - last-updated:: 2025-01-15\n    - quality-score:: 0.92\n\n  - **Definition**\n    - definition:: [[Large Language Models]] (LLMs) are [[Foundation Models]] with billions to trillions of parameters trained on massive text corpora using [[Transformer]] architectures and [[Self-Supervised Learning]], capable of performing diverse [[Natural Language Processing]] tasks through [[Few-Shot Learning]], [[Zero-Shot Learning]], and [[Prompt Engineering]]. LLMs represent a paradigm shift in [[Artificial Intelligence]], demonstrating emergent capabilities in reasoning, code generation, multilingual understanding, and complex task decomposition.\n    - maturity:: mature\n    - source:: [[OpenAI Research]], [[Google DeepMind]], [[Anthropic]], [[Meta AI Research]], [[NIST AI Standards]]\n    - authority-score:: 0.95\n\n  - **Semantic Classification**\n    - owl:class:: ai:LargeLanguageModel\n    - owl:physicality:: VirtualEntity\n    - owl:role:: Process\n    - owl:inferred-class:: ai:VirtualProcess\n    - belongsToDomain:: [[AI-GroundedDomain]], [[ComputationAndIntelligenceDomain]], [[DataManagementDomain]]\n\n  - #### OWL Restrictions\n    \n\n  - #### CrossDomainBridges\n    - bridges-from:: [[VoiceInteraction]] via has-part\n    - dt:enables:: [[Intelligent Npc]]\n    - dt:enables:: [[DigitalAvatar]]\n\n  -\n### Relationships\n- is-subclass-of:: [[ModelArchitecture]]",
  "properties": {
    "id": "large-language-models-ontology",
    "collapsed": "true",
    "- ontology": "true",
    "- term-id": "AI-0850",
    "- preferred-term": "Large Language Models",
    "- source-domain": "ai",
    "- status": "complete",
    "- public-access": "true",
    "- version": "2.0.0",
    "- last-updated": "2025-01-15",
    "- quality-score": "0.92",
    "- definition": "[[Large Language Models]] (LLMs) are [[Foundation Models]] with billions to trillions of parameters trained on massive text corpora using [[Transformer]] architectures and [[Self-Supervised Learning]], capable of performing diverse [[Natural Language Processing]] tasks through [[Few-Shot Learning]], [[Zero-Shot Learning]], and [[Prompt Engineering]]. LLMs represent a paradigm shift in [[Artificial Intelligence]], demonstrating emergent capabilities in reasoning, code generation, multilingual understanding, and complex task decomposition.",
    "- maturity": "mature",
    "- source": "[[OpenAI Research]], [[Google DeepMind]], [[Anthropic]], [[Meta AI Research]], [[NIST AI Standards]]",
    "- authority-score": "0.95",
    "- owl:class": "ai:LargeLanguageModel",
    "- owl:physicality": "VirtualEntity",
    "- owl:role": "Process",
    "- owl:inferred-class": "ai:VirtualProcess",
    "- belongsToDomain": "[[AI-GroundedDomain]], [[ComputationAndIntelligenceDomain]], [[DataManagementDomain]]",
    "- bridges-from": "[[VoiceInteraction]] via has-part",
    "- dt:enables": "[[DigitalAvatar]]"
  },
  "backlinks": [
    "Artificial Intelligence",
    "Runes and Glyphs",
    "Education Metaverse"
  ],
  "wiki_links": [
    "Self-Supervised Learning",
    "DigitalAvatar",
    "VoiceInteraction",
    "Intelligent Npc",
    "ComputationAndIntelligenceDomain",
    "Large Language Models",
    "NIST AI Standards",
    "Prompt Engineering",
    "Few-Shot Learning",
    "AI-GroundedDomain",
    "Anthropic",
    "OpenAI Research",
    "ModelArchitecture",
    "Google DeepMind",
    "Natural Language Processing",
    "Zero-Shot Learning",
    "DataManagementDomain",
    "Meta AI Research",
    "Transformer",
    "Foundation Models",
    "Artificial Intelligence"
  ],
  "ontology": {
    "term_id": "AI-0850",
    "preferred_term": "Large Language Models",
    "definition": "[[Large Language Models]] (LLMs) are [[Foundation Models]] with billions to trillions of parameters trained on massive text corpora using [[Transformer]] architectures and [[Self-Supervised Learning]], capable of performing diverse [[Natural Language Processing]] tasks through [[Few-Shot Learning]], [[Zero-Shot Learning]], and [[Prompt Engineering]]. LLMs represent a paradigm shift in [[Artificial Intelligence]], demonstrating emergent capabilities in reasoning, code generation, multilingual understanding, and complex task decomposition.",
    "source_domain": "ai",
    "maturity_level": null,
    "authority_score": 0.95
  }
}