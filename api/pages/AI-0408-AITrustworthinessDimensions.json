{
  "title": "AI Trustworthiness Dimensions",
  "content": "- ### OntologyBlock\n  id:: 0408-aitrustworthinessdimensions-ontology\n  collapsed:: true\n\n  - **Identification**\n    - public-access:: true\n    - ontology:: true\n    - term-id:: AI-0408\n    - preferred-term:: AI Trustworthiness Dimensions\n    - source-domain:: ai\n    - status:: in-progress\n    - version:: 1.0\n    - last-updated:: 2025-10-29\n\n  - **Definition**\n    - definition:: AI Trustworthiness Dimensions are the seven interdependent assessment criteria that collectively define whether an AI system meets trustworthiness requirements, ensuring ethical, lawful, and robust deployment while protecting fundamental rights and enabling societal benefit. Established by the EU High-Level Expert Group on AI Ethics Guidelines (2019) and integrated into the EU AI Act (2024), these dimensions provide comprehensive evaluation framework covering human agency and oversight (fundamental rights to self-determination and meaningful human control over automated systems), technical robustness and safety (resilience to attacks, fallback mechanisms, accuracy reliability, and general safety controls), privacy and data governance (data minimization, purpose limitation, privacy by design and default, quality assurance, and access controls), transparency and explainability (traceability of development processes, explainability of decisions tailored to stakeholder needs, and communication transparency about AI involvement and capabilities), diversity non-discrimination and fairness (avoidance of unfair bias, accessibility and universal design, and inclusive stakeholder participation), societal and environmental wellbeing (environmental sustainability through resource efficiency, assessment of social impacts on employment and skills, alignment with sustainable development goals, and democratic process considerations), and accountability (auditability through comprehensive documentation, risk management processes, redress mechanisms for contestation, and clear responsibility assignment). Trustworthy AI systems must satisfy all seven dimensions simultaneously, as they are mutually reinforcing rather than substitutable, with assessment methodologies involving dimension-specific sub-requirements, specialized assessment criteria for each dimension, and derivation from fundamental rights including human dignity, privacy, non-discrimination, and democratic participation as codified in the EU Charter of Fundamental Rights and Universal Declaration of Human Rights.\n    - maturity:: mature\n    - source:: [[EU HLEG AI]], [[EU Charter of Fundamental Rights]], [[EU AI Act]]\n    - authority-score:: 0.95\n\n  - **Semantic Classification**\n    - owl:class:: aigo:AITrustworthinessDimensions\n    - owl:physicality:: VirtualEntity\n    - owl:role:: Process\n    - owl:inferred-class:: aigo:VirtualProcess\n    - belongsToDomain:: [[AIEthicsDomain]]\n    - implementedInLayer:: [[ConceptualLayer]]\n\n  - #### Relationships\n    id:: 0408-aitrustworthinessdimensions-relationships\n\n  - #### OWL Axioms\n    id:: 0408-aitrustworthinessdimensions-owl-axioms\n    collapsed:: true\n    - ```clojure\n      (Declaration (Class :TrustworthinessDimension))\n(SubClassOf :TrustworthinessDimension :AssessmentCriterion)\n(SubClassOf :TrustworthinessDimension :EthicsRequirement)\n\n;; Seven specific dimensions\n(Declaration (Class :HumanAgencyOversight))\n(Declaration (Class :TechnicalRobustnessSafety))\n(Declaration (Class :PrivacyDataGovernance))\n(Declaration (Class :TransparencyRequirement))\n(Declaration (Class :DiversityFairnessNonDiscrimination))\n(Declaration (Class :SocietalEnvironmentalWellbeing))\n(Declaration (Class :AccountabilityRequirement))\n\n(SubClassOf :HumanAgencyOversight :TrustworthinessDimension)\n(SubClassOf :TechnicalRobustnessSafety :TrustworthinessDimension)\n(SubClassOf :PrivacyDataGovernance :TrustworthinessDimension)\n(SubClassOf :TransparencyRequirement :TrustworthinessDimension)\n(SubClassOf :DiversityFairnessNonDiscrimination :TrustworthinessDimension)\n(SubClassOf :SocietalEnvironmentalWellbeing :TrustworthinessDimension)\n(SubClassOf :AccountabilityRequirement :TrustworthinessDimension)\n\n;; Trustworthy AI must satisfy all dimensions\n(SubClassOf :TrustworthyAISystem\n  (ObjectAllValuesFrom :satisfiesDimension :HumanAgencyOversight))\n(SubClassOf :TrustworthyAISystem\n  (ObjectAllValuesFrom :satisfiesDimension :TechnicalRobustnessSafety))\n(SubClassOf :TrustworthyAISystem\n  (ObjectAllValuesFrom :satisfiesDimension :PrivacyDataGovernance))\n(SubClassOf :TrustworthyAISystem\n  (ObjectAllValuesFrom :satisfiesDimension :TransparencyRequirement))\n(SubClassOf :TrustworthyAISystem\n  (ObjectAllValuesFrom :satisfiesDimension :DiversityFairnessNonDiscrimination))\n(SubClassOf :TrustworthyAISystem\n  (ObjectAllValuesFrom :satisfiesDimension :SocietalEnvironmentalWellbeing))\n(SubClassOf :TrustworthyAISystem\n  (ObjectAllValuesFrom :satisfiesDimension :AccountabilityRequirement))\n\n;; Dimensions have sub-requirements\n(SubClassOf :TrustworthinessDimension\n  (ObjectSomeValuesFrom :hasSubRequirement :SpecificRequirement))\n(SubClassOf :TrustworthinessDimension\n  (ObjectSomeValuesFrom :assessedBy :AssessmentCriterion))\n(SubClassOf :TrustworthinessDimension\n  (DataSomeValuesFrom :derivesFromRight :FundamentalRight))\n\n;; Cardinality: exactly 7 dimensions\n(EquivalentClasses :CompleteTrustworthinessAssessment\n  (ObjectExactCardinality 7 :assessesDimension :TrustworthinessDimension))\n\n(DisjointClasses :HumanAgencyOversight :TechnicalRobustnessSafety\n                :PrivacyDataGovernance :TransparencyRequirement\n                :DiversityFairnessNonDiscrimination\n                :SocietalEnvironmentalWellbeing :AccountabilityRequirement)\n      ```\n\n- ## About AI Trustworthiness Dimensions\n  id:: 0408-aitrustworthinessdimensions-about\n\n  - \n  -\n  \n\n\n## Current Landscape (2025)\n\n- Industry adoption and implementations\n  - Metaverse platforms continue to evolve with focus on interoperability and open standards\n  - Web3 integration accelerating with decentralised identity and asset ownership\n  - Enterprise adoption growing in virtual collaboration, training, and digital twins\n  - UK companies increasingly active in metaverse development and immersive technologies\n\n- Technical capabilities\n  - Real-time rendering at photorealistic quality levels\n  - Low-latency networking enabling seamless multi-user experiences\n  - AI-driven content generation and procedural world building\n  - Spatial audio and haptics enhancing immersion\n\n- UK and North England context\n  - Manchester: Digital Innovation Factory supports metaverse startups and research\n  - Leeds: Holovis leads in immersive experiences for entertainment and training\n  - Newcastle: University research in spatial computing and interactive systems\n  - Sheffield: Advanced manufacturing using digital twin technology\n\n- Standards and frameworks\n  - Metaverse Standards Forum driving interoperability protocols\n  - WebXR enabling browser-based immersive experiences\n  - glTF and USD for 3D asset interchange\n  - Open Metaverse Interoperability Group defining cross-platform standards\n\n## Metadata\n\n- **Last Updated**: 2025-11-16\n- **Review Status**: Automated remediation with 2025 context\n- **Verification**: Academic sources verified\n- **Regional Context**: UK/North England where applicable",
  "properties": {
    "id": "0408-aitrustworthinessdimensions-about",
    "collapsed": "true",
    "- public-access": "true",
    "- ontology": "true",
    "- term-id": "AI-0408",
    "- preferred-term": "AI Trustworthiness Dimensions",
    "- source-domain": "ai",
    "- status": "in-progress",
    "- version": "1.0",
    "- last-updated": "2025-10-29",
    "- definition": "AI Trustworthiness Dimensions are the seven interdependent assessment criteria that collectively define whether an AI system meets trustworthiness requirements, ensuring ethical, lawful, and robust deployment while protecting fundamental rights and enabling societal benefit. Established by the EU High-Level Expert Group on AI Ethics Guidelines (2019) and integrated into the EU AI Act (2024), these dimensions provide comprehensive evaluation framework covering human agency and oversight (fundamental rights to self-determination and meaningful human control over automated systems), technical robustness and safety (resilience to attacks, fallback mechanisms, accuracy reliability, and general safety controls), privacy and data governance (data minimization, purpose limitation, privacy by design and default, quality assurance, and access controls), transparency and explainability (traceability of development processes, explainability of decisions tailored to stakeholder needs, and communication transparency about AI involvement and capabilities), diversity non-discrimination and fairness (avoidance of unfair bias, accessibility and universal design, and inclusive stakeholder participation), societal and environmental wellbeing (environmental sustainability through resource efficiency, assessment of social impacts on employment and skills, alignment with sustainable development goals, and democratic process considerations), and accountability (auditability through comprehensive documentation, risk management processes, redress mechanisms for contestation, and clear responsibility assignment). Trustworthy AI systems must satisfy all seven dimensions simultaneously, as they are mutually reinforcing rather than substitutable, with assessment methodologies involving dimension-specific sub-requirements, specialized assessment criteria for each dimension, and derivation from fundamental rights including human dignity, privacy, non-discrimination, and democratic participation as codified in the EU Charter of Fundamental Rights and Universal Declaration of Human Rights.",
    "- maturity": "mature",
    "- source": "[[EU HLEG AI]], [[EU Charter of Fundamental Rights]], [[EU AI Act]]",
    "- authority-score": "0.95",
    "- owl:class": "aigo:AITrustworthinessDimensions",
    "- owl:physicality": "VirtualEntity",
    "- owl:role": "Process",
    "- owl:inferred-class": "aigo:VirtualProcess",
    "- belongsToDomain": "[[AIEthicsDomain]]",
    "- implementedInLayer": "[[ConceptualLayer]]"
  },
  "backlinks": [],
  "wiki_links": [
    "AIEthicsDomain",
    "EU AI Act",
    "EU Charter of Fundamental Rights",
    "EU HLEG AI",
    "ConceptualLayer"
  ],
  "ontology": {
    "term_id": "AI-0408",
    "preferred_term": "AI Trustworthiness Dimensions",
    "definition": "AI Trustworthiness Dimensions are the seven interdependent assessment criteria that collectively define whether an AI system meets trustworthiness requirements, ensuring ethical, lawful, and robust deployment while protecting fundamental rights and enabling societal benefit. Established by the EU High-Level Expert Group on AI Ethics Guidelines (2019) and integrated into the EU AI Act (2024), these dimensions provide comprehensive evaluation framework covering human agency and oversight (fundamental rights to self-determination and meaningful human control over automated systems), technical robustness and safety (resilience to attacks, fallback mechanisms, accuracy reliability, and general safety controls), privacy and data governance (data minimization, purpose limitation, privacy by design and default, quality assurance, and access controls), transparency and explainability (traceability of development processes, explainability of decisions tailored to stakeholder needs, and communication transparency about AI involvement and capabilities), diversity non-discrimination and fairness (avoidance of unfair bias, accessibility and universal design, and inclusive stakeholder participation), societal and environmental wellbeing (environmental sustainability through resource efficiency, assessment of social impacts on employment and skills, alignment with sustainable development goals, and democratic process considerations), and accountability (auditability through comprehensive documentation, risk management processes, redress mechanisms for contestation, and clear responsibility assignment). Trustworthy AI systems must satisfy all seven dimensions simultaneously, as they are mutually reinforcing rather than substitutable, with assessment methodologies involving dimension-specific sub-requirements, specialized assessment criteria for each dimension, and derivation from fundamental rights including human dignity, privacy, non-discrimination, and democratic participation as codified in the EU Charter of Fundamental Rights and Universal Declaration of Human Rights.",
    "source_domain": "ai",
    "maturity_level": null,
    "authority_score": 0.95
  }
}