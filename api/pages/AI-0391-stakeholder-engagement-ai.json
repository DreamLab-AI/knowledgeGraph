{
  "title": "Stakeholder Engagement in AI",
  "content": "- ### OntologyBlock\n  id:: 0391-stakeholder-engagement-ai-ontology\n  collapsed:: true\n\n  - **Identification**\n    - public-access:: true\n    - ontology:: true\n    - term-id:: AI-0391\n    - preferred-term:: Stakeholder Engagement in AI\n    - source-domain:: ai\n    - status:: in-progress\n    - version:: 1.0\n    - last-updated:: 2025-10-29\n\n  - **Definition**\n    - definition:: Stakeholder Engagement in AI is a participatory process that systematically identifies, involves, and incorporates perspectives from individuals, groups, and communities affected by or having legitimate interests in AI systems, ensuring inclusive design, accountable deployment, and responsive governance. This engagement encompasses diverse stakeholders including end users, affected communities, subject matter experts, civil society organizations, regulators, and internal organizational stakeholders, soliciting input through various methods to inform AI system design, risk assessment, and governance decisions. Engagement methods span the participation spectrum from information provision (transparency reports, public documentation), consultation (surveys, focus groups, public comment periods), collaboration (co-design workshops, participatory research), and empowerment (community oversight boards, contestation mechanisms). Effective stakeholder engagement identifies power asymmetries and barriers to participation, ensuring meaningful inclusion of marginalized and vulnerable groups, uses accessible communication avoiding technical jargon, provides adequate time and resources for informed participation, demonstrates responsiveness by showing how input influenced decisions, and maintains ongoing dialogue rather than one-time consultation. Benefits include surfacing ethical concerns and unintended consequences, incorporating domain expertise and lived experience, building public trust and legitimacy, identifying fairness issues across diverse populations, and strengthening accountability through external oversight. Implementation aligns with participatory design methodologies, human rights due diligence processes, and requirements in frameworks including the EU AI Act Article 29 (codes of conduct involving stakeholders), OECD AI Principle 2.3 (stakeholder engagement), and ISO 26000 guidance on stakeholder engagement.\n    - maturity:: mature\n    - source:: [[EU AI Act]], [[OECD AI Principles]], [[ISO 26000]]\n    - authority-score:: 0.95\n\n  - **Semantic Classification**\n    - owl:class:: aigo:StakeholderEngagementInAI\n    - owl:physicality:: VirtualEntity\n    - owl:role:: Process\n    - owl:inferred-class:: aigo:VirtualProcess\n    - belongsToDomain:: [[AIEthicsDomain]]\n    - implementedInLayer:: [[ConceptualLayer]]\n\n  - #### Relationships\n    id:: 0391-stakeholder-engagement-ai-relationships\n\n  - #### OWL Axioms\n    id:: 0391-stakeholder-engagement-ai-owl-axioms\n    collapsed:: true\n    - ```clojure\n      (Declaration (Class :AIStakeholderEngagement))\n(SubClassOf :AIStakeholderEngagement :TechnologyStakeholderEngagement)\n\n(SubClassOf :AIStakeholderEngagement\n  (ObjectSomeValuesFrom :identifies :Stakeholder))\n(SubClassOf :AIStakeholderEngagement\n  (ObjectSomeValuesFrom :involves :AffectedCommunity))\n(SubClassOf :AIStakeholderEngagement\n  (ObjectSomeValuesFrom :solicits :StakeholderInput))\n(SubClassOf :AIStakeholderEngagement\n  (ObjectSomeValuesFrom :informs :AISystemDesign))\n(SubClassOf :AIStakeholderEngagement\n  (ObjectSomeValuesFrom :ensures :Inclusivity))\n(SubClassOf :AIStakeholderEngagement\n  (ObjectSomeValuesFrom :supports :AccountabilityMechanism))\n\n(SubClassOf :AIStakeholderEngagement\n  (ObjectIntersectionOf\n    (ObjectSomeValuesFrom :uses :EngagementMethod)\n    (ObjectSomeValuesFrom :produces :StakeholderFeedback)))\n      ```\n\n- ## About 0391 Stakeholder Engagement Ai\n  id:: 0391-stakeholder-engagement-ai-about\n\n  - \n  -\n  \n\n\t- ##### Engage\n\n\t- ##### Engage\n\n- ### Applications\n\t- **Consumer Tools Using LLMs**: Showcasing the application of LLMs in creating innovative consumer tools.\n\t\t- [CustomGPT for Personalized Customer Experiences](https://customgpt.ai)\n\t\t- *CustomGPT leverages LLMs to offer personalized interactions, demonstrating the potential of AI in enhancing customer service and engagement.*\n\n- ### Applications\n\t- **Consumer Tools Using LLMs**: Showcasing the application of LLMs in creating innovative consumer tools.\n\t\t- [CustomGPT for Personalized Customer Experiences](https://customgpt.ai)\n\t\t- *CustomGPT leverages LLMs to offer personalized interactions, demonstrating the potential of AI in enhancing customer service and engagement.*\n\n- ### Applications\n\t- **Consumer Tools Using LLMs**: Showcasing the application of LLMs in creating innovative consumer tools.\n\t\t- [CustomGPT for Personalized Customer Experiences](https://customgpt.ai)\n\t\t- *CustomGPT leverages LLMs to offer personalized interactions, demonstrating the potential of AI in enhancing customer service and engagement.*\n\n\n## Current Landscape (2025)\n\n- Industry adoption and implementations\n  - Metaverse platforms continue to evolve with focus on interoperability and open standards\n  - Web3 integration accelerating with decentralised identity and asset ownership\n  - Enterprise adoption growing in virtual collaboration, training, and digital twins\n  - UK companies increasingly active in metaverse development and immersive technologies\n\n- Technical capabilities\n  - Real-time rendering at photorealistic quality levels\n  - Low-latency networking enabling seamless multi-user experiences\n  - AI-driven content generation and procedural world building\n  - Spatial audio and haptics enhancing immersion\n\n- UK and North England context\n  - Manchester: Digital Innovation Factory supports metaverse startups and research\n  - Leeds: Holovis leads in immersive experiences for entertainment and training\n  - Newcastle: University research in spatial computing and interactive systems\n  - Sheffield: Advanced manufacturing using digital twin technology\n\n- Standards and frameworks\n  - Metaverse Standards Forum driving interoperability protocols\n  - WebXR enabling browser-based immersive experiences\n  - glTF and USD for 3D asset interchange\n  - Open Metaverse Interoperability Group defining cross-platform standards\n\n## Metadata\n\n- **Last Updated**: 2025-11-16\n- **Review Status**: Automated remediation with 2025 context\n- **Verification**: Academic sources verified\n- **Regional Context**: UK/North England where applicable",
  "properties": {
    "id": "0391-stakeholder-engagement-ai-about",
    "collapsed": "true",
    "- public-access": "true",
    "- ontology": "true",
    "- term-id": "AI-0391",
    "- preferred-term": "Stakeholder Engagement in AI",
    "- source-domain": "ai",
    "- status": "in-progress",
    "- version": "1.0",
    "- last-updated": "2025-10-29",
    "- definition": "Stakeholder Engagement in AI is a participatory process that systematically identifies, involves, and incorporates perspectives from individuals, groups, and communities affected by or having legitimate interests in AI systems, ensuring inclusive design, accountable deployment, and responsive governance. This engagement encompasses diverse stakeholders including end users, affected communities, subject matter experts, civil society organizations, regulators, and internal organizational stakeholders, soliciting input through various methods to inform AI system design, risk assessment, and governance decisions. Engagement methods span the participation spectrum from information provision (transparency reports, public documentation), consultation (surveys, focus groups, public comment periods), collaboration (co-design workshops, participatory research), and empowerment (community oversight boards, contestation mechanisms). Effective stakeholder engagement identifies power asymmetries and barriers to participation, ensuring meaningful inclusion of marginalized and vulnerable groups, uses accessible communication avoiding technical jargon, provides adequate time and resources for informed participation, demonstrates responsiveness by showing how input influenced decisions, and maintains ongoing dialogue rather than one-time consultation. Benefits include surfacing ethical concerns and unintended consequences, incorporating domain expertise and lived experience, building public trust and legitimacy, identifying fairness issues across diverse populations, and strengthening accountability through external oversight. Implementation aligns with participatory design methodologies, human rights due diligence processes, and requirements in frameworks including the EU AI Act Article 29 (codes of conduct involving stakeholders), OECD AI Principle 2.3 (stakeholder engagement), and ISO 26000 guidance on stakeholder engagement.",
    "- maturity": "mature",
    "- source": "[[EU AI Act]], [[OECD AI Principles]], [[ISO 26000]]",
    "- authority-score": "0.95",
    "- owl:class": "aigo:StakeholderEngagementInAI",
    "- owl:physicality": "VirtualEntity",
    "- owl:role": "Process",
    "- owl:inferred-class": "aigo:VirtualProcess",
    "- belongsToDomain": "[[AIEthicsDomain]]",
    "- implementedInLayer": "[[ConceptualLayer]]"
  },
  "backlinks": [],
  "wiki_links": [
    "ConceptualLayer",
    "AIEthicsDomain",
    "ISO 26000",
    "OECD AI Principles",
    "EU AI Act"
  ],
  "ontology": {
    "term_id": "AI-0391",
    "preferred_term": "Stakeholder Engagement in AI",
    "definition": "Stakeholder Engagement in AI is a participatory process that systematically identifies, involves, and incorporates perspectives from individuals, groups, and communities affected by or having legitimate interests in AI systems, ensuring inclusive design, accountable deployment, and responsive governance. This engagement encompasses diverse stakeholders including end users, affected communities, subject matter experts, civil society organizations, regulators, and internal organizational stakeholders, soliciting input through various methods to inform AI system design, risk assessment, and governance decisions. Engagement methods span the participation spectrum from information provision (transparency reports, public documentation), consultation (surveys, focus groups, public comment periods), collaboration (co-design workshops, participatory research), and empowerment (community oversight boards, contestation mechanisms). Effective stakeholder engagement identifies power asymmetries and barriers to participation, ensuring meaningful inclusion of marginalized and vulnerable groups, uses accessible communication avoiding technical jargon, provides adequate time and resources for informed participation, demonstrates responsiveness by showing how input influenced decisions, and maintains ongoing dialogue rather than one-time consultation. Benefits include surfacing ethical concerns and unintended consequences, incorporating domain expertise and lived experience, building public trust and legitimacy, identifying fairness issues across diverse populations, and strengthening accountability through external oversight. Implementation aligns with participatory design methodologies, human rights due diligence processes, and requirements in frameworks including the EU AI Act Article 29 (codes of conduct involving stakeholders), OECD AI Principle 2.3 (stakeholder engagement), and ISO 26000 guidance on stakeholder engagement.",
    "source_domain": "ai",
    "maturity_level": null,
    "authority_score": 0.95
  }
}