{
  "title": "GDPR Article 22 Compliance",
  "content": "- ### OntologyBlock\n  id:: 0429-gdpr-article-22-compliance-ontology\n  collapsed:: true\n\n  - **Identification**\n    - public-access:: true\n    - ontology:: true\n    - term-id:: AI-0429\n    - preferred-term:: GDPR Article 22 Compliance\n    - source-domain:: ai-grounded\n    - status:: in-progress\n    - version:: 1.0\n    - last-updated:: 2025-10-29\n\n  - **Definition**\n    - definition:: GDPR Article 22 Compliance addresses automated decision-making and profiling by establishing that data subjects have the right not to be subject to decisions based solely on automated processing (including profiling) which produce legal effects or similarly significantly affect them, requiring human intervention, contestation mechanisms, and meaningful information provision for permitted automated decisions. Article 22(1) prohibits solely automated decisions with significant effects unless falling within Article 22(2) exceptions: necessary for contract performance between data subject and controller, authorized by EU or member state law providing suitable safeguards for rights and legitimate interests, or based on data subject's explicit consent. Article 22(3) mandates safeguards for permitted automated decisions including right to obtain human intervention (qualified human reviewer with authority to change decision assessing AI outputs and exercising meaningful discretion rather than rubber-stamping), right to express views (data subjects may provide context, explanations, or objections influencing final determination), and right to contest decision (formal challenge procedures with review and potential reversal), while Article 22(4) restricts decisions based solely on special category data (health, genetic, biometric, racial/ethnic origin, political opinions, religious beliefs, trade union membership, sexual orientation) unless substantial public interest exception applies with suitable safeguards. Compliance requirements encompass determining legal effects or significant effects through criteria including financial impact (credit denial, insurance pricing, employment termination), access to services (healthcare, education, social benefits), legal status (visa, residency, criminal justice), and life opportunities (housing, employment, education), ensuring meaningful human involvement through reviewers with competence to assess AI outputs, authority to change decisions, access to all relevant information beyond AI recommendations, and sufficient time for considered evaluation, providing transparency through information about logic involved in automated processing, significance and envisaged consequences for data subject, and factors considered in decision-making, and implementing technical measures including explainable AI enabling human reviewers to understand decision rationale, audit trails documenting automated and human decision components, bias detection and mitigation ensuring fair treatment across groups, and data quality assurance preventing propagation of errors or outdated information. The 2024-2025 enforcement period witnessed multiple actions establishing that nominal human review insufficient if humans consistently defer to AI outputs (French CNIL cases), automated social welfare systems requiring genuine human discretion (Dutch DPA investigations), and automated employment screening necessitating adequate rejection explanations when AI-driven (Austrian DPA challenges), collectively establishing that Article 22 creates de facto requirement for explainable AI in high-stakes contexts as unexplainable decisions cannot satisfy right to explanation, with decision types commonly subject to Article 22 including credit scoring, recruitment and employment decisions, healthcare diagnoses and treatment recommendations, insurance underwriting and claims processing, and profiling for targeted advertising or content curation when producing significant effects.\n    - maturity:: mature\n    - source:: [[GDPR Article 22]], [[French CNIL]], [[Dutch DPA]], [[WP29 Guidelines]]\n    - authority-score:: 0.95\n\n  - **Semantic Classification**\n    - owl:class:: aigo:GDPRArticle22Compliance\n    - owl:physicality:: VirtualEntity\n    - owl:role:: Process\n    - owl:inferred-class:: aigo:VirtualProcess\n    - belongsToDomain:: [[AIEthicsDomain]]\n    - implementedInLayer:: [[ConceptualLayer]]\n\n  - #### Relationships\n    id:: 0429-gdpr-article-22-compliance-relationships\n\n  - #### OWL Axioms\n    id:: 0429-gdpr-article-22-compliance-owl-axioms\n    collapsed:: true\n    - ```clojure\n      (Declaration (Class :GDPRArticle22Compliance))\n(AnnotationAssertion rdfs:label :GDPRArticle22Compliance \"GDPR Article 22 Compliance\"@en)\n(SubClassOf :GDPRArticle22Compliance :RegulatoryCompliance)\n\n;; Core Relationships\n(SubClassOf :GDPRArticle22Compliance\n  (ObjectSomeValuesFrom :regulates :AutomatedDecisionMaking))\n(SubClassOf :GDPRArticle22Compliance\n  (ObjectSomeValuesFrom :protects :DataSubjectRights))\n(SubClassOf :GDPRArticle22Compliance\n  (ObjectSomeValuesFrom :requires :HumanIntervention))\n(SubClassOf :GDPRArticle22Compliance\n  (ObjectSomeValuesFrom :ensures :ContestationMechanism))\n(SubClassOf :GDPRArticle22Compliance\n  (ObjectSomeValuesFrom :provides :MeaningfulInformation))\n(SubClassOf :GDPRArticle22Compliance\n  (ObjectSomeValuesFrom :implements :Safeguards))\n(SubClassOf :GDPRArticle22Compliance\n  (ObjectSomeValuesFrom :enables :ExpressionOfViews))\n(SubClassOf :GDPRArticle22Compliance\n  (ObjectSomeValuesFrom :documents :DecisionLogic))\n\n;; Article 22(1) Prohibition\n(SubClassOf :GDPRArticle22Compliance\n  (ObjectSomeValuesFrom :prohibits\n    (ObjectIntersectionOf :SolelyAutomatedDecision\n                         :LegalEffect\n                         :SimilarlySignificantEffect)))\n\n;; Article 22(2) Exceptions\n(SubClassOf :GDPRArticle22Compliance\n  (ObjectSomeValuesFrom :permits\n    (ObjectUnionOf :NecessaryForContract\n                   :AuthorisedByLaw\n                   :ExplicitConsent)))\n\n;; Article 22(3) Safeguards\n(SubClassOf :GDPRArticle22Compliance\n  (ObjectSomeValuesFrom :mandates\n    (ObjectUnionOf :RightToHumanIntervention\n                   :RightToExpressViews\n                   :RightToContest)))\n\n;; Article 22(4) Special Categories\n(SubClassOf :GDPRArticle22Compliance\n  (ObjectSomeValuesFrom :restricts\n    (ObjectIntersectionOf :SpecialCategoryData\n                         :SubstantialPublicInterest\n                         :SuitableSafeguards)))\n\n;; Data Properties\n(SubClassOf :GDPRArticle22Compliance\n  (DataHasValue :hasLegalEffect xsd:boolean))\n(SubClassOf :GDPRArticle22Compliance\n  (DataHasValue :hasSignificantEffect xsd:boolean))\n(SubClassOf :GDPRArticle22Compliance\n  (DataHasValue :humanInvolvementLevel\n    (DataOneOf \"none\" \"minimal\" \"meaningful\" \"full\")))\n(SubClassOf :GDPRArticle22Compliance\n  (DataHasValue :legalBasis xsd:string))\n(SubClassOf :GDPRArticle22Compliance\n  (DataHasValue :contestationAvailable xsd:boolean))\n\n;; Decision Types\n(SubClassOf :GDPRArticle22Compliance\n  (ObjectSomeValuesFrom :appliesTo\n    (ObjectUnionOf :CreditDecision\n                   :RecruitmentDecision\n                   :HealthcareDecision\n                   :InsuranceDecision\n                   :ProfilingDecision)))\n\n;; Compliance Requirements\n(SubClassOf :GDPRArticle22Compliance\n  (ObjectSomeValuesFrom :requires\n    (ObjectUnionOf :ExplainableAI\n                   :AuditTrail\n                   :BiasDetection\n                   :HumanReview\n                   :DataQualityAssurance)))\n      ```\n\n### Relationships\n- is-subclass-of:: [[AIGovernance]]",
  "properties": {
    "id": "0429-gdpr-article-22-compliance-owl-axioms",
    "collapsed": "true",
    "- public-access": "true",
    "- ontology": "true",
    "- term-id": "AI-0429",
    "- preferred-term": "GDPR Article 22 Compliance",
    "- source-domain": "ai-grounded",
    "- status": "in-progress",
    "- version": "1.0",
    "- last-updated": "2025-10-29",
    "- definition": "GDPR Article 22 Compliance addresses automated decision-making and profiling by establishing that data subjects have the right not to be subject to decisions based solely on automated processing (including profiling) which produce legal effects or similarly significantly affect them, requiring human intervention, contestation mechanisms, and meaningful information provision for permitted automated decisions. Article 22(1) prohibits solely automated decisions with significant effects unless falling within Article 22(2) exceptions: necessary for contract performance between data subject and controller, authorized by EU or member state law providing suitable safeguards for rights and legitimate interests, or based on data subject's explicit consent. Article 22(3) mandates safeguards for permitted automated decisions including right to obtain human intervention (qualified human reviewer with authority to change decision assessing AI outputs and exercising meaningful discretion rather than rubber-stamping), right to express views (data subjects may provide context, explanations, or objections influencing final determination), and right to contest decision (formal challenge procedures with review and potential reversal), while Article 22(4) restricts decisions based solely on special category data (health, genetic, biometric, racial/ethnic origin, political opinions, religious beliefs, trade union membership, sexual orientation) unless substantial public interest exception applies with suitable safeguards. Compliance requirements encompass determining legal effects or significant effects through criteria including financial impact (credit denial, insurance pricing, employment termination), access to services (healthcare, education, social benefits), legal status (visa, residency, criminal justice), and life opportunities (housing, employment, education), ensuring meaningful human involvement through reviewers with competence to assess AI outputs, authority to change decisions, access to all relevant information beyond AI recommendations, and sufficient time for considered evaluation, providing transparency through information about logic involved in automated processing, significance and envisaged consequences for data subject, and factors considered in decision-making, and implementing technical measures including explainable AI enabling human reviewers to understand decision rationale, audit trails documenting automated and human decision components, bias detection and mitigation ensuring fair treatment across groups, and data quality assurance preventing propagation of errors or outdated information. The 2024-2025 enforcement period witnessed multiple actions establishing that nominal human review insufficient if humans consistently defer to AI outputs (French CNIL cases), automated social welfare systems requiring genuine human discretion (Dutch DPA investigations), and automated employment screening necessitating adequate rejection explanations when AI-driven (Austrian DPA challenges), collectively establishing that Article 22 creates de facto requirement for explainable AI in high-stakes contexts as unexplainable decisions cannot satisfy right to explanation, with decision types commonly subject to Article 22 including credit scoring, recruitment and employment decisions, healthcare diagnoses and treatment recommendations, insurance underwriting and claims processing, and profiling for targeted advertising or content curation when producing significant effects.",
    "- maturity": "mature",
    "- source": "[[GDPR Article 22]], [[French CNIL]], [[Dutch DPA]], [[WP29 Guidelines]]",
    "- authority-score": "0.95",
    "- owl:class": "aigo:GDPRArticle22Compliance",
    "- owl:physicality": "VirtualEntity",
    "- owl:role": "Process",
    "- owl:inferred-class": "aigo:VirtualProcess",
    "- belongsToDomain": "[[AIEthicsDomain]]",
    "- implementedInLayer": "[[ConceptualLayer]]"
  },
  "backlinks": [],
  "wiki_links": [
    "Dutch DPA",
    "AIEthicsDomain",
    "French CNIL",
    "WP29 Guidelines",
    "ConceptualLayer",
    "AIGovernance",
    "GDPR Article 22"
  ],
  "ontology": {
    "term_id": "AI-0429",
    "preferred_term": "GDPR Article 22 Compliance",
    "definition": "GDPR Article 22 Compliance addresses automated decision-making and profiling by establishing that data subjects have the right not to be subject to decisions based solely on automated processing (including profiling) which produce legal effects or similarly significantly affect them, requiring human intervention, contestation mechanisms, and meaningful information provision for permitted automated decisions. Article 22(1) prohibits solely automated decisions with significant effects unless falling within Article 22(2) exceptions: necessary for contract performance between data subject and controller, authorized by EU or member state law providing suitable safeguards for rights and legitimate interests, or based on data subject's explicit consent. Article 22(3) mandates safeguards for permitted automated decisions including right to obtain human intervention (qualified human reviewer with authority to change decision assessing AI outputs and exercising meaningful discretion rather than rubber-stamping), right to express views (data subjects may provide context, explanations, or objections influencing final determination), and right to contest decision (formal challenge procedures with review and potential reversal), while Article 22(4) restricts decisions based solely on special category data (health, genetic, biometric, racial/ethnic origin, political opinions, religious beliefs, trade union membership, sexual orientation) unless substantial public interest exception applies with suitable safeguards. Compliance requirements encompass determining legal effects or significant effects through criteria including financial impact (credit denial, insurance pricing, employment termination), access to services (healthcare, education, social benefits), legal status (visa, residency, criminal justice), and life opportunities (housing, employment, education), ensuring meaningful human involvement through reviewers with competence to assess AI outputs, authority to change decisions, access to all relevant information beyond AI recommendations, and sufficient time for considered evaluation, providing transparency through information about logic involved in automated processing, significance and envisaged consequences for data subject, and factors considered in decision-making, and implementing technical measures including explainable AI enabling human reviewers to understand decision rationale, audit trails documenting automated and human decision components, bias detection and mitigation ensuring fair treatment across groups, and data quality assurance preventing propagation of errors or outdated information. The 2024-2025 enforcement period witnessed multiple actions establishing that nominal human review insufficient if humans consistently defer to AI outputs (French CNIL cases), automated social welfare systems requiring genuine human discretion (Dutch DPA investigations), and automated employment screening necessitating adequate rejection explanations when AI-driven (Austrian DPA challenges), collectively establishing that Article 22 creates de facto requirement for explainable AI in high-stakes contexts as unexplainable decisions cannot satisfy right to explanation, with decision types commonly subject to Article 22 including credit scoring, recruitment and employment decisions, healthcare diagnoses and treatment recommendations, insurance underwriting and claims processing, and profiling for targeted advertising or content curation when producing significant effects.",
    "source_domain": "ai-grounded",
    "maturity_level": null,
    "authority_score": 0.95
  }
}