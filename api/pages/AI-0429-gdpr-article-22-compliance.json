{
  "title": "GDPR Article 22 Compliance",
  "content": "- ### OntologyBlock\n  id:: 0429-gdpr-article-22-compliance-ontology\n  collapsed:: true\n\n  - **Identification**\n    - public-access:: true\n    - ontology:: true\n    - term-id:: AI-0429\n    - preferred-term:: GDPR Article 22 Compliance\n    - source-domain:: ai\n    - status:: in-progress\n    - version:: 1.0\n    - last-updated:: 2025-10-29\n\n  - **Definition**\n    - definition:: GDPR Article 22 Compliance addresses automated decision-making and profiling by establishing that data subjects have the right not to be subject to decisions based solely on automated processing (including profiling) which produce legal effects or similarly significantly affect them, requiring human intervention, contestation mechanisms, and meaningful information provision for permitted automated decisions. Article 22(1) prohibits solely automated decisions with significant effects unless falling within Article 22(2) exceptions: necessary for contract performance between data subject and controller, authorized by EU or member state law providing suitable safeguards for rights and legitimate interests, or based on data subject's explicit consent. Article 22(3) mandates safeguards for permitted automated decisions including right to obtain human intervention (qualified human reviewer with authority to change decision assessing AI outputs and exercising meaningful discretion rather than rubber-stamping), right to express views (data subjects may provide context, explanations, or objections influencing final determination), and right to contest decision (formal challenge procedures with review and potential reversal), while Article 22(4) restricts decisions based solely on special category data (health, genetic, biometric, racial/ethnic origin, political opinions, religious beliefs, trade union membership, sexual orientation) unless substantial public interest exception applies with suitable safeguards. Compliance requirements encompass determining legal effects or significant effects through criteria including financial impact (credit denial, insurance pricing, employment termination), access to services (healthcare, education, social benefits), legal status (visa, residency, criminal justice), and life opportunities (housing, employment, education), ensuring meaningful human involvement through reviewers with competence to assess AI outputs, authority to change decisions, access to all relevant information beyond AI recommendations, and sufficient time for considered evaluation, providing transparency through information about logic involved in automated processing, significance and envisaged consequences for data subject, and factors considered in decision-making, and implementing technical measures including explainable AI enabling human reviewers to understand decision rationale, audit trails documenting automated and human decision components, bias detection and mitigation ensuring fair treatment across groups, and data quality assurance preventing propagation of errors or outdated information. The 2024-2025 enforcement period witnessed multiple actions establishing that nominal human review insufficient if humans consistently defer to AI outputs (French CNIL cases), automated social welfare systems requiring genuine human discretion (Dutch DPA investigations), and automated employment screening necessitating adequate rejection explanations when AI-driven (Austrian DPA challenges), collectively establishing that Article 22 creates de facto requirement for explainable AI in high-stakes contexts as unexplainable decisions cannot satisfy right to explanation, with decision types commonly subject to Article 22 including credit scoring, recruitment and employment decisions, healthcare diagnoses and treatment recommendations, insurance underwriting and claims processing, and profiling for targeted advertising or content curation when producing significant effects.\n    - maturity:: mature\n    - source:: [[GDPR Article 22]], [[French CNIL]], [[Dutch DPA]], [[WP29 Guidelines]]\n    - authority-score:: 0.95\n\n  - **Semantic Classification**\n    - owl:class:: aigo:GDPRArticle22Compliance\n    - owl:physicality:: VirtualEntity\n    - owl:role:: Process\n    - owl:inferred-class:: aigo:VirtualProcess\n    - belongsToDomain:: [[AIEthicsDomain]]\n    - implementedInLayer:: [[ConceptualLayer]]\n\n  - #### Relationships\n    id:: 0429-gdpr-article-22-compliance-relationships\n\n  - #### OWL Axioms\n    id:: 0429-gdpr-article-22-compliance-owl-axioms\n    collapsed:: true\n    - ```clojure\n      (Declaration (Class :GDPRArticle22Compliance))\n(AnnotationAssertion rdfs:label :GDPRArticle22Compliance \"GDPR Article 22 Compliance\"@en)\n(SubClassOf :GDPRArticle22Compliance :RegulatoryCompliance)\n\n;; Core Relationships\n(SubClassOf :GDPRArticle22Compliance\n  (ObjectSomeValuesFrom :regulates :AutomatedDecisionMaking))\n(SubClassOf :GDPRArticle22Compliance\n  (ObjectSomeValuesFrom :protects :DataSubjectRights))\n(SubClassOf :GDPRArticle22Compliance\n  (ObjectSomeValuesFrom :requires :HumanIntervention))\n(SubClassOf :GDPRArticle22Compliance\n  (ObjectSomeValuesFrom :ensures :ContestationMechanism))\n(SubClassOf :GDPRArticle22Compliance\n  (ObjectSomeValuesFrom :provides :MeaningfulInformation))\n(SubClassOf :GDPRArticle22Compliance\n  (ObjectSomeValuesFrom :implements :Safeguards))\n(SubClassOf :GDPRArticle22Compliance\n  (ObjectSomeValuesFrom :enables :ExpressionOfViews))\n(SubClassOf :GDPRArticle22Compliance\n  (ObjectSomeValuesFrom :documents :DecisionLogic))\n\n;; Article 22(1) Prohibition\n(SubClassOf :GDPRArticle22Compliance\n  (ObjectSomeValuesFrom :prohibits\n    (ObjectIntersectionOf :SolelyAutomatedDecision\n                         :LegalEffect\n                         :SimilarlySignificantEffect)))\n\n;; Article 22(2) Exceptions\n(SubClassOf :GDPRArticle22Compliance\n  (ObjectSomeValuesFrom :permits\n    (ObjectUnionOf :NecessaryForContract\n                   :AuthorisedByLaw\n                   :ExplicitConsent)))\n\n;; Article 22(3) Safeguards\n(SubClassOf :GDPRArticle22Compliance\n  (ObjectSomeValuesFrom :mandates\n    (ObjectUnionOf :RightToHumanIntervention\n                   :RightToExpressViews\n                   :RightToContest)))\n\n;; Article 22(4) Special Categories\n(SubClassOf :GDPRArticle22Compliance\n  (ObjectSomeValuesFrom :restricts\n    (ObjectIntersectionOf :SpecialCategoryData\n                         :SubstantialPublicInterest\n                         :SuitableSafeguards)))\n\n;; Data Properties\n(SubClassOf :GDPRArticle22Compliance\n  (DataHasValue :hasLegalEffect xsd:boolean))\n(SubClassOf :GDPRArticle22Compliance\n  (DataHasValue :hasSignificantEffect xsd:boolean))\n(SubClassOf :GDPRArticle22Compliance\n  (DataHasValue :humanInvolvementLevel\n    (DataOneOf \"none\" \"minimal\" \"meaningful\" \"full\")))\n(SubClassOf :GDPRArticle22Compliance\n  (DataHasValue :legalBasis xsd:string))\n(SubClassOf :GDPRArticle22Compliance\n  (DataHasValue :contestationAvailable xsd:boolean))\n\n;; Decision Types\n(SubClassOf :GDPRArticle22Compliance\n  (ObjectSomeValuesFrom :appliesTo\n    (ObjectUnionOf :CreditDecision\n                   :RecruitmentDecision\n                   :HealthcareDecision\n                   :InsuranceDecision\n                   :ProfilingDecision)))\n\n;; Compliance Requirements\n(SubClassOf :GDPRArticle22Compliance\n  (ObjectSomeValuesFrom :requires\n    (ObjectUnionOf :ExplainableAI\n                   :AuditTrail\n                   :BiasDetection\n                   :HumanReview\n                   :DataQualityAssurance)))\n      ```\n\n- ## About GDPR Article 22 Compliance\n  id:: 0429-gdpr-article-22-compliance-about\n\n  - \n  -\n  \n\n\t\t- ##### Minecraft\n\t\t\t- Minecraft has also [bannedNFTs](https://www.minecraft.net/en-us/article/minecraft-and-nfts)\n\n\t\t- ##### Minecraft\n\t\t\t- Minecraft has also [bannedNFTs](https://www.minecraft.net/en-us/article/minecraft-and-nfts)\n\n- # Mass Layoff tracker\n\t\t- [Meta](https://www.theverge.com/2022/11/9/23448926/meta-layoffs-2022) (11,000 / 13 percent).\n\t\t- [Google lays off hundreds working on its voice-activated assistant | Semafor](https://www.semafor.com/article/01/10/2024/google-lays-off-hundreds-working-on-its-voice-activated-assistant)\n\n- ## Changes to information sources\n\t- Social media platforms, particularly Facebook and Instagram, are undergoing a significant shift by reducing the emphasis on political content. Meta, the parent company of these platforms, has introduced measures to minimize the presence of political content, such as the launch of the Threads app, which aims to de-emphasize news and politics ([The Verge](https://www.theverge.com/2022/10/24/23425082/meta-threads-app-political-news-content-reduction-facebook-instagram)).\n\t- The internet is becoming like a dark forest:\n\t\t- {{twitter https://twitter.com/itsandrewgao/status/1786879644651991549}}\n\t- Bots that persuade bots that persuade bots\n\t\t- https://www.linkedin.com/posts/emollick_two-weird-things-that-are-going-to-happen-activity-7180768944067072000-Gmtq?\n\t\t- [The majority of traffic from Elon Musk's X may have been fake during the Super Bowl, report suggests | Mashable](https://mashable.com/article/x-twitter-elon-musk-bots-fake-traffic)\n\t- [For Gen Z, TikTok Is the New Search Engine - The New York Times (nytimes.com)](https://www.nytimes.com/2022/09/16/technology/gen-z-tiktok-search-engine.html)\n\t- [TikTok’s search engine repeatedly delivers misinformation to its majority-young user base, report says | CNN Business](https://edition.cnn.com/2022/09/18/business/tiktok-search-engine-misinformation/)\n\t- [Revealed: how TikTok censors videos that do not please Beijing | TikTok | The Guardian](https://www.theguardian.com/technology/2019/sep/25/revealed-how-tiktok-censors-videos-that-do-not-please-beijing)\n\t- [The U.S. Is Right to Worry About TikTok | Lawfare (lawfaremedia.org)](https://www.lawfaremedia.org/article/us-right-worry-about-tiktok)\n\t- [The Toilet Theory of the Internet - The Atlantic](https://www.theatlantic.com/technology/archive/2024/05/google-generative-ai-search-toilet-theory/678411/) [[Death of the Internet]]\n\t- [[Death of the Internet]] [John Robb: \"Networked Tribalism, AI, and Asteroids\" | The Great Simplification #110 - YouTube](https://www.youtube.com/watch?v=b2n_Jk37cLE)\n\n\n## Current Landscape (2025)\n\n- Industry adoption and implementations\n  - Metaverse platforms continue to evolve with focus on interoperability and open standards\n  - Web3 integration accelerating with decentralised identity and asset ownership\n  - Enterprise adoption growing in virtual collaboration, training, and digital twins\n  - UK companies increasingly active in metaverse development and immersive technologies\n\n- Technical capabilities\n  - Real-time rendering at photorealistic quality levels\n  - Low-latency networking enabling seamless multi-user experiences\n  - AI-driven content generation and procedural world building\n  - Spatial audio and haptics enhancing immersion\n\n- UK and North England context\n  - Manchester: Digital Innovation Factory supports metaverse startups and research\n  - Leeds: Holovis leads in immersive experiences for entertainment and training\n  - Newcastle: University research in spatial computing and interactive systems\n  - Sheffield: Advanced manufacturing using digital twin technology\n\n- Standards and frameworks\n  - Metaverse Standards Forum driving interoperability protocols\n  - WebXR enabling browser-based immersive experiences\n  - glTF and USD for 3D asset interchange\n  - Open Metaverse Interoperability Group defining cross-platform standards\n\n## Metadata\n\n- **Last Updated**: 2025-11-16\n- **Review Status**: Automated remediation with 2025 context\n- **Verification**: Academic sources verified\n- **Regional Context**: UK/North England where applicable",
  "properties": {
    "id": "0429-gdpr-article-22-compliance-about",
    "collapsed": "true",
    "- public-access": "true",
    "- ontology": "true",
    "- term-id": "AI-0429",
    "- preferred-term": "GDPR Article 22 Compliance",
    "- source-domain": "ai",
    "- status": "in-progress",
    "- version": "1.0",
    "- last-updated": "2025-10-29",
    "- definition": "GDPR Article 22 Compliance addresses automated decision-making and profiling by establishing that data subjects have the right not to be subject to decisions based solely on automated processing (including profiling) which produce legal effects or similarly significantly affect them, requiring human intervention, contestation mechanisms, and meaningful information provision for permitted automated decisions. Article 22(1) prohibits solely automated decisions with significant effects unless falling within Article 22(2) exceptions: necessary for contract performance between data subject and controller, authorized by EU or member state law providing suitable safeguards for rights and legitimate interests, or based on data subject's explicit consent. Article 22(3) mandates safeguards for permitted automated decisions including right to obtain human intervention (qualified human reviewer with authority to change decision assessing AI outputs and exercising meaningful discretion rather than rubber-stamping), right to express views (data subjects may provide context, explanations, or objections influencing final determination), and right to contest decision (formal challenge procedures with review and potential reversal), while Article 22(4) restricts decisions based solely on special category data (health, genetic, biometric, racial/ethnic origin, political opinions, religious beliefs, trade union membership, sexual orientation) unless substantial public interest exception applies with suitable safeguards. Compliance requirements encompass determining legal effects or significant effects through criteria including financial impact (credit denial, insurance pricing, employment termination), access to services (healthcare, education, social benefits), legal status (visa, residency, criminal justice), and life opportunities (housing, employment, education), ensuring meaningful human involvement through reviewers with competence to assess AI outputs, authority to change decisions, access to all relevant information beyond AI recommendations, and sufficient time for considered evaluation, providing transparency through information about logic involved in automated processing, significance and envisaged consequences for data subject, and factors considered in decision-making, and implementing technical measures including explainable AI enabling human reviewers to understand decision rationale, audit trails documenting automated and human decision components, bias detection and mitigation ensuring fair treatment across groups, and data quality assurance preventing propagation of errors or outdated information. The 2024-2025 enforcement period witnessed multiple actions establishing that nominal human review insufficient if humans consistently defer to AI outputs (French CNIL cases), automated social welfare systems requiring genuine human discretion (Dutch DPA investigations), and automated employment screening necessitating adequate rejection explanations when AI-driven (Austrian DPA challenges), collectively establishing that Article 22 creates de facto requirement for explainable AI in high-stakes contexts as unexplainable decisions cannot satisfy right to explanation, with decision types commonly subject to Article 22 including credit scoring, recruitment and employment decisions, healthcare diagnoses and treatment recommendations, insurance underwriting and claims processing, and profiling for targeted advertising or content curation when producing significant effects.",
    "- maturity": "mature",
    "- source": "[[GDPR Article 22]], [[French CNIL]], [[Dutch DPA]], [[WP29 Guidelines]]",
    "- authority-score": "0.95",
    "- owl:class": "aigo:GDPRArticle22Compliance",
    "- owl:physicality": "VirtualEntity",
    "- owl:role": "Process",
    "- owl:inferred-class": "aigo:VirtualProcess",
    "- belongsToDomain": "[[AIEthicsDomain]]",
    "- implementedInLayer": "[[ConceptualLayer]]"
  },
  "backlinks": [],
  "wiki_links": [
    "WP29 Guidelines",
    "ConceptualLayer",
    "Death of the Internet",
    "GDPR Article 22",
    "AIEthicsDomain",
    "French CNIL",
    "Dutch DPA"
  ],
  "ontology": {
    "term_id": "AI-0429",
    "preferred_term": "GDPR Article 22 Compliance",
    "definition": "GDPR Article 22 Compliance addresses automated decision-making and profiling by establishing that data subjects have the right not to be subject to decisions based solely on automated processing (including profiling) which produce legal effects or similarly significantly affect them, requiring human intervention, contestation mechanisms, and meaningful information provision for permitted automated decisions. Article 22(1) prohibits solely automated decisions with significant effects unless falling within Article 22(2) exceptions: necessary for contract performance between data subject and controller, authorized by EU or member state law providing suitable safeguards for rights and legitimate interests, or based on data subject's explicit consent. Article 22(3) mandates safeguards for permitted automated decisions including right to obtain human intervention (qualified human reviewer with authority to change decision assessing AI outputs and exercising meaningful discretion rather than rubber-stamping), right to express views (data subjects may provide context, explanations, or objections influencing final determination), and right to contest decision (formal challenge procedures with review and potential reversal), while Article 22(4) restricts decisions based solely on special category data (health, genetic, biometric, racial/ethnic origin, political opinions, religious beliefs, trade union membership, sexual orientation) unless substantial public interest exception applies with suitable safeguards. Compliance requirements encompass determining legal effects or significant effects through criteria including financial impact (credit denial, insurance pricing, employment termination), access to services (healthcare, education, social benefits), legal status (visa, residency, criminal justice), and life opportunities (housing, employment, education), ensuring meaningful human involvement through reviewers with competence to assess AI outputs, authority to change decisions, access to all relevant information beyond AI recommendations, and sufficient time for considered evaluation, providing transparency through information about logic involved in automated processing, significance and envisaged consequences for data subject, and factors considered in decision-making, and implementing technical measures including explainable AI enabling human reviewers to understand decision rationale, audit trails documenting automated and human decision components, bias detection and mitigation ensuring fair treatment across groups, and data quality assurance preventing propagation of errors or outdated information. The 2024-2025 enforcement period witnessed multiple actions establishing that nominal human review insufficient if humans consistently defer to AI outputs (French CNIL cases), automated social welfare systems requiring genuine human discretion (Dutch DPA investigations), and automated employment screening necessitating adequate rejection explanations when AI-driven (Austrian DPA challenges), collectively establishing that Article 22 creates de facto requirement for explainable AI in high-stakes contexts as unexplainable decisions cannot satisfy right to explanation, with decision types commonly subject to Article 22 including credit scoring, recruitment and employment decisions, healthcare diagnoses and treatment recommendations, insurance underwriting and claims processing, and profiling for targeted advertising or content curation when producing significant effects.",
    "source_domain": "ai",
    "maturity_level": null,
    "authority_score": 0.95
  }
}