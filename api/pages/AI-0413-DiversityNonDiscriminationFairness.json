{
  "title": "Diversity, Non-Discrimination, and Fairness",
  "content": "- ### OntologyBlock\n  id:: 0413-diversitynondiscriminationfairness-ontology\n  collapsed:: true\n\n  - **Identification**\n    - public-access:: true\n    - ontology:: true\n    - is-subclass-of:: [[ArtificialIntelligenceTechnology]]\n    - term-id:: AI-0413\n    - preferred-term:: Diversity, Non-Discrimination, and Fairness\n    - source-domain:: ai-grounded\n    - status:: in-progress\n    - version:: 1.0\n    - last-updated:: 2025-10-29\n\n  - **Definition**\n    - definition:: Diversity Non-Discrimination and Fairness is a trustworthiness dimension ensuring AI systems avoid unfair bias, ensure equitable treatment across demographic groups, implement accessibility and universal design, and enable inclusive stakeholder participation throughout development and deployment. This dimension encompasses three core components: unfair bias avoidance (identifying bias affecting protected characteristics including sex, racial or ethnic origin, religion, disability, age, and sexual orientation per EU Charter Article 21, implementing bias mitigation through pre-processing data corrections, in-processing fairness constraints, and post-processing prediction adjustments, and continuously monitoring fairness metrics including demographic parity requiring equal selection rates across groups, equalized odds ensuring equal true positive and false positive rates, equal opportunity guaranteeing equal true positive rates, and individual fairness treating similar individuals similarly), accessibility and universal design (complying with Web Content Accessibility Guidelines WCAG ensuring perceivable, operable, understandable, and robust interfaces, implementing European Accessibility Act requirements, and applying universal design principles creating systems usable by people with diverse abilities without specialized adaptation), and stakeholder participation (involving diverse stakeholders including end users, affected communities, domain experts, and civil society throughout development lifecycle, implementing participatory design methodologies enabling co-creation with affected populations, and ensuring representative development teams reflecting diversity of deployment contexts and user populations). Legal frameworks including the EU AI Act mandate high-risk systems implement data governance ensuring training, validation, and testing datasets are relevant, representative, accurate, complete, and free from errors, with potential biases identified and mitigated. The 2024-2025 period marked transition from voluntary fairness practices to legally mandated requirements with enforcement mechanisms across jurisdictions including EU AI Act penalties reaching EUR 35 million or 7% of worldwide annual turnover, U.S. state-level legislation including Colorado AI Act and New York City Bias Audit Law, and international standards including ISO/IEC TR 24027:2021 for bias detection and ISO/IEC 42001:2023 for AI risk management, with regulatory sandboxes enabling deliberate testing to expose unwanted bias before deployment.\n    - maturity:: mature\n    - source:: [[EU AI Act]], [[EU Charter Article 21]], [[ISO/IEC TR 24027]], [[WCAG]]\n    - authority-score:: 0.95\n\n  - **Semantic Classification**\n    - owl:class:: aigo:DiversityNonDiscriminationFairness\n    - owl:physicality:: VirtualEntity\n    - owl:role:: Process\n    - owl:inferred-class:: aigo:VirtualProcess\n    - belongsToDomain:: [[AIEthicsDomain]]\n    - implementedInLayer:: [[ConceptualLayer]]\n\n  - #### Relationships\n    id:: 0413-diversitynondiscriminationfairness-relationships\n\n  - #### OWL Axioms\n    id:: 0413-diversitynondiscriminationfairness-owl-axioms\n    collapsed:: true\n    - ```clojure\n      (Declaration (Class :DiversityNonDiscriminationFairness))\n(SubClassOf :DiversityNonDiscriminationFairness :TrustworthinessDimension)\n(SubClassOf :DiversityNonDiscriminationFairness :FundamentalRightsRequirement)\n\n;; Three core components\n(Declaration (Class :UnfairBiasAvoidance))\n(Declaration (Class :AccessibilityUniversalDesign))\n(Declaration (Class :StakeholderParticipation))\n\n(SubClassOf :UnfairBiasAvoidance :DiversityNonDiscriminationFairness)\n(SubClassOf :AccessibilityUniversalDesign :DiversityNonDiscriminationFairness)\n(SubClassOf :StakeholderParticipation :DiversityNonDiscriminationFairness)\n\n;; Bias avoidance requirements\n(SubClassOf :UnfairBiasAvoidance\n  (ObjectSomeValuesFrom :identifiesBias :ProtectedCharacteristic))\n(SubClassOf :UnfairBiasAvoidance\n  (ObjectSomeValuesFrom :mitigates :AlgorithmicBias))\n(SubClassOf :UnfairBiasAvoidance\n  (ObjectSomeValuesFrom :monitors :FairnessMetric))\n\n;; Protected characteristics (EU Charter Article 21)\n(Declaration (Class :ProtectedCharacteristic))\n(Declaration (Class :Sex))\n(Declaration (Class :RacialEthnicOrigin))\n(Declaration (Class :Religion))\n(Declaration (Class :Disability))\n(Declaration (Class :Age))\n(Declaration (Class :SexualOrientation))\n\n(SubClassOf :Sex :ProtectedCharacteristic)\n(SubClassOf :RacialEthnicOrigin :ProtectedCharacteristic)\n(SubClassOf :Religion :ProtectedCharacteristic)\n(SubClassOf :Disability :ProtectedCharacteristic)\n(SubClassOf :Age :ProtectedCharacteristic)\n(SubClassOf :SexualOrientation :ProtectedCharacteristic)\n\n;; Fairness definitions\n(Declaration (Class :FairnessDefinition))\n(Declaration (Class :DemographicParity))\n(Declaration (Class :EqualOpportunity))\n(Declaration (Class :EqualOdds))\n(Declaration (Class :IndividualFairness))\n\n(SubClassOf :DemographicParity :FairnessDefinition)\n(SubClassOf :EqualOpportunity :FairnessDefinition)\n(SubClassOf :EqualOdds :FairnessDefinition)\n(SubClassOf :IndividualFairness :FairnessDefinition)\n\n;; Accessibility requirements\n(SubClassOf :AccessibilityUniversalDesign\n  (ObjectSomeValuesFrom :compliesWith :WCAG))\n(SubClassOf :AccessibilityUniversalDesign\n  (ObjectSomeValuesFrom :compliesWith :EuropeanAccessibilityAct))\n(SubClassOf :AccessibilityUniversalDesign\n  (ObjectSomeValuesFrom :implements :UniversalDesignPrinciple))\n\n;; Stakeholder participation requirements\n(SubClassOf :StakeholderParticipation\n  (ObjectSomeValuesFrom :involves :DiverseStakeholders))\n(SubClassOf :StakeholderParticipation\n  (ObjectSomeValuesFrom :implements :ParticipatoryDesign))\n(SubClassOf :StakeholderParticipation\n  (ObjectSomeValuesFrom :ensures :RepresentativeDevelopmentTeam))\n\n(DisjointClasses :DiversityNonDiscriminationFairness :DiscriminatorySystem)\n(DisjointClasses :DiversityNonDiscriminationFairness :BiasedSystem)\n      ```",
  "properties": {
    "id": "0413-diversitynondiscriminationfairness-owl-axioms",
    "collapsed": "true",
    "- public-access": "true",
    "- ontology": "true",
    "- is-subclass-of": "[[ArtificialIntelligenceTechnology]]",
    "- term-id": "AI-0413",
    "- preferred-term": "Diversity, Non-Discrimination, and Fairness",
    "- source-domain": "ai-grounded",
    "- status": "in-progress",
    "- version": "1.0",
    "- last-updated": "2025-10-29",
    "- definition": "Diversity Non-Discrimination and Fairness is a trustworthiness dimension ensuring AI systems avoid unfair bias, ensure equitable treatment across demographic groups, implement accessibility and universal design, and enable inclusive stakeholder participation throughout development and deployment. This dimension encompasses three core components: unfair bias avoidance (identifying bias affecting protected characteristics including sex, racial or ethnic origin, religion, disability, age, and sexual orientation per EU Charter Article 21, implementing bias mitigation through pre-processing data corrections, in-processing fairness constraints, and post-processing prediction adjustments, and continuously monitoring fairness metrics including demographic parity requiring equal selection rates across groups, equalized odds ensuring equal true positive and false positive rates, equal opportunity guaranteeing equal true positive rates, and individual fairness treating similar individuals similarly), accessibility and universal design (complying with Web Content Accessibility Guidelines WCAG ensuring perceivable, operable, understandable, and robust interfaces, implementing European Accessibility Act requirements, and applying universal design principles creating systems usable by people with diverse abilities without specialized adaptation), and stakeholder participation (involving diverse stakeholders including end users, affected communities, domain experts, and civil society throughout development lifecycle, implementing participatory design methodologies enabling co-creation with affected populations, and ensuring representative development teams reflecting diversity of deployment contexts and user populations). Legal frameworks including the EU AI Act mandate high-risk systems implement data governance ensuring training, validation, and testing datasets are relevant, representative, accurate, complete, and free from errors, with potential biases identified and mitigated. The 2024-2025 period marked transition from voluntary fairness practices to legally mandated requirements with enforcement mechanisms across jurisdictions including EU AI Act penalties reaching EUR 35 million or 7% of worldwide annual turnover, U.S. state-level legislation including Colorado AI Act and New York City Bias Audit Law, and international standards including ISO/IEC TR 24027:2021 for bias detection and ISO/IEC 42001:2023 for AI risk management, with regulatory sandboxes enabling deliberate testing to expose unwanted bias before deployment.",
    "- maturity": "mature",
    "- source": "[[EU AI Act]], [[EU Charter Article 21]], [[ISO/IEC TR 24027]], [[WCAG]]",
    "- authority-score": "0.95",
    "- owl:class": "aigo:DiversityNonDiscriminationFairness",
    "- owl:physicality": "VirtualEntity",
    "- owl:role": "Process",
    "- owl:inferred-class": "aigo:VirtualProcess",
    "- belongsToDomain": "[[AIEthicsDomain]]",
    "- implementedInLayer": "[[ConceptualLayer]]"
  },
  "backlinks": [],
  "wiki_links": [
    "ConceptualLayer",
    "ArtificialIntelligenceTechnology",
    "EU AI Act",
    "ISO/IEC TR 24027",
    "EU Charter Article 21",
    "WCAG",
    "AIEthicsDomain"
  ],
  "ontology": {
    "term_id": "AI-0413",
    "preferred_term": "Diversity, Non-Discrimination, and Fairness",
    "definition": "Diversity Non-Discrimination and Fairness is a trustworthiness dimension ensuring AI systems avoid unfair bias, ensure equitable treatment across demographic groups, implement accessibility and universal design, and enable inclusive stakeholder participation throughout development and deployment. This dimension encompasses three core components: unfair bias avoidance (identifying bias affecting protected characteristics including sex, racial or ethnic origin, religion, disability, age, and sexual orientation per EU Charter Article 21, implementing bias mitigation through pre-processing data corrections, in-processing fairness constraints, and post-processing prediction adjustments, and continuously monitoring fairness metrics including demographic parity requiring equal selection rates across groups, equalized odds ensuring equal true positive and false positive rates, equal opportunity guaranteeing equal true positive rates, and individual fairness treating similar individuals similarly), accessibility and universal design (complying with Web Content Accessibility Guidelines WCAG ensuring perceivable, operable, understandable, and robust interfaces, implementing European Accessibility Act requirements, and applying universal design principles creating systems usable by people with diverse abilities without specialized adaptation), and stakeholder participation (involving diverse stakeholders including end users, affected communities, domain experts, and civil society throughout development lifecycle, implementing participatory design methodologies enabling co-creation with affected populations, and ensuring representative development teams reflecting diversity of deployment contexts and user populations). Legal frameworks including the EU AI Act mandate high-risk systems implement data governance ensuring training, validation, and testing datasets are relevant, representative, accurate, complete, and free from errors, with potential biases identified and mitigated. The 2024-2025 period marked transition from voluntary fairness practices to legally mandated requirements with enforcement mechanisms across jurisdictions including EU AI Act penalties reaching EUR 35 million or 7% of worldwide annual turnover, U.S. state-level legislation including Colorado AI Act and New York City Bias Audit Law, and international standards including ISO/IEC TR 24027:2021 for bias detection and ISO/IEC 42001:2023 for AI risk management, with regulatory sandboxes enabling deliberate testing to expose unwanted bias before deployment.",
    "source_domain": "ai-grounded",
    "maturity_level": null,
    "authority_score": 0.95
  }
}