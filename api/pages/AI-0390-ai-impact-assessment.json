{
  "title": "0390 Ai Impact Assessment",
  "content": "- ### OntologyBlock\n  id:: 0390-ai-impact-assessment-ontology\n  collapsed:: true\n\n  - **Identification**\n    - public-access:: true\n    - ontology:: true\n    - term-id:: AI-0390\n    - preferred-term:: 0390 Ai Impact Assessment\n    - source-domain:: ai-grounded\n    - status:: in-progress\n    - version:: 1.0\n    - last-updated:: 2025-10-29\n\n  - **Definition**\n    - definition:: AI Impact Assessment is a structured evaluation methodology that systematically identifies, analyzes, and documents potential positive and negative impacts of AI systems on individuals, groups, organizations, society, and the environment, informing risk mitigation and responsible deployment decisions. This assessment process evaluates technical performance, ethical risks, human rights implications, societal consequences, and environmental effects, incorporating stakeholder perspectives and expert analysis to produce comprehensive impact reports. Key assessment dimensions include fairness and discrimination impacts (disparate treatment of protected groups, reinforcement of historical inequalities), privacy and data protection effects (surveillance risks, consent violations, data security), autonomy and human agency implications (erosion of human decision-making, manipulation risks), safety and security risks (system failures, adversarial attacks, unintended consequences), labor and economic impacts (job displacement, skill requirements, economic concentration), social and cultural effects (social cohesion, cultural values, power dynamics), and environmental sustainability (energy consumption, resource requirements, carbon footprint). The assessment methodology follows structured stages: scoping and system characterization, stakeholder identification and engagement, impact identification through workshops and analysis, severity and likelihood evaluation, mitigation measure design, residual risk assessment, and ongoing monitoring protocols. This process shares methodological foundations with Data Protection Impact Assessments (GDPR Article 35), Human Rights Impact Assessments, and Environmental Impact Assessments, adapted for AI-specific contexts. Requirements for impact assessments appear in the EU AI Act Articles 9 and 27, Canada's Algorithmic Impact Assessment, and ISO/IEC 23894:2023 guidance on AI risk management.\n    - maturity:: mature\n    - source:: [[EU AI Act]], [[ISO/IEC 23894:2023]], [[Canada AIA]]\n    - authority-score:: 0.95\n\n  - **Semantic Classification**\n    - owl:class:: aigo:AIGovernancePrinciple\n    - owl:physicality:: VirtualEntity\n    - owl:role:: Process\n    - owl:inferred-class:: aigo:VirtualProcess\n    - belongsToDomain:: [[AIEthicsDomain]]\n    - implementedInLayer:: [[ConceptualLayer]]\n\n  - #### Relationships\n    id:: 0390-ai-impact-assessment-relationships\n\n  - #### OWL Axioms\n    id:: 0390-ai-impact-assessment-owl-axioms\n    collapsed:: true\n    - ```clojure\n      (Declaration (Class :AIImpactAssessment))\n(SubClassOf :AIImpactAssessment :TechnologyImpactAssessment)\n\n(SubClassOf :AIImpactAssessment\n  (ObjectSomeValuesFrom :evaluates :AISystem))\n(SubClassOf :AIImpactAssessment\n  (ObjectSomeValuesFrom :identifies :PotentialImpact))\n(SubClassOf :AIImpactAssessment\n  (ObjectSomeValuesFrom :analyzes :EthicalRisk))\n(SubClassOf :AIImpactAssessment\n  (ObjectSomeValuesFrom :assesses :HumanRightsImpact))\n(SubClassOf :AIImpactAssessment\n  (ObjectSomeValuesFrom :proposes :MitigationMeasure))\n(SubClassOf :AIImpactAssessment\n  (ObjectSomeValuesFrom :informs :DecisionMaking))\n\n(DisjointWith :AIImpactAssessment :DataProtectionImpactAssessment)\n(DisjointWith :AIImpactAssessment :EnvironmentalImpactAssessment)\n\n(SubClassOf :AIImpactAssessment\n  (ObjectIntersectionOf\n    (ObjectSomeValuesFrom :incorporates :StakeholderInput)\n    (ObjectSomeValuesFrom :produces :ImpactReport)))\n      ```\n\n- ## About AI Impact Assessment\n  id:: 0390-ai-impact-assessment-about\n\n  - \n  -",
  "properties": {
    "id": "0390-ai-impact-assessment-about",
    "collapsed": "true",
    "- public-access": "true",
    "- ontology": "true",
    "- term-id": "AI-0390",
    "- preferred-term": "0390 Ai Impact Assessment",
    "- source-domain": "ai-grounded",
    "- status": "in-progress",
    "- version": "1.0",
    "- last-updated": "2025-10-29",
    "- definition": "AI Impact Assessment is a structured evaluation methodology that systematically identifies, analyzes, and documents potential positive and negative impacts of AI systems on individuals, groups, organizations, society, and the environment, informing risk mitigation and responsible deployment decisions. This assessment process evaluates technical performance, ethical risks, human rights implications, societal consequences, and environmental effects, incorporating stakeholder perspectives and expert analysis to produce comprehensive impact reports. Key assessment dimensions include fairness and discrimination impacts (disparate treatment of protected groups, reinforcement of historical inequalities), privacy and data protection effects (surveillance risks, consent violations, data security), autonomy and human agency implications (erosion of human decision-making, manipulation risks), safety and security risks (system failures, adversarial attacks, unintended consequences), labor and economic impacts (job displacement, skill requirements, economic concentration), social and cultural effects (social cohesion, cultural values, power dynamics), and environmental sustainability (energy consumption, resource requirements, carbon footprint). The assessment methodology follows structured stages: scoping and system characterization, stakeholder identification and engagement, impact identification through workshops and analysis, severity and likelihood evaluation, mitigation measure design, residual risk assessment, and ongoing monitoring protocols. This process shares methodological foundations with Data Protection Impact Assessments (GDPR Article 35), Human Rights Impact Assessments, and Environmental Impact Assessments, adapted for AI-specific contexts. Requirements for impact assessments appear in the EU AI Act Articles 9 and 27, Canada's Algorithmic Impact Assessment, and ISO/IEC 23894:2023 guidance on AI risk management.",
    "- maturity": "mature",
    "- source": "[[EU AI Act]], [[ISO/IEC 23894:2023]], [[Canada AIA]]",
    "- authority-score": "0.95",
    "- owl:class": "aigo:AIGovernancePrinciple",
    "- owl:physicality": "VirtualEntity",
    "- owl:role": "Process",
    "- owl:inferred-class": "aigo:VirtualProcess",
    "- belongsToDomain": "[[AIEthicsDomain]]",
    "- implementedInLayer": "[[ConceptualLayer]]"
  },
  "backlinks": [],
  "wiki_links": [
    "AIEthicsDomain",
    "ISO/IEC 23894:2023",
    "EU AI Act",
    "Canada AIA",
    "ConceptualLayer"
  ],
  "ontology": {
    "term_id": "AI-0390",
    "preferred_term": "0390 Ai Impact Assessment",
    "definition": "AI Impact Assessment is a structured evaluation methodology that systematically identifies, analyzes, and documents potential positive and negative impacts of AI systems on individuals, groups, organizations, society, and the environment, informing risk mitigation and responsible deployment decisions. This assessment process evaluates technical performance, ethical risks, human rights implications, societal consequences, and environmental effects, incorporating stakeholder perspectives and expert analysis to produce comprehensive impact reports. Key assessment dimensions include fairness and discrimination impacts (disparate treatment of protected groups, reinforcement of historical inequalities), privacy and data protection effects (surveillance risks, consent violations, data security), autonomy and human agency implications (erosion of human decision-making, manipulation risks), safety and security risks (system failures, adversarial attacks, unintended consequences), labor and economic impacts (job displacement, skill requirements, economic concentration), social and cultural effects (social cohesion, cultural values, power dynamics), and environmental sustainability (energy consumption, resource requirements, carbon footprint). The assessment methodology follows structured stages: scoping and system characterization, stakeholder identification and engagement, impact identification through workshops and analysis, severity and likelihood evaluation, mitigation measure design, residual risk assessment, and ongoing monitoring protocols. This process shares methodological foundations with Data Protection Impact Assessments (GDPR Article 35), Human Rights Impact Assessments, and Environmental Impact Assessments, adapted for AI-specific contexts. Requirements for impact assessments appear in the EU AI Act Articles 9 and 27, Canada's Algorithmic Impact Assessment, and ISO/IEC 23894:2023 guidance on AI risk management.",
    "source_domain": "ai-grounded",
    "maturity_level": null,
    "authority_score": 0.95
  }
}