{
  "id": "Stakeholder",
  "title": "Stakeholder",
  "content": "- ### OntologyBlock\n  id:: stakeholder-ontology\n  collapsed:: true\n\t- ontology:: true\n\t- term-id:: AI-0101\n\t- preferred-term:: Stakeholder\n\t- source-domain:: metaverse\n\t- status:: draft\n\t- public-access:: true\n\n\n\n\n### OWL Classification\n\t- owl:class:: mv:Stakeholder\n\t- owl:physicality:: ConceptualEntity\n\t- owl:role:: Concept\n\n### Domain & Architecture\n\t- belongsToDomain:: [[MetaverseDomain]]\n\t- maturity:: draft\n\n### Relationships\nid:: stakeholder-relationships\n\t\t- is-subclass-of:: [[Metaverse]]\n\n## OWL Formal Semantics\n\n```clojure\n;; OWL Functional Syntax\n\n(Declaration (Class :Stakeholder))\n\n;; Annotations\n(AnnotationAssertion rdfs:label :Stakeholder \"Stakeholder\"@en)\n(AnnotationAssertion rdfs:comment :Stakeholder \"Any individual, group, organisation, or entity that has an interest in, is affected by, influences, or holds rights regarding an artificial intelligence system throughout its lifecycle, including those who develop, deploy, operate, use, regulate, are impacted by, or hold accountability for AI systems, as well as broader society and communities whose interests may be affected by AI system design, deployment, or outcomes, encompassing both direct participants in AI value chains and indirect partie\"@en)\n\n;; Semantic Relationships\n(SubClassOf :Stakeholder\n  (ObjectSomeValuesFrom :appliesTo :AiUser))\n(SubClassOf :Stakeholder\n  (ObjectSomeValuesFrom :relatedTo :Transparency))\n(SubClassOf :Stakeholder\n  (ObjectSomeValuesFrom :relatedTo :Accountability))\n(SubClassOf :Stakeholder\n  (ObjectSomeValuesFrom :relatedTo :Fairness))\n(SubClassOf :Stakeholder\n  (ObjectSomeValuesFrom :relatedTo :AiImpactAssessment))\n\n;; Data Properties\n(AnnotationAssertion dcterms:identifier :Stakeholder \"AI-0101\"^^xsd:string)\n(DataPropertyAssertion :isAITechnology :Stakeholder \"true\"^^xsd:boolean)\n```\n\n## Context and Significance\n\nStakeholder engagement represents a fundamental principle of responsible and trustworthy AI development and deployment. AI systems, unlike many traditional technologies, can affect broad populations beyond immediate users, create distributional impacts across society, and raise complex ethical questions requiring diverse perspectives. Effective stakeholder identification, engagement, and consideration ensures that AI systems account for varied interests, values, and concerns, reduces risks of unintended consequences, and builds social licence for beneficial AI applications.\n\nThe NIST AI Risk Management Framework emphasises stakeholder participation as essential to the GOVERN function, noting that trustworthy AI requires incorporating diverse perspectives throughout the AI lifecycle. ISO/IEC 42001 mandates organisations to identify and understand stakeholder needs and expectations as a foundational requirement of AI management systems. The EU AI Act reflects stakeholder concerns through requirements for impact assessments, transparency, and various protective measures addressing different stakeholder interests.\n\nStakeholder engagement must be inclusive, meaningful, and sustained—reaching beyond easily accessible parties to include marginalised groups, addressing power imbalances, providing genuine influence over decisions, and maintaining dialogue throughout the AI lifecycle rather than treating engagement as a one-time activity.\n\n## Key Characteristics\n\n- **Diverse composition**: Wide range of roles, interests, and perspectives\n- **Varied proximity**: Direct involvement to indirect societal impacts\n- **Power dynamics**: Differing influence and resources across stakeholders\n- **Competing interests**: Potential conflicts requiring bal ancing\n- **Lifecycle involvement**: Engagement relevant at different phases\n- **Rights and responsibilities**: Legal, ethical, and practical entitlements\n- **Dynamic membership**: Stakeholder relevance evolves with AI system changes\n- **Multi-level**: Individual, organisational, community, and societal stakeholders\n\n## Stakeholder Categories\n\n### 1. Development Stakeholders\n- **AI Developers**: Engineers, data scientists, ML researchers\n- **Organisational Leadership**: Executives, product managers, strategists\n- **Technical Infrastructure**: IT staff, platform providers, tool vendors\n- **Funding Sources**: Investors, grant providers, sponsors\n- **Research Subjects**: Individuals providing data or participating in studies\n\n### 2. Deployment and Operations Stakeholders\n- **AI Providers**: Entities supplying AI systems\n- **AI Operators**: Entities deploying and managing systems\n- **System Integrators**: Organisations incorporating AI into broader systems\n- **Maintenance Personnel**: Staff responsible for ongoing system operation\n- **Support Services**: Help desk, customer service, technical support\n\n### 3. User Stakeholders\n- **Direct Users**: Individuals actively interacting with AI systems\n- **Indirect Users**: People affected by AI outputs without direct interaction\n- **Customers**: Organisations or individuals purchasing AI services\n- **Professional Users**: Domain experts using AI as professional tools\n- **Vulnerable Users**: Groups facing heightened risks (children, elderly, disadvantaged)\n\n### 4. Affected Parties\n- **Decision Subjects**: Individuals about whom AI makes decisions\n- **Impacted Communities**: Groups experiencing collective AI effects\n- **Workers**: People whose employment affected by AI automation\n- **Competitors**: Market participants affected by AI-driven competition\n- **Environment**: Natural systems impacted by AI applications or infrastructure\n\n### 5. Governance and Oversight Stakeholders\n- **Regulators**: Government bodies enforcing AI-related laws\n- **Standards Bodies**: Organisations developing technical and ethical standards\n- **Ethics Committees**: Groups reviewing AI ethical implications\n- **Audit Organisations**: Entities conducting AI system assessments\n- **Legal System**: Courts, dispute resolution bodies, legal professionals\n\n### 6. Societal Stakeholders\n- **Civil Society**: NGOs, advocacy groups, community organisations\n- **Academia**: Researchers studying AI impacts and ethics\n- **Media**: Journalists, commentators shaping public discourse\n- **General Public**: Broader society with interest in AI's societal role\n- **Future Generations**: Those who will inherit AI-shaped world\n\n## Stakeholder Engagement Approaches\n\n### Identification\n- Systematic analysis of who is affected by or can influence AI system\n- Mapping of stakeholder relationships and interdependencies\n- Recognition of marginalised or less visible stakeholder groups\n- Periodic review as AI systems and contexts evolve\n\n### Analysis\n- Understanding stakeholder interests, concerns, and expectations\n- Assessing stakeholder influence, authority, and resources\n- Identifying potential conflicts and synergies among stakeholders\n- Recognising power imbalances and vulnerability factors\n\n### Engagement Methods\n- **Consultation**: Gathering stakeholder input and feedback\n- **Collaboration**: Working together on design and decision-making\n- **Participation**: Involving stakeholders in governance structures\n- **Information Provision**: Keeping stakeholders informed of developments\n- **Negotiation**: Addressing conflicts and finding acceptable solutions\n\n### Continuous Involvement\n- Ongoing dialogue throughout AI lifecycle, not just initial development\n- Feedback loops incorporating stakeholder input into improvements\n- Transparency about how stakeholder input influenced decisions\n- Accountability mechanisms ensuring stakeholder interests protected\n\n## Relationships\n\n- **Includes**: AI Provider, AI Operator, AI User, affected communities\n- **Inform**: AI Governance, ethical principles, design choices\n- **Participate in**: AI Impact Assessment, risk assessment, audits\n- **Subject of**: Stakeholder analysis, engagement planning\n- **Provide**: Requirements, feedback, oversight, accountability pressure\n- **Benefit from**: AI system capabilities and services\n- **Vulnerable to**: AI risks, harms, unfair treatment\n- **Shape**: Regulatory requirements, social licence, public discourse\n- **Monitored via**: Surveys, consultations, feedback mechanisms\n- **Represented in**: Governance bodies, advisory committees, user groups\n\n## Examples and Applications\n\n1. **Healthcare AI Stakeholder Engagement**: Hospital deploying diagnostic AI identifies stakeholders including patients (decision subjects), clinicians (professional users), hospital administrators (operators), AI vendor (provider), regulatory bodies (FDA, local health authorities), patient advocacy groups (civil society), medical ethics committee (oversight), and conducts multi-stakeholder workshops to define acceptable performance, oversight procedures, and transparency requirements\n2. **Employment AI Stakeholder Consultation**: Company implementing AI hiring tool engages HR staff (direct users), job applicants (affected parties), diversity and inclusion advocates (civil society), labour unions (worker representatives), legal compliance team (internal oversight), and external bias auditors, using feedback to establish human review requirements, transparency commitments, and fairness metrics\n3. **Smart City Surveillance Stakeholder Process**: Municipal government considering AI-enabled public safety system convenes residents (impacted community), civil liberties organisations (civil society), police department (operators), disabled persons organisations (vulnerable groups), technology vendor (provider), privacy commissioners (regulators), conducting public hearings, impact assessments, and establishing citizen oversight board with ongoing review authority\n4. **Agricultural AI Development**: Precision farming AI developer engages farmers (users), agricultural workers (affected workers), environmental organisations (civil society), food supply chain participants (customers), agricultural extension services (intermediaries), rural broadband providers (infrastructure), agricultural standards bodies, incorporating diverse perspectives into system design, pricing, accessibility, and environmental impact mitigation\n\n## ISO/IEC Standards Alignment\n\n**ISO/IEC 42001:2023** (AI Management Systems):\n- Clause 4.2: Understanding needs and expectations of interested parties\n- Clause 5.2: AI policy addressing stakeholder interests\n- Clause 9.1.3: Analysis of stakeholder feedback\n- Throughout: Stakeholder consideration in planning, development, operation\n\n**ISO/IEC 38507:2022** (Governance of IT):\n- Governance principle of stakeholder engagement\n- Evaluation of AI systems considering stakeholder impacts\n- Governance body responsibility for stakeholder interests\n\n**ISO/IEC 23894:2023** (AI Risk Management):\n- Stakeholder involvement in risk identification and assessment\n- Consideration of stakeholder-specific risks\n- Communication of risk information to stakeholders\n\n## NIST AI RMF Integration\n\n**GOVERN Function**:\n- GV-1.7: Processes for stakeholder feedback incorporated\n- GV-4: Organisational teams diverse and composed of stakeholders\n- GV-5: Organisational policies account for potential impacts to stakeholders\n- GV-6: Workforce diversity and skills matched to stakeholder needs\n\n**MAP Function**:\n- Context includes stakeholder landscape analysis\n- Categorisation considers stakeholder impact severity\n- Stakeholder input informs risk identification\n\n**MEASURE Function**:\n- Metrics address stakeholder-relevant outcomes\n- Measurement includes stakeholder experience indicators\n- Stakeholder feedback integrated into evaluation\n\n**MANAGE Function**:\n- Risk management responsive to stakeholder concerns\n- Stakeholder communication in incident response\n- Continuous improvement incorporates stakeholder perspectives\n\n## Implementation Considerations\n\n**Inclusive Stakeholder Identification**:\n- Systematic rather than ad hoc identification\n- Active outreach to marginalised or less visible groups\n- Recognition of indirect and long-term stakeholders\n- Periodic review and update of stakeholder landscape\n\n**Meaningful Engagement**:\n- Adequate time and resources for participation\n- Accessible formats and languages\n- Clear explanation of how input will be used\n- Transparency about constraints and trade-offs\n- Feedback on how stakeholder input influenced decisions\n- Compensation for stakeholder time and expertise where appropriate\n\n**Power Imbalance Mitigation**:\n- Amplification of less powerful stakeholder voices\n- Resources enabling participation by under-resourced groups\n- Independent facilitation of multi-stakeholder processes\n- Binding commitments rather than purely consultative engagement\n- Accountability mechanisms ensuring stakeholder interests protected\n\n**Challenges**:\n- Identifying all relevant stakeholders, especially less visible ones\n- Managing competing or conflicting stakeholder interests\n- Addressing power imbalances among stakeholders\n- Ensuring engagement is meaningful rather than performative\n- Maintaining sustained engagement across AI lifecycle\n- Balancing diverse stakeholder input with timely development\n- Representing future generations and non-human stakeholders\n- Preventing stakeholder fatigue from excessive consultation\n\n**Best Practices**:\n- Adopt systematic stakeholder identification methods\n- Prioritise engagement with most affected and vulnerable groups\n- Provide stakeholders with genuine influence over decisions\n- Maintain transparency about decision-making processes\n- Document and communicate how stakeholder input used\n- Build long-term relationships rather than transactional consultation\n- Establish ongoing stakeholder advisory mechanisms\n- Regularly evaluate and improve engagement approaches\n- Address power dynamics and resource disparities\n- Create multiple channels for diverse participation styles\n\n## Regulatory and Policy Context\n\n**EU AI Act**: Requires impact assessments considering affected persons and groups (stakeholders)\n\n**ISO/IEC 42001**: Mandates understanding of interested party (stakeholder) needs and expectations\n\n**OECD AI Principles**: Calls for inclusive growth and human-centred AI reflecting diverse stakeholder interests\n\n**Corporate Governance Codes**: Increasingly expect consideration of multi-stakeholder interests beyond shareholders\n\n**Human Rights Due Diligence**: Requires identification and engagement with rights-holder stakeholders\n\n## Related Terms\n\n- **AI Provider**: Key stakeholder category in AI value chain\n- **AI Operator**: Stakeholder deploying and managing AI systems\n- **AI User**: Stakeholder directly interacting with or affected by AI\n- **AI Governance**: Framework for managing stakeholder interests\n- **AI Impact Assessment**: Tool for understanding stakeholder impacts\n- **Accountability**: Obligation to stakeholders\n- **Fairness**: Principle addressing stakeholder equity concerns\n- **Transparency**: Information provision to stakeholders\n- **Participation**: Stakeholder involvement in decisions\n- **Civil Society**: Important stakeholder category\n\n## References\n\n1. ISO/IEC 42001:2023, *Information technology — Artificial intelligence — Management system*\n2. NIST AI 100-1, *Artificial Intelligence Risk Management Framework* (2023)\n3. OECD, *Recommendation of the Council on Artificial Intelligence* (2019)\n4. Freeman, R.E., *Strategic Management: A Stakeholder Approach* (2010)\n5. Ada Lovelace Institute, *Participatory AI* (2021)\n\n## See Also\n\n- [[AI Provider]]\n- [[AI Operator]]\n- [[AI User]]\n- [[AI Governance]]\n- [[AI Impact Assessment]]\n- [[Accountability]]\n- [[Fairness]]\n- [[Transparency]]\n- [[Participation]]\n- [[Civil Society]]\n\t- maturity:: draft\n\t- owl:class:: mv:Stakeholder\n\t- owl:physicality:: ConceptualEntity\n\t- owl:role:: Concept\n\t- belongsToDomain:: [[MetaverseDomain]]\n\t- #### Relationships\n\t  id:: stakeholder-relationships\n\t\t- is-subclass-of:: [[Metaverse]]",
  "backlinks": [],
  "wiki_links": [
    "AI Impact Assessment",
    "Participation",
    "Accountability",
    "Fairness",
    "AI Governance",
    "Civil Society",
    "AI Provider",
    "Transparency",
    "MetaverseDomain",
    "AI Operator",
    "Metaverse",
    "AI User"
  ],
  "ontology": {
    "term_id": "AI-0101",
    "preferred_term": "Stakeholder",
    "alt_terms": [],
    "iri": "http://narrativegoldmine.com/metaverse#Stakeholder",
    "source_domain": "metaverse",
    "domain": "metaverse",
    "domain_full_name": "",
    "definition": null,
    "scope_note": null,
    "status": "draft",
    "maturity": "draft",
    "version": null,
    "public_access": true,
    "last_updated": null,
    "authority_score": null,
    "quality_score": null,
    "cross_domain_links": null,
    "owl_class": "mv:Stakeholder",
    "owl_physicality": "ConceptualEntity",
    "owl_role": "Concept",
    "owl_inferred_class": null,
    "is_subclass_of": [
      "Metaverse"
    ],
    "has_part": [],
    "is_part_of": [],
    "requires": [],
    "depends_on": [],
    "enables": [],
    "relates_to": [],
    "bridges_to": [],
    "bridges_from": [],
    "domain_extensions": {},
    "belongs_to_domain": [
      "MetaverseDomain",
      "MetaverseDomain"
    ],
    "implemented_in_layer": [],
    "source": [],
    "validation": {
      "is_valid": false,
      "errors": [
        "Missing required property: last-updated",
        "Missing required property: definition",
        "owl:class namespace 'mv' doesn't match source-domain 'metaverse'"
      ]
    }
  }
}