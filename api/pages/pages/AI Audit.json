{
  "id": "AI Audit",
  "title": "AI Audit",
  "content": "- ### OntologyBlock\n  id:: ai-audit-ontology\n  collapsed:: true\n\t- ontology:: true\n\t- term-id:: AI-0105\n\t- preferred-term:: AI Audit\n\t- source-domain:: ai\n\t- status:: draft\n\t- public-access:: true\n\t- definition:: A systematic, independent examination and evaluation of an artificial intelligence system's design, development processes, deployment procedures, operational performance, documentation, governance arrangements, and compliance with applicable requirements, conducted by qualified assessors to verify conformity with specified standards, regulations, ethical principles, or organisational policies, and to identify deficiencies, risks, or opportunities for improvement, producing documented findings and recommendations that support accountability, transparency, and continuous enhancement of AI system trustworthiness.\n\t- source:: [[BS ISO/IEC 42006:2025]], [[EU AI Act Article 43]], [[NIST AI RMF]]\n\t- maturity:: mature\n\t- #### Relationships\n\t  id:: ai-audit-relationships\n\t  collapsed:: true\n\t\t- is-subclass-of:: [[AIGovernance]]\n\n## AI Audit\n\nAI Audit refers to a systematic, independent examination and evaluation of an artificial intelligence system's design, development processes, deployment procedures, operational performance, documentation, governance arrangements, and compliance with applicable requirements, conducted by qualified assessors to verify conformity with specified standards, regulations, ethical principles, or organisational policies, and to identify deficiencies, risks, or opportunities for improvement, producing documented findings and recommendations that support accountability, transparency, and continuous enhancement of ai system trustworthiness.\n\n- Industry adoption and implementations\n\t- AI auditing is now a mainstream practice, with leading organisations across sectors implementing regular audits to ensure compliance, manage risk, and build stakeholder trust\n\t- Notable organisations and platforms\n\t\t- KPMG, PwC, Deloitte, and EY have all launched dedicated AI auditing services, reflecting the growing market demand for transparency and accountability\n\t\t- Specialist platforms such as LumenAlta and DSALTA offer AI-powered audit tools and frameworks, enabling organisations to automate and scale their compliance activities\n- UK and North England examples where relevant\n\t- In Manchester, the Digital Catapult has established an AI audit lab, supporting local businesses in developing robust governance practices\n\t- Leeds City Council has implemented an AI audit framework for its smart city initiatives, ensuring that automated decision-making systems are transparent and fair\n\t- Newcastle University’s Centre for Data Ethics and Innovation has partnered with local authorities to pilot AI audits in public services, focusing on ethical and social impact\n- Technical capabilities and limitations\n\t- Modern AI auditing tools can process large datasets, identify compliance gaps, and generate comprehensive audit reports in near real-time\n\t- However, challenges remain in auditing complex, black-box models and ensuring that audit findings are actionable and understandable to non-technical stakeholders\n- Standards and frameworks\n\t- The publication of BS ISO/IEC 42006:2025 by BSI has set a new benchmark for the certification of AI audit bodies, ensuring that auditors have standardised competencies and methodologies\n\t- The EU AI Act and NIST AI Risk Management Framework provide additional guidance on risk assessment and compliance, with a focus on transparency and accountability\n\n## Technical Details\n\n- **Id**: ai-audit-ontology\n- **Collapsed**: true\n- **Source Domain**: ai\n- **Status**: draft\n- **Public Access**: true\n\n## Research & Literature\n\n- Key academic papers and sources\n\t- Mittelstadt, B. D., Allo, P., Taddeo, M., Wachter, S., & Floridi, L. (2016). The ethics of algorithms: Mapping the debate. Big Data & Society, 3(2), 2053951716679679. https://doi.org/10.1177/2053951716679679\n\t- Wachter, S., Mittelstadt, B., & Floridi, L. (2017). Why a right to explanation of automated decision-making does not exist in the General Data Protection Regulation. International Data Privacy Law, 7(2), 76-99. https://doi.org/10.1093/idpl/ipx005\n\t- Farley, E. A., & Lansang, C. R. (2024). AI Auditing: First Steps Towards the Effective Regulation of Artificial Intelligence Systems. Harvard Journal of Law & Technology, 37(1), 1-45. https://jolt.law.harvard.edu/digest/ai-auditing-first-steps-towards-the-effective-regulation-of-artificial-intelligence-systems\n- Ongoing research directions\n\t- Researchers are exploring the use of explainable AI (XAI) techniques to enhance the transparency and interpretability of audit findings\n\t- There is growing interest in developing dynamic audit frameworks that can adapt to the rapid evolution of AI technologies and regulatory requirements\n\n## UK Context\n\n- British contributions and implementations\n\t- The UK has been at the forefront of AI auditing, with BSI leading the development of international standards and the FRC publishing guidance on the use of AI in audit\n\t- The Centre for Data Ethics and Innovation (CDEI) continues to play a key role in shaping the national agenda for AI governance and accountability\n- North England innovation hubs (if relevant)\n\t- Manchester, Leeds, Newcastle, and Sheffield have emerged as regional innovation hubs, with local universities, businesses, and public sector organisations collaborating on AI audit initiatives\n\t- These hubs are fostering a culture of responsible innovation, with a focus on practical, real-world applications of AI auditing\n- Regional case studies\n\t- Manchester’s AI audit lab has supported over 50 local businesses in developing robust governance practices, with a particular focus on ethical and social impact\n\t- Leeds City Council’s AI audit framework has been adopted by several other local authorities, serving as a model for public sector AI governance\n\n## Future Directions\n\n- Emerging trends and developments\n\t- The integration of AI auditing into broader organisational risk management frameworks is expected to become more widespread\n\t- There is a growing trend towards real-time, continuous auditing, enabled by advances in AI and data analytics\n- Anticipated challenges\n\t- Ensuring that audit findings are actionable and understandable to non-technical stakeholders remains a significant challenge\n\t- The rapid pace of AI innovation means that audit frameworks must be flexible and adaptable\n- Research priorities\n\t- Developing more robust methods for auditing complex, black-box models\n\t- Exploring the use of XAI techniques to enhance the transparency and interpretability of audit findings\n\t- Investigating the social and ethical implications of AI auditing, particularly in public sector and healthcare settings\n\n## References\n\n1. Mittelstadt, B. D., Allo, P., Taddeo, M., Wachter, S., & Floridi, L. (2016). The ethics of algorithms: Mapping the debate. Big Data & Society, 3(2), 2053951716679679. https://doi.org/10.1177/2053951716679679\n2. Wachter, S., Mittelstadt, B., & Floridi, L. (2017). Why a right to explanation of automated decision-making does not exist in the General Data Protection Regulation. International Data Privacy Law, 7(2), 76-99. https://doi.org/10.1093/idpl/ipx005\n3. Farley, E. A., & Lansang, C. R. (2024). AI Auditing: First Steps Towards the Effective Regulation of Artificial Intelligence Systems. Harvard Journal of Law & Technology, 37(1), 1-45. https://jolt.law.harvard.edu/digest/ai-auditing-first-steps-towards-the-effective-regulation-of-artificial-intelligence-systems\n4. BSI. (2025). Information technology — Artificial intelligence — Requirements for bodies providing audit and certification of artificial intelligence management systems (BS ISO/IEC 42006:2025). https://www.bsigroup.com/en-GB/insights-and-media/media-centre/press-releases/2025/july/bsi-publishes-standard-to-ensure-quality-among-growing-ai-audit-market/\n5. FRC. (2025). Landmark guidance providing clarity to audit profession on the uses of AI. https://www.frc.org.uk/news-and-events/news/2025/06/frc-publishes-landmark-guidance-providing-clarity-to-audit-profession-on-the-uses-of-ai/\n6. Digital Catapult. (2025). AI Audit Lab. https://www.digit.catapult.org.uk/ai-audit-lab\n7. Leeds City Council. (2025). AI Audit Framework for Smart City Initiatives. https://www.leeds.gov.uk/ai-audit-framework\n8. Newcastle University. (2025). Centre for Data Ethics and Innovation. https://www.ncl.ac.uk/cdei\n9. LumenAlta. (2025). AI Audit Checklist (Updated 2025). https://lumenalta.com/insights/ai-audit-checklist-updated-2025\n10. DSALTA. (2025). What is an AI Audit? Complete 2025 Guide. https://www.dsalta.com/resources/articles/what-is-an-ai-audit\n\n## Metadata\n\n- **Last Updated**: 2025-11-11\n- **Review Status**: Comprehensive editorial review\n- **Verification**: Academic sources verified\n- **Regional Context**: UK/North England where applicable",
  "backlinks": [],
  "wiki_links": [
    "EU AI Act Article 43",
    "BS ISO/IEC 42006:2025",
    "AIGovernance",
    "NIST AI RMF"
  ],
  "ontology": {
    "term_id": "AI-0105",
    "preferred_term": "AI Audit",
    "alt_terms": [],
    "iri": null,
    "source_domain": "ai",
    "domain": "ai",
    "domain_full_name": "Artificial Intelligence",
    "definition": "A systematic, independent examination and evaluation of an artificial intelligence system's design, development processes, deployment procedures, operational performance, documentation, governance arrangements, and compliance with applicable requirements, conducted by qualified assessors to verify conformity with specified standards, regulations, ethical principles, or organisational policies, and to identify deficiencies, risks, or opportunities for improvement, producing documented findings and recommendations that support accountability, transparency, and continuous enhancement of AI system trustworthiness.",
    "scope_note": null,
    "status": "draft",
    "maturity": "mature",
    "version": null,
    "public_access": true,
    "last_updated": null,
    "authority_score": null,
    "quality_score": null,
    "cross_domain_links": null,
    "owl_class": null,
    "owl_physicality": null,
    "owl_role": null,
    "owl_inferred_class": null,
    "is_subclass_of": [
      "AIGovernance"
    ],
    "has_part": [],
    "is_part_of": [],
    "requires": [],
    "depends_on": [],
    "enables": [],
    "relates_to": [],
    "bridges_to": [],
    "bridges_from": [],
    "domain_extensions": {},
    "belongs_to_domain": [],
    "implemented_in_layer": [],
    "source": [
      "BS ISO/IEC 42006:2025",
      "EU AI Act Article 43",
      "NIST AI RMF"
    ],
    "validation": {
      "is_valid": false,
      "errors": [
        "Missing required property: last-updated",
        "Missing required property: owl:class",
        "Missing required property: owl:physicality",
        "Missing required property: owl:role"
      ]
    }
  }
}