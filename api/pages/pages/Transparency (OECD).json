{
  "id": "Transparency (OECD)",
  "title": "Transparency (OECD)",
  "content": "- ### OntologyBlock\n  id:: transparency-oecd-ontology\n  collapsed:: true\n\t- ontology:: true\n\t- term-id:: AI-0161\n\t- preferred-term:: Transparency (OECD)\n\t- source-domain:: ai\n\t- status:: draft\n\t- public-access:: true\n\t- definition:: AI actors should commit to transparency and responsible disclosure regarding AI systems, providing sufficient information to enable people to understand AI outcomes, challenge decisions and participate meaningfully in AI-influenced processes.\n\t- owl:class:: ai:TransparencyOecd\n\t- owl:physicality:: ConceptualEntity\n\t- owl:role:: Principle\n\n## Transparency (OECD)\n\nTransparency (OECD) refers to ai actors should commit to transparency and responsible disclosure regarding ai systems, providing sufficient information to enable people to understand ai outcomes, challenge decisions and participate meaningfully in ai-influenced processes.\n\n- Industry adoption of transparency practices is growing, with many organisations voluntarily reporting on AI risk management under the OECD’s new reporting framework launched in early 2025.\n  - This framework encourages disclosure of governance measures without constituting formal certification, promoting a culture of openness rather than bureaucratic box-ticking.\n  - Leading AI developers worldwide are enhancing system robustness, security, and transparency, as highlighted in recent OECD reports.\n- In the UK, transparency is increasingly embedded in AI governance strategies, aligning with the OECD principles and anticipating forthcoming regulatory frameworks.\n- Technical capabilities have advanced to support explainability, though challenges remain in balancing transparency with proprietary concerns and preventing information overload for users.\n- Standards and frameworks continue to evolve, with the OECD’s principles influencing the EU AI Act, UK regulatory approaches, and global interoperability efforts.\n\n## Technical Details\n\n- **Id**: transparency-(oecd)-ontology\n- **Collapsed**: true\n- **Source Domain**: ai\n- **Status**: draft\n- **Public Access**: true\n\n## Research & Literature\n\n- Key academic sources include:\n  - Floridi, L., Cowls, J., Beltrametti, M., et al. (2018). \"AI4People—An Ethical Framework for a Good AI Society: Opportunities, Risks, Principles, and Recommendations.\" *Minds and Machines*, 28(4), 689–707. DOI: 10.1007/s11023-018-9482-5\n  - Mittelstadt, B. D., Russell, C., & Wachter, S. (2019). \"Explaining explanations in AI.\" *Proceedings of the Conference on Fairness, Accountability, and Transparency*, 279–288. DOI: 10.1145/3287560.3287574\n  - OECD (2024). *Recommendation of the Council on Artificial Intelligence*. OECD Publishing. DOI: 10.1787/eedfee77-en\n- Ongoing research focuses on improving explainability methods, user-centric transparency, and balancing transparency with privacy and security concerns.\n\n## UK Context\n\n- The UK government and regulatory bodies actively endorse the OECD AI Principles, integrating transparency into national AI strategies.\n- North England, including innovation hubs in Manchester, Leeds, Newcastle, and Sheffield, hosts several AI research centres and startups prioritising transparent AI systems.\n  - For example, Manchester’s AI research institutes collaborate with industry to develop explainable AI tools tailored for healthcare and public services.\n  - Leeds and Sheffield contribute through interdisciplinary projects combining AI ethics and technical transparency.\n- Regional case studies demonstrate practical applications of transparency principles in public sector AI deployments, enhancing citizen trust and engagement.\n\n## Future Directions\n\n- Emerging trends include:\n  - Enhanced voluntary reporting mechanisms with richer, standardised transparency disclosures.\n  - Development of AI transparency tools that adapt explanations to diverse user needs and contexts.\n  - Integration of transparency with AI safety and accountability frameworks to form comprehensive governance.\n- Anticipated challenges:\n  - Avoiding transparency fatigue among users bombarded with complex information.\n  - Reconciling transparency with commercial confidentiality and security imperatives.\n  - Ensuring transparency efforts do not become mere performative gestures but lead to genuine user empowerment.\n- Research priorities:\n  - User experience studies on effective transparency communication.\n  - Technical innovations in explainability for complex, evolving AI systems.\n  - Cross-jurisdictional harmonisation of transparency standards.\n\n## References\n\n1. OECD (2024). *Recommendation of the Council on Artificial Intelligence*. OECD Publishing. DOI: 10.1787/eedfee77-en\n2. Floridi, L., Cowls, J., Beltrametti, M., et al. (2018). AI4People—An Ethical Framework for a Good AI Society: Opportunities, Risks, Principles, and Recommendations. *Minds and Machines*, 28(4), 689–707. DOI: 10.1007/s11023-018-9482-5\n3. Mittelstadt, B. D., Russell, C., & Wachter, S. (2019). Explaining explanations in AI. *Proceedings of the Conference on Fairness, Accountability, and Transparency*, 279–288. DOI: 10.1145/3287560.3287574\n4. OECD (2025). *Governing with Artificial Intelligence*. OECD Publishing.\n5. OECD (2025). OECD finds growing transparency efforts among leading AI developers. OECD Press Release, September 2025.\n\n## Metadata\n\n- **Last Updated**: 2025-11-11\n- **Review Status**: Comprehensive editorial review\n- **Verification**: Academic sources verified\n- **Regional Context**: UK/North England where applicable",
  "backlinks": [],
  "wiki_links": [],
  "ontology": {
    "term_id": "AI-0161",
    "preferred_term": "Transparency (OECD)",
    "alt_terms": [],
    "iri": "http://narrativegoldmine.com/ai#TransparencyOecd",
    "source_domain": "ai",
    "domain": "ai",
    "domain_full_name": "Artificial Intelligence",
    "definition": "AI actors should commit to transparency and responsible disclosure regarding AI systems, providing sufficient information to enable people to understand AI outcomes, challenge decisions and participate meaningfully in AI-influenced processes.",
    "scope_note": null,
    "status": "draft",
    "maturity": null,
    "version": null,
    "public_access": true,
    "last_updated": null,
    "authority_score": null,
    "quality_score": null,
    "cross_domain_links": null,
    "owl_class": "ai:TransparencyOecd",
    "owl_physicality": "ConceptualEntity",
    "owl_role": "Principle",
    "owl_inferred_class": null,
    "is_subclass_of": [],
    "has_part": [],
    "is_part_of": [],
    "requires": [],
    "depends_on": [],
    "enables": [],
    "relates_to": [],
    "bridges_to": [],
    "bridges_from": [],
    "domain_extensions": {},
    "belongs_to_domain": [],
    "implemented_in_layer": [],
    "source": [],
    "validation": {
      "is_valid": false,
      "errors": [
        "Missing required property: last-updated",
        "Missing required property: is-subclass-of (at least one parent class)"
      ]
    }
  }
}