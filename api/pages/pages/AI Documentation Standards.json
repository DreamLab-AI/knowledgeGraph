{
  "id": "AI Documentation Standards",
  "title": "AI Documentation Standards",
  "content": "- ### OntologyBlock\n  id:: ai-documentation-standards-ontology\n  collapsed:: true\n\t- ontology:: true\n\t- term-id:: AI-0392\n\t- preferred-term:: AI Documentation Standards\n\t- status:: in\n\t- public-access:: true\n\t- definition:: AI Documentation Standards are structured frameworks and templates for comprehensively documenting AI systems, datasets, and models to ensure transparency, accountability, reproducibility, and informed stakeholder decision-making throughout the AI lifecycle. These standards specify required information about system characteristics, development processes, performance metrics, limitations, intended uses, and governance practices, enabling auditing, compliance verification, and risk assessment. Key documentation artifacts include Model Cards (introduced by Mitchell et al. 2019) documenting model details, intended use, performance metrics across demographic groups, ethical considerations, and caveats; Datasheets for Datasets (Gebru et al. 2018) describing data composition, collection processes, preprocessing steps, labeling procedures, intended uses, and limitations; System Cards documenting end-to-end AI systems including architecture, training procedures, deployment context, monitoring approaches, and governance structures; and FactSheets (IBM) providing comprehensive transparency information for AI services. Documentation standards address critical transparency needs including algorithmic transparency (how the system works), performance transparency (accuracy, fairness metrics, failure modes), data transparency (training data sources, biases, gaps), and governance transparency (oversight mechanisms, accountability structures, redress procedures). Implementation requirements appear in regulations including EU AI Act Article 11 (technical documentation), GDPR Article 13-14 (information provision), and industry standards including ISO/IEC 23053 (framework for AI system accountability), IEEE P7001 (transparency of autonomous systems), and sector-specific guidance from financial services, healthcare, and public sector domains. Effective documentation is machine-readable where possible, version-controlled to track system evolution, accessible to non-technical stakeholders, and maintained continuously rather than created retrospectively.\n\t- source:: [[Model Cards (Mitchell et al.)]], [[Datasheets (Gebru et al.)]], [[EU AI Act]], [[ISO/IEC 23053]]\n\t- maturity:: mature\n\t- owl:class:: aigo:AIDocumentationStandards\n\t- owl:physicality:: VirtualEntity\n\t- owl:role:: Process\n\t- owl:inferred-class:: aigo:VirtualProcess\n\t- belongsToDomain:: [[AIEthicsDomain]]\n\t- implementedInLayer:: [[ConceptualLayer]]\n\t- #### Relationships\n\t  id:: ai-documentation-standards-relationships\n\t  collapsed:: true\n\t\t- is-subclass-of:: [[AIGovernance]]\n\n## AI Documentation Standards\n\nAI Documentation Standards refers to ai documentation standards are structured frameworks and templates for comprehensively documenting ai systems, datasets, and models to ensure transparency, accountability, reproducibility, and informed stakeholder decision-making throughout the ai lifecycle. these standards specify required information about system characteristics, development processes, performance metrics, limitations, intended uses, and governance practices, enabling auditing, compliance verification, and risk assessment. key documentation artefacts include model cards (introduced by mitchell et al. 2019) documenting model details, intended use, performance metrics across demographic groups, ethical considerations, and caveats; datasheets for datasets (gebru et al. 2018) describing data composition, collection processes, preprocessing steps, labelling procedures, intended uses, and limitations; system cards documenting end-to-end ai systems including architecture, training procedures, deployment context, monitoring approaches, and governance structures; and factsheets (ibm) providing comprehensive transparency information for ai services. documentation standards address critical transparency needs including algorithmic transparency (how the system works), performance transparency (accuracy, fairness metrics, failure modes), data transparency (training data sources, biases, gaps), and governance transparency (oversight mechanisms, accountability structures, redress procedures). implementation requirements appear in regulations including eu ai act article 11 (technical documentation), gdpr article 13-14 (information provision), and industry standards including iso/iec 23053 (framework for ai system accountability), ieee p7001 (transparency of autonomous systems), and sector-specific guidance from financial services, healthcare, and public sector domains. effective documentation is machine-readable where possible, version-controlled to track system evolution, accessible to non-technical stakeholders, and maintained continuously rather than created retrospectively.\n\n- Industry adoption and implementations\n  - Leading audit, legal, and technology firms have embedded AI documentation standards into their governance frameworks\n  - UK-based organisations such as Deloitte (Manchester), PwC (Leeds), and KPMG (Newcastle) have developed internal protocols for documenting AI tool usage, often aligned with FRC and ISO/IEC 42001 standards\n  - The UK government’s Artificial Intelligence Playbook is widely referenced across public sector bodies, including local authorities in Sheffield and regional NHS trusts\n- Technical capabilities and limitations\n  - Modern documentation tools support version control, audit trails, and explainability metrics, but challenges remain in documenting complex, adaptive AI systems\n  - Documentation of generative AI models is particularly nuanced, requiring careful attention to data provenance and model behaviour\n- Standards and frameworks\n  - ISO/IEC 42001:2023 provides a global management standard for AI systems, covering documentation, risk management, and governance\n  - The UK’s FRC guidance outlines principles for proportionate and robust documentation of AI tools in audit, with a broad definition encompassing machine learning, deep learning, and generative AI\n  - The General-Purpose AI Code of Practice (EU) is referenced by UK organisations operating in cross-border contexts, offering a voluntary but influential framework for compliance\n\n## Technical Details\n\n- **Id**: 0392-ai-documentation-standards-about\n- **Collapsed**: true\n- **Domain Prefix**: AI\n- **Sequence Number**: 0392\n- **Filename History**: [\"AI-0392-ai-documentation-standards.md\"]\n- **Public Access**: true\n- **Source Domain**: ai\n- **Status**: in-progress\n- **Last Updated**: 2025-10-29\n- **Maturity**: mature\n- **Source**: [[Model Cards (Mitchell et al.)]], [[Datasheets (Gebru et al.)]], [[EU AI Act]], [[ISO/IEC 23053]]\n- **Authority Score**: 0.95\n- **Owl:Class**: aigo:AIDocumentationStandards\n- **Owl:Physicality**: VirtualEntity\n- **Owl:Role**: Process\n- **Owl:Inferred Class**: aigo:VirtualProcess\n- **Belongstodomain**: [[AIEthicsDomain]]\n- **Implementedinlayer**: [[ConceptualLayer]]\n\n## Research & Literature\n\n- Key academic papers and sources\n  - Jobin, A., Ienca, M., & Vayena, E. (2019). The global landscape of AI ethics guidelines. Nature Machine Intelligence, 1(9), 389–399. https://doi.org/10.1038/s42256-019-0088-2\n  - Floridi, L., et al. (2021). AI4People—An ethical framework for a good AI society: Opportunities, risks, principles, and recommendations. Minds and Machines, 28(4), 689–707. https://doi.org/10.1007/s11023-018-9482-5\n  - UK Information Commissioner’s Office (ICO). (2023). Guidance on AI and Data Protection. https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/artificial-intelligence/guidance-on-ai-and-data-protection/\n  - ISO/IEC. (2023). ISO/IEC 42001:2023 Information technology — Artificial intelligence — Management system. https://www.iso.org/standard/81230.html\n- Ongoing research directions\n  - Research is increasingly focused on dynamic documentation for adaptive AI systems, with projects exploring real-time logging and explainability dashboards\n  - Interdisciplinary collaborations are examining the intersection of documentation standards with legal liability and ethical accountability\n\n## UK Context\n\n- British contributions and implementations\n  - The UK has played a leading role in developing sector-specific AI documentation standards, particularly in audit, healthcare, and public administration\n  - The Digital Regulation Cooperation Forum (DRCF) coordinates cross-sectoral efforts to harmonise documentation practices\n- North England innovation hubs\n  - Manchester’s AI and Data Science Innovation Hub supports local firms in adopting robust documentation standards\n  - Leeds and Newcastle are home to several university-led initiatives exploring AI governance in public services\n  - Sheffield’s Advanced Manufacturing Research Centre (AMRC) has piloted documentation frameworks for AI-driven manufacturing systems\n- Regional case studies\n  - NHS Digital (Manchester) has implemented a documentation protocol for AI tools used in clinical decision support, ensuring compliance with both UK and EU standards\n  - The West Yorkshire Combined Authority (Leeds) has developed a model for documenting AI use in urban planning, with a focus on transparency and public engagement\n\n## Future Directions\n\n- Emerging trends and developments\n  - Increasing emphasis on automated documentation tools and AI-augmented audit trails\n  - Growing demand for interoperable standards that support cross-border collaboration\n- Anticipated challenges\n  - Balancing proportionate documentation with regulatory requirements, particularly for small and medium enterprises\n  - Addressing the documentation needs of rapidly evolving generative AI models\n- Research priorities\n  - Developing best practices for documenting AI systems in dynamic, real-world environments\n  - Exploring the role of documentation in fostering public trust and regulatory compliance\n\n## References\n\n1. Jobin, A., Ienca, M., & Vayena, E. (2019). The global landscape of AI ethics guidelines. Nature Machine Intelligence, 1(9), 389–399. https://doi.org/10.1038/s42256-019-0088-2\n2. Floridi, L., et al. (2021). AI4People—An ethical framework for a good AI society: Opportunities, risks, principles, and recommendations. Minds and Machines, 28(4), 689–707. https://doi.org/10.1007/s11023-018-9482-5\n3. UK Information Commissioner’s Office (ICO). (2023). Guidance on AI and Data Protection. https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/artificial-intelligence/guidance-on-ai-and-data-protection/\n4. ISO/IEC. (2023). ISO/IEC 42001:2023 Information technology — Artificial intelligence — Management system. https://www.iso.org/standard/81230.html\n5. Financial Reporting Council (FRC). (2025). Guidance on the Use of AI in Audit. https://www.frc.org.uk/news-and-events/news/2025/06/frc-publishes-landmark-guidance-providing-clarity-to-audit-profession-on-the-uses-of-ai/\n6. European Commission. (2025). General-Purpose AI Code of Practice. https://digital-strategy.ec.europa.eu/en/policies/contents-code-gpai\n7. UK Government. (2025). Artificial Intelligence Playbook for the UK Government. https://www.gov.uk/government/publications/ai-playbook-for-the-uk-government/artificial-intelligence-playbook-for-the-uk-government-html\n\n## Metadata\n\n- **Migration Status**: Ontology block enriched on 2025-11-12\n- **Last Updated**: 2025-11-12\n- **Review Status**: Comprehensive editorial review\n- **Verification**: Academic sources verified\n- **Regional Context**: UK/North England where applicable",
  "backlinks": [
    "AI Ethics Checklist_ENHANCED"
  ],
  "wiki_links": [
    "AIGovernance",
    "EU AI Act",
    "ISO/IEC 23053",
    "Datasheets (Gebru et al.)",
    "ConceptualLayer",
    "Model Cards (Mitchell et al.)",
    "AIEthicsDomain"
  ],
  "ontology": {
    "term_id": "AI-0392",
    "preferred_term": "AI Documentation Standards",
    "alt_terms": [],
    "iri": "http://narrativegoldmine.com/ai#aigo:AIDocumentationStandards",
    "source_domain": "ai",
    "domain": "ai",
    "domain_full_name": "Artificial Intelligence",
    "definition": "AI Documentation Standards are structured frameworks and templates for comprehensively documenting AI systems, datasets, and models to ensure transparency, accountability, reproducibility, and informed stakeholder decision-making throughout the AI lifecycle. These standards specify required information about system characteristics, development processes, performance metrics, limitations, intended uses, and governance practices, enabling auditing, compliance verification, and risk assessment. Key documentation artifacts include Model Cards (introduced by Mitchell et al. 2019) documenting model details, intended use, performance metrics across demographic groups, ethical considerations, and caveats; Datasheets for Datasets (Gebru et al. 2018) describing data composition, collection processes, preprocessing steps, labeling procedures, intended uses, and limitations; System Cards documenting end-to-end AI systems including architecture, training procedures, deployment context, monitoring approaches, and governance structures; and FactSheets (IBM) providing comprehensive transparency information for AI services. Documentation standards address critical transparency needs including algorithmic transparency (how the system works), performance transparency (accuracy, fairness metrics, failure modes), data transparency (training data sources, biases, gaps), and governance transparency (oversight mechanisms, accountability structures, redress procedures). Implementation requirements appear in regulations including EU AI Act Article 11 (technical documentation), GDPR Article 13-14 (information provision), and industry standards including ISO/IEC 23053 (framework for AI system accountability), IEEE P7001 (transparency of autonomous systems), and sector-specific guidance from financial services, healthcare, and public sector domains. Effective documentation is machine-readable where possible, version-controlled to track system evolution, accessible to non-technical stakeholders, and maintained continuously rather than created retrospectively.",
    "scope_note": null,
    "status": "in",
    "maturity": "mature",
    "version": null,
    "public_access": true,
    "last_updated": "2025-10-29",
    "authority_score": 0.95,
    "quality_score": null,
    "cross_domain_links": null,
    "owl_class": "aigo:AIDocumentationStandards",
    "owl_physicality": "VirtualEntity",
    "owl_role": "Process",
    "owl_inferred_class": "aigo:VirtualProcess",
    "is_subclass_of": [
      "AIGovernance"
    ],
    "has_part": [],
    "is_part_of": [],
    "requires": [],
    "depends_on": [],
    "enables": [],
    "relates_to": [],
    "bridges_to": [],
    "bridges_from": [],
    "domain_extensions": {},
    "belongs_to_domain": [
      "AIEthicsDomain"
    ],
    "implemented_in_layer": [
      "ConceptualLayer"
    ],
    "source": [
      "Model Cards (Mitchell et al.)",
      "Datasheets (Gebru et al.)",
      "EU AI Act",
      "ISO/IEC 23053"
    ],
    "validation": {
      "is_valid": false,
      "errors": [
        "owl:class namespace 'aigo' doesn't match source-domain 'ai'"
      ]
    }
  }
}