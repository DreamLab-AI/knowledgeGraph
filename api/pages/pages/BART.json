{
  "id": "BART",
  "title": "BART",
  "content": "- ### OntologyBlock\n  id:: bart-ontology\n  collapsed:: true\n\t- ontology:: true\n\t- term-id:: AI-0222\n\t- preferred-term:: BART\n\t- source-domain:: metaverse\n\t- status:: draft\n\t- public-access:: true\n\n\n\n\n### OWL Classification\n\t- owl:class:: mv:BART\n\t- owl:physicality:: ConceptualEntity\n\t- owl:role:: Concept\n\n### Domain & Architecture\n\t- belongsToDomain:: [[MetaverseDomain]]\n\t- maturity:: draft\n\n### Relationships\n\n## Characteristics\n\n- **Encoder-Decoder Architecture**: Full transformer with both components\n- **Denoising Objective**: Learns to reconstruct corrupted text\n- **Flexible Corruption**: Multiple noise functions (masking, deletion, shuffling)\n- **Generation Tasks**: Optimised for text generation\n\n## Academic Foundations\n\n**Primary Source**: Lewis et al., \"BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension\", arXiv:1910.13461 (2019)\n\n**Performance**: Achieves state-of-the-art performance on text generation tasks including summarisation and dialogue.\n\n## Technical Context\n\nBART trains by corrupting text with an arbitrary noising function and learning to reconstruct the original text. This combines the bidirectional context of BERT's encoder with the autoregressive generation of GPT's decoder, making it particularly effective for generation tasks.\n\n## Ontological Relationships\n\n- **Broader Term**: Pre-trained Language Model\n- **Related Terms**: BERT, GPT, T5, Encoder-Decoder Architecture\n- **Task Strength**: Summarisation, Generation\n\n## Usage Context\n\n\"BART's denoising pre-training combines bidirectional encoding with autoregressive decoding for strong generation performance.\"\n\n## OWL Functional Syntax\n\n```clojure\n(Declaration (Class :BART))\n(AnnotationAssertion rdfs:label :BART \"BART\"@en)\n(AnnotationAssertion rdfs:comment :BART\n  \"Bidirectional and Auto-Regressive Transformers: a denoising autoencoder combining bidirectional encoding with autoregressive decoding.\"@en)\n(AnnotationAssertion :hasSource :BART\n  \"Lewis et al., 'BART: Denoising Sequence-to-Sequence Pre-training', arXiv:1910.13461 (2019)\"@en)\n\n;; Taxonomic relationships\n(SubClassOf :BART :PreTrainedLanguageModel)\n(SubClassOf :BART :EncoderDecoderArchitecture)\n(SubClassOf :BART :TransformerArchitecture)\n\n;; Architectural components\n(SubClassOf :BART\n  (ObjectSomeValuesFrom :hasComponent :Encoder))\n(SubClassOf :BART\n  (ObjectSomeValuesFrom :hasComponent :Decoder))\n(SubClassOf :BART\n  (ObjectSomeValuesFrom :hasComponent :DenoisingObjective))\n\n;; Pre-training approach\n(SubClassOf :BART\n  (ObjectSomeValuesFrom :usesPre-training :DenoisingAutoencoder))\n(SubClassOf :BART\n  (ObjectSomeValuesFrom :applies :NoiseFunction))\n\n;; Capabilities\n(SubClassOf :BART\n  (ObjectSomeValuesFrom :excellsAt :TextGeneration))\n(SubClassOf :BART\n  (ObjectSomeValuesFrom :excellsAt :Summarisation))\n(SubClassOf :BART\n  (ObjectSomeValuesFrom :excellsAt :DialogueGeneration))\n\n;; Combines approaches\n(SubClassOf :BART\n  (ObjectSomeValuesFrom :combines :BidirectionalEncoding))\n(SubClassOf :BART\n  (ObjectSomeValuesFrom :combines :AutoregressiveDecoding))\n\n;; Properties\n(DataPropertyAssertion :hasBidirectionalEncoder :BART \"true\"^^xsd:boolean)\n(DataPropertyAssertion :hasAutoregressiveDecoder :BART \"true\"^^xsd:boolean)\n(DataPropertyAssertion :usesDenoisingObjective :BART \"true\"^^xsd:boolean)\n(DataPropertyAssertion :optimisedForGeneration :BART \"true\"^^xsd:boolean)\n```\n\n## References\n\n- Lewis, M., et al. (2019). \"BART: Denoising Sequence-to-Sequence Pre-training\". arXiv:1910.13461\n\n---\n\n*Ontology Term managed by AI-Grounded Ontology Working Group*\n*UK English Spelling Standards Applied*\n\t- maturity:: draft\n\t- owl:class:: mv:BART\n\t- owl:physicality:: ConceptualEntity\n\t- owl:role:: Concept\n\t- is-subclass-of:: [[ArtificialIntelligence]]\n\t- belongsToDomain:: [[MetaverseDomain]]",
  "backlinks": [],
  "wiki_links": [
    "MetaverseDomain",
    "ArtificialIntelligence"
  ],
  "ontology": {
    "term_id": "AI-0222",
    "preferred_term": "BART",
    "alt_terms": [],
    "iri": "http://narrativegoldmine.com/metaverse#BART",
    "source_domain": "metaverse",
    "domain": "metaverse",
    "domain_full_name": "",
    "definition": null,
    "scope_note": null,
    "status": "draft",
    "maturity": "draft",
    "version": null,
    "public_access": true,
    "last_updated": null,
    "authority_score": null,
    "quality_score": null,
    "cross_domain_links": null,
    "owl_class": "mv:BART",
    "owl_physicality": "ConceptualEntity",
    "owl_role": "Concept",
    "owl_inferred_class": null,
    "is_subclass_of": [],
    "has_part": [],
    "is_part_of": [],
    "requires": [],
    "depends_on": [],
    "enables": [],
    "relates_to": [],
    "bridges_to": [],
    "bridges_from": [],
    "domain_extensions": {},
    "belongs_to_domain": [
      "MetaverseDomain",
      "MetaverseDomain"
    ],
    "implemented_in_layer": [],
    "source": [],
    "validation": {
      "is_valid": false,
      "errors": [
        "Missing required property: last-updated",
        "Missing required property: definition",
        "Missing required property: is-subclass-of (at least one parent class)",
        "owl:class namespace 'mv' doesn't match source-domain 'metaverse'"
      ]
    }
  }
}