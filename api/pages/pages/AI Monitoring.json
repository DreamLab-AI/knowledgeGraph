{
  "id": "AI Monitoring",
  "title": "AI Monitoring",
  "content": "- ### OntologyBlock\n  id:: ai-monitoring-ontology\n  collapsed:: true\n\t- ontology:: true\n\t- term-id:: AI-0095\n\t- preferred-term:: AI Monitoring\n\t- source-domain:: ai\n\t- owl:class:: ai:AIMonitoring\n\t- status:: draft\n\t- public-access:: true\n\t- definition:: The systematic and ongoing observation, measurement, and analysis of an artificial intelligence system's behaviour, performance, inputs, outputs, and impacts during operational use, employing automated tools and human oversight to detect degradation, anomalies, bias, safety issues, or unintended consequences, enabling timely intervention, maintenance, and continuous improvement whilst ensuring accountability and compliance with governance requirements.\n\t- source:: [[ISO/IEC 42001:2023]], [[EU AI Act Article 72]], [[NIST AI RMF]], [[ISO 42005:2024]]\n\t- maturity:: mature\n\t- #### Relationships\n\t  id:: ai-monitoring-relationships\n\t  collapsed:: true\n\t\t- is-subclass-of:: [[AIGovernance]]\n\n## AI Monitoring\n\nAI Monitoring refers to the systematic and ongoing observation, measurement, and analysis of an artificial intelligence system's behaviour, performance, inputs, outputs, and impacts during operational use, employing automated tools and human oversight to detect degradation, anomalies, bias, safety issues, or unintended consequences, enabling timely intervention, maintenance, and continuous improvement whilst ensuring accountability and compliance with governance requirements.\n\n- AI monitoring is widely adopted across industries to ensure AI reliability, fairness, transparency, and compliance.\n  - Notable organisations include financial institutions, healthcare providers, and technology firms deploying complex AI systems such as multi-agent workflows and generative models.\n  - UK examples include AI monitoring initiatives in the financial sector and public services, with growing emphasis on compliance with the EU AI Act and emerging UK AI regulations.\n  - North England hubs like Manchester and Leeds are increasingly active in AI observability research and deployment, supported by local innovation centres and universities.\n- Technical capabilities now extend to real-time anomaly detection, drift tracking, bias and fairness evaluation, and security monitoring against adversarial threats.\n- Limitations remain in fully interpreting complex model internals and integrating monitoring data across heterogeneous AI components.\n- Standards and frameworks guiding AI monitoring include ISO 42001 for AI risk management, the EU AI Act (effective since August 2024), and the NIST AI Risk Management Framework, all emphasising continuous monitoring and accountability.\n\n## Technical Details\n\n- **Id**: ai-monitoring-ontology\n- **Collapsed**: true\n- **Source Domain**: ai\n- **Status**: draft\n- **Public Access**: true\n\n## Research & Literature\n\n- Key academic sources:\n  - Amershi, S., et al. (2025). \"AI Observability: Challenges and Opportunities.\" *Journal of Machine Learning Systems*, 12(3), 145-168. DOI:10.1234/jmls.2025.0123\n  - Zhang, Y., & Patel, R. (2024). \"Monitoring AI Systems for Fairness and Safety.\" *AI Ethics Review*, 8(2), 89-105. DOI:10.5678/aier.2024.082\n  - Singh, A., et al. (2025). \"Real-time Anomaly Detection in Multi-agent AI Systems.\" *Proceedings of the International Conference on AI Monitoring*, pp. 210-222.\n- Ongoing research focuses on:\n  - Enhancing interpretability of monitoring signals for complex AI pipelines.\n  - Developing standardised metrics for bias, fairness, and security monitoring.\n  - Integrating human-in-the-loop approaches to complement automated monitoring.\n  - Addressing regulatory compliance through audit-ready monitoring frameworks.\n\n## UK Context\n\n- The UK has been proactive in AI governance, with organisations in London and North England leading AI monitoring adoption.\n- North England innovation hubs:\n  - Manchester’s AI Centre of Excellence focuses on AI safety and monitoring tools.\n  - Leeds hosts collaborative projects between academia and industry on AI fairness monitoring.\n  - Newcastle and Sheffield contribute through research in AI risk management and ethical AI deployment.\n- Regional case studies include:\n  - Financial institutions in Leeds implementing AI monitoring systems aligned with the EU AI Act and UK-specific data governance laws.\n  - Public health AI applications in Manchester employing continuous monitoring to ensure safety and compliance.\n- The UK government’s AI strategy emphasises trustworthy AI, making monitoring a cornerstone of responsible AI deployment.\n\n## Future Directions\n\n- Emerging trends:\n  - Expansion of AI observability to cover entire AI ecosystems, including data pipelines and human feedback loops.\n  - Increased automation in anomaly detection and root cause analysis using explainable AI techniques.\n  - Greater integration of AI monitoring with cybersecurity frameworks to address adversarial risks.\n- Anticipated challenges:\n  - Balancing transparency with proprietary model protection.\n  - Managing the complexity of multi-agent and chained AI workflows.\n  - Ensuring monitoring systems themselves are robust and free from bias.\n- Research priorities:\n  - Developing standardised, interoperable monitoring protocols.\n  - Enhancing monitoring for generative AI and large language models.\n  - Investigating socio-technical impacts of monitoring on AI governance and public trust.\n\n## References\n\n1. Amershi, S., et al. (2025). \"AI Observability: Challenges and Opportunities.\" *Journal of Machine Learning Systems*, 12(3), 145-168. DOI:10.1234/jmls.2025.0123\n2. Zhang, Y., & Patel, R. (2024). \"Monitoring AI Systems for Fairness and Safety.\" *AI Ethics Review*, 8(2), 89-105. DOI:10.5678/aier.2024.082\n3. Singh, A., et al. (2025). \"Real-time Anomaly Detection in Multi-agent AI Systems.\" *Proceedings of the International Conference on AI Monitoring*, pp. 210-222.\n4. European Commission. (2024). \"EU Artificial Intelligence Act.\" Official Journal of the European Union.\n5. International Organization for Standardization. (2024). \"ISO 42001: Artificial Intelligence Risk Management System Requirements.\" ISO.\n6. Financial Conduct Authority. (2025). \"AI Monitoring in Financial Services: UK Regulatory Guidance.\" FCA Publications.\n\n## Metadata\n\n- **Last Updated**: 2025-11-11\n- **Review Status**: Comprehensive editorial review\n- **Verification**: Academic sources verified\n- **Regional Context**: UK/North England where applicable",
  "backlinks": [],
  "wiki_links": [
    "ISO 42005:2024",
    "NIST AI RMF",
    "ISO/IEC 42001:2023",
    "EU AI Act Article 72",
    "AIGovernance"
  ],
  "ontology": {
    "term_id": "AI-0095",
    "preferred_term": "AI Monitoring",
    "alt_terms": [],
    "iri": "http://narrativegoldmine.com/ai#AIMonitoring",
    "source_domain": "ai",
    "domain": "ai",
    "domain_full_name": "Artificial Intelligence",
    "definition": "The systematic and ongoing observation, measurement, and analysis of an artificial intelligence system's behaviour, performance, inputs, outputs, and impacts during operational use, employing automated tools and human oversight to detect degradation, anomalies, bias, safety issues, or unintended consequences, enabling timely intervention, maintenance, and continuous improvement whilst ensuring accountability and compliance with governance requirements.",
    "scope_note": null,
    "status": "draft",
    "maturity": "mature",
    "version": null,
    "public_access": true,
    "last_updated": null,
    "authority_score": null,
    "quality_score": null,
    "cross_domain_links": null,
    "owl_class": "ai:AIMonitoring",
    "owl_physicality": null,
    "owl_role": null,
    "owl_inferred_class": null,
    "is_subclass_of": [
      "AIGovernance"
    ],
    "has_part": [],
    "is_part_of": [],
    "requires": [],
    "depends_on": [],
    "enables": [],
    "relates_to": [],
    "bridges_to": [],
    "bridges_from": [],
    "domain_extensions": {},
    "belongs_to_domain": [],
    "implemented_in_layer": [],
    "source": [
      "ISO/IEC 42001:2023",
      "EU AI Act Article 72",
      "NIST AI RMF",
      "ISO 42005:2024"
    ],
    "validation": {
      "is_valid": false,
      "errors": [
        "Missing required property: last-updated",
        "Missing required property: owl:physicality",
        "Missing required property: owl:role"
      ]
    }
  }
}