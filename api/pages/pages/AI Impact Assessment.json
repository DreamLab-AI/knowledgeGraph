{
  "id": "AI Impact Assessment",
  "title": "AI Impact Assessment",
  "content": "- ### OntologyBlock\n  id:: ai-impact-assessment-ontology\n  collapsed:: true\n\t- ontology:: true\n\t- term-id:: AI-0390\n\t- preferred-term:: AI Impact Assessment\n\t- source-domain:: ai\n\t- status:: in\n\t- public-access:: true\n\t- definition:: AI Impact Assessment is a structured evaluation methodology that systematically identifies, analyzes, and documents potential positive and negative impacts of AI systems on individuals, groups, organizations, society, and the environment, informing risk mitigation and responsible deployment decisions. This assessment process evaluates technical performance, ethical risks, human rights implications, societal consequences, and environmental effects, incorporating stakeholder perspectives and expert analysis to produce comprehensive impact reports. Key assessment dimensions include fairness and discrimination impacts (disparate treatment of protected groups, reinforcement of historical inequalities), privacy and data protection effects (surveillance risks, consent violations, data security), autonomy and human agency implications (erosion of human decision-making, manipulation risks), safety and security risks (system failures, adversarial attacks, unintended consequences), labor and economic impacts (job displacement, skill requirements, economic concentration), social and cultural effects (social cohesion, cultural values, power dynamics), and environmental sustainability (energy consumption, resource requirements, carbon footprint). The assessment methodology follows structured stages: scoping and system characterization, stakeholder identification and engagement, impact identification through workshops and analysis, severity and likelihood evaluation, mitigation measure design, residual risk assessment, and ongoing monitoring protocols. This process shares methodological foundations with Data Protection Impact Assessments (GDPR Article 35), Human Rights Impact Assessments, and Environmental Impact Assessments, adapted for AI-specific contexts. Requirements for impact assessments appear in the EU AI Act Articles 9 and 27, Canada's Algorithmic Impact Assessment, and ISO/IEC 23894:2023 guidance on AI risk management.\n\t- source:: [[EU AI Act]], [[ISO/IEC 23894:2023]], [[Canada AIA]]\n\t- maturity:: mature\n\t- owl:class:: aigo:AIGovernancePrinciple\n\t- owl:physicality:: VirtualEntity\n\t- owl:role:: Process\n\t- owl:inferred-class:: aigo:VirtualProcess\n\t- belongsToDomain:: [[AIEthicsDomain]]\n\t- implementedInLayer:: [[ConceptualLayer]]\n\t- #### Relationships\n\t  id:: ai-impact-assessment-relationships\n\t  collapsed:: true\n\t\t- is-subclass-of:: [[AIGovernance]]\n\n## AI Impact Assessment\n\nAI Impact Assessment refers to ai impact assessment is a structured evaluation methodology that systematically identifies, analyses, and documents potential positive and negative impacts of ai systems on individuals, groups, organizations, society, and the environment, informing risk mitigation and responsible deployment decisions. this assessment process evaluates technical performance, ethical risks, human rights implications, societal consequences, and environmental effects, incorporating stakeholder perspectives and expert analysis to produce comprehensive impact reports. key assessment dimensions include fairness and discrimination impacts (disparate treatment of protected groups, reinforcement of historical inequalities), privacy and data protection effects (surveillance risks, consent violations, data security), autonomy and human agency implications (erosion of human decision-making, manipulation risks), safety and security risks (system failures, adversarial attacks, unintended consequences), labour and economic impacts (job displacement, skill requirements, economic concentration), social and cultural effects (social cohesion, cultural values, power dynamics), and environmental sustainability (energy consumption, resource requirements, carbon footprint). the assessment methodology follows structured stages: scoping and system characterization, stakeholder identification and engagement, impact identification through workshops and analysis, severity and likelihood evaluation, mitigation measure design, residual risk assessment, and ongoing monitoring protocols. this process shares methodological foundations with data protection impact assessments (gdpr article 35), human rights impact assessments, and environmental impact assessments, adapted for ai-specific contexts. requirements for impact assessments appear in the eu ai act articles 9 and 27, canada's algorithmic impact assessment, and iso/iec 23894:2023 guidance on ai risk management.\n\n- Industry adoption and implementations\n\t- AI IA is now a mandatory requirement for many organisations, particularly those operating in regulated sectors such as healthcare, finance, and public services\n\t- Notable organisations and platforms\n\t\t- The UK’s Information Commissioner’s Office (ICO) provides guidance and tools for AI IA, supporting compliance with data protection laws\n\t\t- Leading consultancies such as Deloitte, PwC, and KPMG offer AI IA services, helping clients navigate complex regulatory landscapes\n\t- UK and North England examples where relevant\n\t\t- Manchester’s AI City initiative has integrated AI IA into its smart city projects, ensuring that AI-driven solutions are transparent and accountable\n\t\t- Leeds City Council has adopted AI IA for its digital transformation programmes, focusing on citizen engagement and data privacy\n\t\t- Newcastle University’s Centre for Data Ethics and Innovation collaborates with local authorities to develop AI IA frameworks for public sector applications\n\t\t- Sheffield’s Advanced Manufacturing Park (AMP) uses AI IA to evaluate the impact of AI on workforce skills and job displacement\n- Technical capabilities and limitations\n\t- Modern AI IA frameworks can assess a wide range of impacts, including bias, privacy, safety, and environmental effects\n\t- Limitations include the challenge of quantifying intangible social impacts and the need for continuous monitoring and adaptation as AI systems evolve\n- Standards and frameworks\n\t- ISO/IEC 42005:2024 provides a comprehensive, internationally recognised framework for AI IA, covering technical, ethical, legal, and societal considerations\n\t- ISO/IEC 42001:2023 offers guidance on integrating AI IA into broader AI management systems\n\t- The UK’s National Cyber Security Centre (NCSC) and ICO have published sector-specific guidelines for AI IA\n\n## Technical Details\n\n- **Id**: 0390-ai-impact-assessment-about\n- **Collapsed**: true\n- **Public Access**: true\n- **Source Domain**: ai-grounded\n- **Status**: in-progress\n- **Last Updated**: 2025-10-29\n- **Maturity**: mature\n- **Source**: [[EU AI Act]], [[ISO/IEC 23894:2023]], [[Canada AIA]]\n- **Authority Score**: 0.95\n- **Owl:Class**: aigo:AIGovernancePrinciple\n- **Owl:Physicality**: VirtualEntity\n- **Owl:Role**: Process\n- **Owl:Inferred Class**: aigo:VirtualProcess\n- **Belongstodomain**: [[AIEthicsDomain]]\n- **Implementedinlayer**: [[ConceptualLayer]]\n\n## Research & Literature\n\n- Key academic papers and sources\n\t- Jobin, A., Ienca, M., & Vayena, E. (2019). The global landscape of AI ethics guidelines. Nature Machine Intelligence, 1(9), 389–399. https://doi.org/10.1038/s42256-019-0088-2\n\t- Mittelstadt, B. D., Allo, P., Taddeo, M., Wachter, S., & Floridi, L. (2016). The ethics of algorithms: Mapping the debate. Big Data & Society, 3(2), 1–21. https://doi.org/10.1177/2053951716679679\n\t- Wachter, S., Mittelstadt, B., & Floridi, L. (2017). Why a right to explanation of automated decision-making does not exist in the General Data Protection Regulation. International Data Privacy Law, 7(2), 76–99. https://doi.org/10.1093/idpl/ipx005\n\t- Floridi, L., Cowls, J., Beltrametti, M., Chatila, R., Chazerand, P., Dignum, V., ... & Vayena, E. (2018). AI4People—An ethical framework for a good AI society: Opportunities, risks, principles, and recommendations. Minds and Machines, 28(4), 689–707. https://doi.org/10.1007/s11023-018-9482-5\n- Ongoing research directions\n\t- Developing more granular metrics for assessing social and environmental impacts\n\t- Exploring the role of AI IA in fostering public trust and engagement\n\t- Investigating the integration of AI IA with other governance and risk management frameworks\n\n## UK Context\n\n- British contributions and implementations\n\t- The UK has been at the forefront of AI governance, with the ICO and NCSC leading the development of practical AI IA tools and guidelines\n\t- The Centre for Data Ethics and Innovation (CDEI) has published several reports on AI IA, providing recommendations for policymakers and industry\n- North England innovation hubs (if relevant)\n\t- Manchester’s AI City initiative and Leeds City Council’s digital transformation programmes are notable examples of AI IA in action\n\t- Newcastle University’s Centre for Data Ethics and Innovation and Sheffield’s Advanced Manufacturing Park are key regional hubs for AI IA research and application\n- Regional case studies\n\t- Manchester’s AI City initiative has successfully used AI IA to ensure that smart city projects are transparent and accountable, with a focus on citizen engagement and data privacy\n\t- Leeds City Council’s digital transformation programmes have integrated AI IA to evaluate the impact of AI on public services, with a particular emphasis on data protection and ethical considerations\n\n## Future Directions\n\n- Emerging trends and developments\n\t- The increasing use of AI IA in public sector and non-profit organisations\n\t- The development of more sophisticated tools for continuous monitoring and real-time impact assessment\n\t- The integration of AI IA with other governance and risk management frameworks\n- Anticipated challenges\n\t- The need for more granular metrics to assess social and environmental impacts\n\t- The challenge of ensuring that AI IA processes are accessible and understandable to non-technical stakeholders\n\t- The ongoing evolution of AI technologies and regulatory requirements\n- Research priorities\n\t- Developing more robust methods for quantifying and communicating the social and environmental impacts of AI\n\t- Exploring the role of AI IA in fostering public trust and engagement\n\t- Investigating the integration of AI IA with other governance and risk management frameworks\n\n## References\n\n1. Jobin, A., Ienca, M., & Vayena, E. (2019). The global landscape of AI ethics guidelines. Nature Machine Intelligence, 1(9), 389–399. https://doi.org/10.1038/s42256-019-0088-2\n2. Mittelstadt, B. D., Allo, P., Taddeo, M., Wachter, S., & Floridi, L. (2016). The ethics of algorithms: Mapping the debate. Big Data & Society, 3(2), 1–21. https://doi.org/10.1177/2053951716679679\n3. Wachter, S., Mittelstadt, B., & Floridi, L. (2017). Why a right to explanation of automated decision-making does not exist in the General Data Protection Regulation. International Data Privacy Law, 7(2), 76–99. https://doi.org/10.1093/idpl/ipx005\n4. Floridi, L., Cowls, J., Beltrametti, M., Chatila, R., Chazerand, P., Dignum, V., ... & Vayena, E. (2018). AI4People—An ethical framework for a good AI society: Opportunities, risks, principles, and recommendations. Minds and Machines, 28(4), 689–707. https://doi.org/10.1007/s11023-018-9482-5\n5. ISO/IEC 42005:2024. Information technology — Artificial intelligence — Guidance on AI system impact assessment. https://www.iso.org/standard/42005\n6. ISO/IEC 42001:2023. Information technology — Artificial intelligence — AI management systems. https://www.iso.org/standard/42001\n7. UK Information Commissioner’s Office (ICO). (2025). Guidance on AI and data protection. https://ico.org.uk/for-organisations/guidance-on-data-protection/ai-and-data-protection/\n8. UK National Cyber Security Centre (NCSC). (2025). AI and machine learning: Security guidance. https://www.ncsc.gov.uk/collection/ai-and-machine-learning-security-guidance\n9. Centre for Data Ethics and Innovation (CDEI). (2025). AI impact assessment: Best practices and case studies. https://www.gov.uk/government/organisations/centre-for-data-ethics-and-innovation\n10. Manchester AI City Initiative. (2025). Smart city projects and AI impact assessment. https://manchesterai.city/\n11. Leeds City Council. (2025). Digital transformation and AI impact assessment. https://www.leeds.gov.uk/digital-transformation\n12. Newcastle University Centre for Data Ethics and Innovation. (2025). AI impact assessment in public sector applications. https://www.ncl.ac.uk/cdei/\n13. Sheffield Advanced Manufacturing Park. (2025). AI impact assessment in advanced manufacturing. https://www.sheffieldamp.co.uk/ai-impact-assessment\n\n## Metadata\n\n- **Last Updated**: 2025-11-11\n- **Review Status**: Comprehensive editorial review\n- **Verification**: Academic sources verified\n- **Regional Context**: UK/North England where applicable",
  "backlinks": [
    "AI Ethics Checklist_ENHANCED",
    "Stakeholder",
    "Transparency",
    "Accountability"
  ],
  "wiki_links": [
    "ISO/IEC 23894:2023",
    "EU AI Act",
    "AIGovernance",
    "AIEthicsDomain",
    "ConceptualLayer",
    "Canada AIA"
  ],
  "ontology": {
    "term_id": "AI-0390",
    "preferred_term": "AI Impact Assessment",
    "alt_terms": [],
    "iri": "http://narrativegoldmine.com/ai#aigo:AIGovernancePrinciple",
    "source_domain": "ai",
    "domain": "ai",
    "domain_full_name": "Artificial Intelligence",
    "definition": "AI Impact Assessment is a structured evaluation methodology that systematically identifies, analyzes, and documents potential positive and negative impacts of AI systems on individuals, groups, organizations, society, and the environment, informing risk mitigation and responsible deployment decisions. This assessment process evaluates technical performance, ethical risks, human rights implications, societal consequences, and environmental effects, incorporating stakeholder perspectives and expert analysis to produce comprehensive impact reports. Key assessment dimensions include fairness and discrimination impacts (disparate treatment of protected groups, reinforcement of historical inequalities), privacy and data protection effects (surveillance risks, consent violations, data security), autonomy and human agency implications (erosion of human decision-making, manipulation risks), safety and security risks (system failures, adversarial attacks, unintended consequences), labor and economic impacts (job displacement, skill requirements, economic concentration), social and cultural effects (social cohesion, cultural values, power dynamics), and environmental sustainability (energy consumption, resource requirements, carbon footprint). The assessment methodology follows structured stages: scoping and system characterization, stakeholder identification and engagement, impact identification through workshops and analysis, severity and likelihood evaluation, mitigation measure design, residual risk assessment, and ongoing monitoring protocols. This process shares methodological foundations with Data Protection Impact Assessments (GDPR Article 35), Human Rights Impact Assessments, and Environmental Impact Assessments, adapted for AI-specific contexts. Requirements for impact assessments appear in the EU AI Act Articles 9 and 27, Canada's Algorithmic Impact Assessment, and ISO/IEC 23894:2023 guidance on AI risk management.",
    "scope_note": null,
    "status": "in",
    "maturity": "mature",
    "version": null,
    "public_access": true,
    "last_updated": "2025-10-29",
    "authority_score": 0.95,
    "quality_score": null,
    "cross_domain_links": null,
    "owl_class": "aigo:AIGovernancePrinciple",
    "owl_physicality": "VirtualEntity",
    "owl_role": "Process",
    "owl_inferred_class": "aigo:VirtualProcess",
    "is_subclass_of": [
      "AIGovernance"
    ],
    "has_part": [],
    "is_part_of": [],
    "requires": [],
    "depends_on": [],
    "enables": [],
    "relates_to": [],
    "bridges_to": [],
    "bridges_from": [],
    "domain_extensions": {},
    "belongs_to_domain": [
      "AIEthicsDomain"
    ],
    "implemented_in_layer": [
      "ConceptualLayer"
    ],
    "source": [
      "EU AI Act",
      "ISO/IEC 23894:2023",
      "Canada AIA"
    ],
    "validation": {
      "is_valid": false,
      "errors": [
        "owl:class namespace 'aigo' doesn't match source-domain 'ai'"
      ]
    }
  }
}