{
  "id": "Robustness (OECD)",
  "title": "Robustness (OECD)",
  "content": "- ### OntologyBlock\n  id:: robustness-oecd-ontology\n  collapsed:: true\n\t- ontology:: true\n\t- term-id:: AI-0163\n\t- preferred-term:: Robustness (OECD)\n\t- source-domain:: ai\n\t- owl:class:: ai:RobustnessOECD\n\t- status:: draft\n\t- public-access:: true\n\t- definition:: AI systems should function reliably and securely throughout their lifecycle, demonstrating resilience against errors, faults, inconsistencies and attempts to alter system use or performance, with continuous assessment and management of potential risks.\n\n## Robustness (OECD)\n\nRobustness (OECD) refers to ai systems should function reliably and securely throughout their lifecycle, demonstrating resilience against errors, faults, inconsistencies and attempts to alter system use or performance, with continuous assessment and management of potential risks.\n\n- Industry adoption of robustness principles is widespread, driven by regulatory frameworks and market demand for trustworthy AI.\n  - Notable organisations include multinational tech companies and standards bodies such as ISO/IEC JTC 1/SC 42, which collaborates with OECD on AI standards.\n  - The OECD AI Principles have influenced major regulatory efforts, including the EU AI Act and the US NIST AI Risk Management Framework.\n- In the UK, robustness is a key requirement in AI governance, especially for high-risk AI systems under the UK’s AI regulations aligned with OECD recommendations.\n- Technical capabilities have advanced to include continuous monitoring, adversarial robustness testing, and automated risk assessment tools.\n  - Limitations remain in fully anticipating novel failure modes and ensuring robustness in generative AI systems that evolve post-deployment.\n- Standards and frameworks continue to evolve, with OECD updates in 2023-2024 clarifying definitions to include generative AI and adaptive systems.\n\n## Technical Details\n\n- **Id**: robustness-(oecd)-ontology\n- **Collapsed**: true\n- **Source Domain**: ai\n- **Status**: draft\n- **Public Access**: true\n\n## Research & Literature\n\n- Key academic sources include:\n  - Floridi, L., Cowls, J., Beltrametti, M., et al. (2020). \"AI4People—An Ethical Framework for a Good AI Society: Opportunities, Risks, Principles, and Recommendations.\" *Minds and Machines*, 30(2), 261-283. DOI: 10.1007/s11023-020-09517-8\n  - Amodei, D., Olah, C., Steinhardt, J., et al. (2016). \"Concrete Problems in AI Safety.\" *arXiv preprint* arXiv:1606.06565.\n  - OECD (2024). *Recommendation of the Council on Artificial Intelligence*. OECD Publishing. DOI: 10.1787/eedfee77-en\n- Ongoing research focuses on:\n  - Enhancing robustness against adversarial attacks and distributional shifts.\n  - Developing explainability methods that complement robustness.\n  - Lifecycle risk management for continuously learning AI systems.\n\n## UK Context\n\n- The UK government and regulatory bodies have adopted the OECD AI Principles as a foundation for national AI governance.\n  - The UK’s Centre for Data Ethics and Innovation (CDEI) actively promotes robustness in AI through guidance and policy recommendations.\n- North England innovation hubs such as Manchester, Leeds, Newcastle, and Sheffield are increasingly involved in AI research and deployment with a focus on robustness.\n  - For example, the University of Manchester’s AI research groups work on resilient AI architectures.\n  - Leeds and Newcastle host AI startups developing robust AI applications in healthcare and manufacturing.\n- Regional case studies highlight efforts to integrate robustness in public sector AI deployments, including smart city initiatives in Sheffield that prioritise secure and reliable AI systems.\n\n## Future Directions\n\n- Emerging trends include:\n  - Integration of robustness with ethical AI frameworks to ensure systems are not only reliable but also fair and transparent.\n  - Development of standardised robustness testing protocols applicable across AI domains.\n  - Use of AI for self-monitoring and self-healing systems to enhance resilience.\n- Anticipated challenges:\n  - Balancing robustness with system adaptability, especially in generative and evolving AI models.\n  - Addressing robustness in AI deployed in complex socio-technical environments with unpredictable human interactions.\n- Research priorities:\n  - Formalising robustness metrics and benchmarks.\n  - Cross-disciplinary approaches combining cybersecurity, ethics, and AI safety.\n  - Regional innovation support to translate robustness research into practical applications, particularly in the UK’s northern AI clusters.\n\n## References\n\n1. OECD (2024). *Recommendation of the Council on Artificial Intelligence*. OECD Publishing. DOI: 10.1787/eedfee77-en\n2. Floridi, L., Cowls, J., Beltrametti, M., et al. (2020). \"AI4People—An Ethical Framework for a Good AI Society: Opportunities, Risks, Principles, and Recommendations.\" *Minds and Machines*, 30(2), 261-283. DOI: 10.1007/s11023-020-09517-8\n3. Amodei, D., Olah, C., Steinhardt, J., et al. (2016). \"Concrete Problems in AI Safety.\" *arXiv preprint* arXiv:1606.06565\n4. Bradley, J. (2025). \"Global AI Governance: Five Key Frameworks Explained.\" Bradley Insights, August 2025.\n5. American National Standards Institute (2024). \"OECD Updates AI Principles.\" ANSI News, May 2024.\n\n## Metadata\n\n- **Last Updated**: 2025-11-11\n- **Review Status**: Comprehensive editorial review\n- **Verification**: Academic sources verified\n- **Regional Context**: UK/North England where applicable",
  "backlinks": [],
  "wiki_links": [],
  "ontology": {
    "term_id": "AI-0163",
    "preferred_term": "Robustness (OECD)",
    "alt_terms": [],
    "iri": "http://narrativegoldmine.com/ai#RobustnessOECD",
    "source_domain": "ai",
    "domain": "ai",
    "domain_full_name": "Artificial Intelligence",
    "definition": "AI systems should function reliably and securely throughout their lifecycle, demonstrating resilience against errors, faults, inconsistencies and attempts to alter system use or performance, with continuous assessment and management of potential risks.",
    "scope_note": null,
    "status": "draft",
    "maturity": null,
    "version": null,
    "public_access": true,
    "last_updated": null,
    "authority_score": null,
    "quality_score": null,
    "cross_domain_links": null,
    "owl_class": "ai:RobustnessOECD",
    "owl_physicality": null,
    "owl_role": null,
    "owl_inferred_class": null,
    "is_subclass_of": [],
    "has_part": [],
    "is_part_of": [],
    "requires": [],
    "depends_on": [],
    "enables": [],
    "relates_to": [],
    "bridges_to": [],
    "bridges_from": [],
    "domain_extensions": {},
    "belongs_to_domain": [],
    "implemented_in_layer": [],
    "source": [],
    "validation": {
      "is_valid": false,
      "errors": [
        "Missing required property: last-updated",
        "Missing required property: owl:physicality",
        "Missing required property: owl:role",
        "Missing required property: is-subclass-of (at least one parent class)"
      ]
    }
  }
}