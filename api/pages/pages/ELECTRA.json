{
  "id": "ELECTRA",
  "title": "ELECTRA",
  "content": "- ### OntologyBlock\n  id:: electra-ontology\n  collapsed:: true\n\t- ontology:: true\n\t- term-id:: AI-0219\n\t- preferred-term:: ELECTRA\n\t- source-domain:: metaverse\n\t- status:: draft\n\t- public-access:: true\n\n\n\n\n### OWL Classification\n\t- owl:class:: mv:ELECTRA\n\t- owl:physicality:: ConceptualEntity\n\t- owl:role:: Concept\n\n### Domain & Architecture\n\t- belongsToDomain:: [[MetaverseDomain]]\n\t- maturity:: draft\n\n### Relationships\n\n## Characteristics\n\n- **Discriminative Pre-training**: Detects replaced tokens rather than predicting them\n- **Generator-Discriminator**: Uses small generator to create replacements\n- **Sample Efficiency**: Learns from all tokens, not just masked ones\n- **Efficient Training**: Achieves strong performance with less compute\n\n## Academic Foundations\n\n**Primary Source**: Clark et al., \"ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators\", arXiv:2003.10555 (2020)\n\n**Efficiency**: Achieves comparable performance to RoBERTa and XLNet using less than 1/4 of their compute.\n\n## Technical Context\n\nELECTRA trains the model to distinguish real input tokens from plausible replacements generated by a small generator network. This replaced token detection task is more sample-efficient than masked language modelling because the model learns from all positions, not just masked ones.\n\n## Ontological Relationships\n\n- **Broader Term**: Pre-trained Language Model\n- **Related Terms**: BERT, Masked Language Model, Generator-Discriminator\n- **Innovation**: Replaced Token Detection\n\n## Usage Context\n\n\"ELECTRA's replaced token detection pre-training achieves strong performance with significantly less computational cost than masked language modelling.\"\n\n## OWL Functional Syntax\n\n```clojure\n(Declaration (Class :ELECTRA))\n(AnnotationAssertion rdfs:label :ELECTRA \"ELECTRA\"@en)\n(AnnotationAssertion rdfs:comment :ELECTRA\n  \"Efficiently Learning an Encoder that Classifies Token Replacements Accurately through discriminative pre-training.\"@en)\n(AnnotationAssertion :hasSource :ELECTRA\n  \"Clark et al., 'ELECTRA: Pre-training Text Encoders as Discriminators', arXiv:2003.10555 (2020)\"@en)\n\n;; Taxonomic relationships\n(SubClassOf :ELECTRA :PreTrainedLanguageModel)\n(SubClassOf :ELECTRA :TransformerArchitecture)\n\n;; Architecture pattern\n(SubClassOf :ELECTRA\n  (ObjectSomeValuesFrom :uses :GeneratorDiscriminatorPattern))\n(SubClassOf :ELECTRA\n  (ObjectSomeValuesFrom :hasComponent :Generator))\n(SubClassOf :ELECTRA\n  (ObjectSomeValuesFrom :hasComponent :Discriminator))\n\n;; Pre-training approach\n(SubClassOf :ELECTRA\n  (ObjectSomeValuesFrom :usesPre-training :ReplacedTokenDetection))\n\n;; Efficiency advantage\n(SubClassOf :ELECTRA\n  (ObjectSomeValuesFrom :moreEfficientThan :MaskedLanguageModelling))\n\n;; Properties\n(DataPropertyAssertion :isDiscriminative :ELECTRA \"true\"^^xsd:boolean)\n(DataPropertyAssertion :isSampleEfficient :ELECTRA \"true\"^^xsd:boolean)\n(DataPropertyAssertion :learnsFromAllTokens :ELECTRA \"true\"^^xsd:boolean)\n(DataPropertyAssertion :computeReduction :ELECTRA \"4x less than RoBERTa/XLNet\"^^xsd:string)\n(DataPropertyAssertion :performanceLevel :ELECTRA \"comparable to RoBERTa\"^^xsd:string)\n\n;; Related models\n(DisjointClasses :ELECTRA :BERT)\n(DisjointClasses :ELECTRA :RoBERTa)\n```\n\n## References\n\n- Clark, K., et al. (2020). \"ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators\". arXiv:2003.10555\n\n---\n\n*Ontology Term managed by AI-Grounded Ontology Working Group*\n*UK English Spelling Standards Applied*\n\t- maturity:: draft\n\t- owl:class:: mv:ELECTRA\n\t- owl:physicality:: ConceptualEntity\n\t- owl:role:: Concept\n\t- is-subclass-of:: [[ArtificialIntelligence]]\n\t- belongsToDomain:: [[MetaverseDomain]]",
  "backlinks": [],
  "wiki_links": [
    "MetaverseDomain",
    "ArtificialIntelligence"
  ],
  "ontology": {
    "term_id": "AI-0219",
    "preferred_term": "ELECTRA",
    "alt_terms": [],
    "iri": "http://narrativegoldmine.com/metaverse#ELECTRA",
    "source_domain": "metaverse",
    "domain": "metaverse",
    "domain_full_name": "",
    "definition": null,
    "scope_note": null,
    "status": "draft",
    "maturity": "draft",
    "version": null,
    "public_access": true,
    "last_updated": null,
    "authority_score": null,
    "quality_score": null,
    "cross_domain_links": null,
    "owl_class": "mv:ELECTRA",
    "owl_physicality": "ConceptualEntity",
    "owl_role": "Concept",
    "owl_inferred_class": null,
    "is_subclass_of": [],
    "has_part": [],
    "is_part_of": [],
    "requires": [],
    "depends_on": [],
    "enables": [],
    "relates_to": [],
    "bridges_to": [],
    "bridges_from": [],
    "domain_extensions": {},
    "belongs_to_domain": [
      "MetaverseDomain",
      "MetaverseDomain"
    ],
    "implemented_in_layer": [],
    "source": [],
    "validation": {
      "is_valid": false,
      "errors": [
        "Missing required property: last-updated",
        "Missing required property: definition",
        "Missing required property: is-subclass-of (at least one parent class)",
        "owl:class namespace 'mv' doesn't match source-domain 'metaverse'"
      ]
    }
  }
}