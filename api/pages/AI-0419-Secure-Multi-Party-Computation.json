{
  "title": "Secure Multi-Party Computation",
  "content": "- ### OntologyBlock\n  id:: secure-multi-party-computation-ontology\n  collapsed:: true\n\n  - **Identification**\n    - public-access:: true\n    - ontology:: true\n    - term-id:: AI-0419\n    - preferred-term:: Secure Multi-Party Computation\n    - source-domain:: ai-grounded\n    - status:: in-progress\n    - version:: 1.0\n    - last-updated:: 2025-10-29\n\n  - **Definition**\n    - definition:: Secure Multi-Party Computation is a cryptographic protocol enabling multiple parties to jointly compute functions over their combined private inputs without revealing individual inputs to other participants or trusted third parties, ensuring that only the final output is disclosed while intermediate computations remain confidential. This technique provides privacy guarantees through mathematical protocols where each party holds secret input x_i, parties execute cryptographic protocol computing function f(x_1, x_2, ..., x_n), and only the result is revealed while intermediate values remain hidden, with security models including semi-honest (honest-but-curious) adversaries following protocol but attempting to infer extra information, and malicious adversaries arbitrarily deviating from protocol requiring verification mechanisms. Implementation techniques span secret sharing methods where values are split into shares distributed across parties enabling computation through share manipulation (Shamir secret sharing for n parties with threshold t, replicated secret sharing for 3-party protocols), garbled circuits where one party creates encrypted circuit and another evaluates it without learning inputs or intermediate values (suitable for 2-party boolean circuits), and oblivious transfer primitives enabling receiver to obtain one of sender's inputs without sender knowing which was chosen or receiver learning others. ML applications include privacy-preserving model evaluation where parties jointly evaluate ML models without exposing proprietary models or sensitive test data, federated learning with secure aggregation preventing server from seeing individual participant updates even during aggregation, and private benchmarking enabling companies to compare ML model performance without revealing architectures or proprietary data. The 2024-2025 period demonstrated MPC feasibility for production systems though computational overheads remained significant (10-1000x slowdown), with successful deployments in financial consortia jointly training fraud detection models, healthcare collaborations enabling multi-institutional research without data sharing, and private set intersection protocols identifying common elements without revealing non-overlapping data.\n    - maturity:: mature\n    - source:: [[Yao's Garbled Circuits]], [[Shamir Secret Sharing]], [[MP-SPDZ]]\n    - authority-score:: 0.95\n\n  - **Semantic Classification**\n    - owl:class:: aigo:SecureMultiPartyComputation\n    - owl:physicality:: VirtualEntity\n    - owl:role:: Process\n    - owl:inferred-class:: aigo:VirtualProcess\n    - belongsToDomain:: [[AIEthicsDomain]]\n\n  - #### CrossDomainBridges\n    - bridges-from:: [[PrivacyEnhancingComputationPec]] via has-part\n    - implementedInLayer:: [[ConceptualLayer]]\n\n  - #### Relationships\n    id:: secure-multi-party-computation-relationships\n\n  - #### OWL Axioms\n    id:: secure-multi-party-computation-owl-axioms\n    collapsed:: true\n    - ```clojure\n      \n      ```\n\n### Relationships\n- is-subclass-of:: [[MachineLearning]]",
  "properties": {
    "id": "secure-multi-party-computation-owl-axioms",
    "collapsed": "true",
    "- public-access": "true",
    "- ontology": "true",
    "- term-id": "AI-0419",
    "- preferred-term": "Secure Multi-Party Computation",
    "- source-domain": "ai-grounded",
    "- status": "in-progress",
    "- version": "1.0",
    "- last-updated": "2025-10-29",
    "- definition": "Secure Multi-Party Computation is a cryptographic protocol enabling multiple parties to jointly compute functions over their combined private inputs without revealing individual inputs to other participants or trusted third parties, ensuring that only the final output is disclosed while intermediate computations remain confidential. This technique provides privacy guarantees through mathematical protocols where each party holds secret input x_i, parties execute cryptographic protocol computing function f(x_1, x_2, ..., x_n), and only the result is revealed while intermediate values remain hidden, with security models including semi-honest (honest-but-curious) adversaries following protocol but attempting to infer extra information, and malicious adversaries arbitrarily deviating from protocol requiring verification mechanisms. Implementation techniques span secret sharing methods where values are split into shares distributed across parties enabling computation through share manipulation (Shamir secret sharing for n parties with threshold t, replicated secret sharing for 3-party protocols), garbled circuits where one party creates encrypted circuit and another evaluates it without learning inputs or intermediate values (suitable for 2-party boolean circuits), and oblivious transfer primitives enabling receiver to obtain one of sender's inputs without sender knowing which was chosen or receiver learning others. ML applications include privacy-preserving model evaluation where parties jointly evaluate ML models without exposing proprietary models or sensitive test data, federated learning with secure aggregation preventing server from seeing individual participant updates even during aggregation, and private benchmarking enabling companies to compare ML model performance without revealing architectures or proprietary data. The 2024-2025 period demonstrated MPC feasibility for production systems though computational overheads remained significant (10-1000x slowdown), with successful deployments in financial consortia jointly training fraud detection models, healthcare collaborations enabling multi-institutional research without data sharing, and private set intersection protocols identifying common elements without revealing non-overlapping data.",
    "- maturity": "mature",
    "- source": "[[Yao's Garbled Circuits]], [[Shamir Secret Sharing]], [[MP-SPDZ]]",
    "- authority-score": "0.95",
    "- owl:class": "aigo:SecureMultiPartyComputation",
    "- owl:physicality": "VirtualEntity",
    "- owl:role": "Process",
    "- owl:inferred-class": "aigo:VirtualProcess",
    "- belongsToDomain": "[[AIEthicsDomain]]",
    "- bridges-from": "[[PrivacyEnhancingComputationPec]] via has-part",
    "- implementedInLayer": "[[ConceptualLayer]]"
  },
  "backlinks": [],
  "wiki_links": [
    "Shamir Secret Sharing",
    "AIEthicsDomain",
    "PrivacyEnhancingComputationPec",
    "Yao's Garbled Circuits",
    "MP-SPDZ",
    "MachineLearning",
    "ConceptualLayer"
  ],
  "ontology": {
    "term_id": "AI-0419",
    "preferred_term": "Secure Multi-Party Computation",
    "definition": "Secure Multi-Party Computation is a cryptographic protocol enabling multiple parties to jointly compute functions over their combined private inputs without revealing individual inputs to other participants or trusted third parties, ensuring that only the final output is disclosed while intermediate computations remain confidential. This technique provides privacy guarantees through mathematical protocols where each party holds secret input x_i, parties execute cryptographic protocol computing function f(x_1, x_2, ..., x_n), and only the result is revealed while intermediate values remain hidden, with security models including semi-honest (honest-but-curious) adversaries following protocol but attempting to infer extra information, and malicious adversaries arbitrarily deviating from protocol requiring verification mechanisms. Implementation techniques span secret sharing methods where values are split into shares distributed across parties enabling computation through share manipulation (Shamir secret sharing for n parties with threshold t, replicated secret sharing for 3-party protocols), garbled circuits where one party creates encrypted circuit and another evaluates it without learning inputs or intermediate values (suitable for 2-party boolean circuits), and oblivious transfer primitives enabling receiver to obtain one of sender's inputs without sender knowing which was chosen or receiver learning others. ML applications include privacy-preserving model evaluation where parties jointly evaluate ML models without exposing proprietary models or sensitive test data, federated learning with secure aggregation preventing server from seeing individual participant updates even during aggregation, and private benchmarking enabling companies to compare ML model performance without revealing architectures or proprietary data. The 2024-2025 period demonstrated MPC feasibility for production systems though computational overheads remained significant (10-1000x slowdown), with successful deployments in financial consortia jointly training fraud detection models, healthcare collaborations enabling multi-institutional research without data sharing, and private set intersection protocols identifying common elements without revealing non-overlapping data.",
    "source_domain": "ai-grounded",
    "maturity_level": null,
    "authority_score": 0.95
  }
}