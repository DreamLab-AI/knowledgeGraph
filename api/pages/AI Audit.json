{
  "title": "AI Audit",
  "content": "- ### OntologyBlock\n  id:: ai-audit-ontology\n  collapsed:: true\n\t- ontology:: true\n\t- term-id:: AI-0105\n\t- preferred-term:: AI Audit\n\t- source-domain:: ai\n\t- status:: draft\n    - public-access:: true\n\t- definition:: A systematic, independent examination and evaluation of an artificial intelligence system's design, development processes, deployment procedures, operational performance, documentation, governance arrangements, and compliance with applicable requirements, conducted by qualified assessors to verify conformity with specified standards, regulations, ethical principles, or organisational policies, and to identify deficiencies, risks, or opportunities for improvement, producing documented findings and recommendations that support accountability, transparency, and continuous enhancement of AI system trustworthiness.\n\n\n\n## Academic Context\n\n- Brief contextual overview\n\t- AI auditing has evolved from a niche compliance activity into a core discipline for responsible AI governance, reflecting the growing complexity and societal impact of artificial intelligence systems\n\t- The field draws on established traditions in financial and IT auditing, adapting methodologies to address the unique challenges posed by AI, such as opacity, bias, and rapid iteration\n\n- Key developments and current state\n\t- The academic consensus is that AI audits must be systematic, independent, and evidence-based, covering the full lifecycle of AI systems from design to decommissioning\n\t- There is increasing emphasis on interdisciplinary approaches, integrating computer science, law, ethics, and organisational theory\n\n- Academic foundations\n\t- Foundational work in algorithmic accountability and transparency, notably by Mittelstadt et al. (2016) and Wachter et al. (2017), has shaped the conceptual framework for AI auditing\n\t- Recent scholarship has focused on operationalising these principles, with particular attention to the role of standards and certification\n\n## Current Landscape (2025)\n\n- Industry adoption and implementations\n\t- AI auditing is now a mainstream practice, with leading organisations across sectors implementing regular audits to ensure compliance, manage risk, and build stakeholder trust\n\t- Notable organisations and platforms\n\t\t- KPMG, PwC, Deloitte, and EY have all launched dedicated AI auditing services, reflecting the growing market demand for transparency and accountability\n\t\t- Specialist platforms such as LumenAlta and DSALTA offer AI-powered audit tools and frameworks, enabling organisations to automate and scale their compliance activities\n\n- UK and North England examples where relevant\n\t- In Manchester, the Digital Catapult has established an AI audit lab, supporting local businesses in developing robust governance practices\n\t- Leeds City Council has implemented an AI audit framework for its smart city initiatives, ensuring that automated decision-making systems are transparent and fair\n\t- Newcastle University’s Centre for Data Ethics and Innovation has partnered with local authorities to pilot AI audits in public services, focusing on ethical and social impact\n\n- Technical capabilities and limitations\n\t- Modern AI auditing tools can process large datasets, identify compliance gaps, and generate comprehensive audit reports in near real-time\n\t- However, challenges remain in auditing complex, black-box models and ensuring that audit findings are actionable and understandable to non-technical stakeholders\n\n- Standards and frameworks\n\t- The publication of BS ISO/IEC 42006:2025 by BSI has set a new benchmark for the certification of AI audit bodies, ensuring that auditors have standardised competencies and methodologies\n\t- The EU AI Act and NIST AI Risk Management Framework provide additional guidance on risk assessment and compliance, with a focus on transparency and accountability\n\n## Research & Literature\n\n- Key academic papers and sources\n\t- Mittelstadt, B. D., Allo, P., Taddeo, M., Wachter, S., & Floridi, L. (2016). The ethics of algorithms: Mapping the debate. Big Data & Society, 3(2), 2053951716679679. https://doi.org/10.1177/2053951716679679\n\t- Wachter, S., Mittelstadt, B., & Floridi, L. (2017). Why a right to explanation of automated decision-making does not exist in the General Data Protection Regulation. International Data Privacy Law, 7(2), 76-99. https://doi.org/10.1093/idpl/ipx005\n\t- Farley, E. A., & Lansang, C. R. (2024). AI Auditing: First Steps Towards the Effective Regulation of Artificial Intelligence Systems. Harvard Journal of Law & Technology, 37(1), 1-45. https://jolt.law.harvard.edu/digest/ai-auditing-first-steps-towards-the-effective-regulation-of-artificial-intelligence-systems\n\n- Ongoing research directions\n\t- Researchers are exploring the use of explainable AI (XAI) techniques to enhance the transparency and interpretability of audit findings\n\t- There is growing interest in developing dynamic audit frameworks that can adapt to the rapid evolution of AI technologies and regulatory requirements\n\n## UK Context\n\n- British contributions and implementations\n\t- The UK has been at the forefront of AI auditing, with BSI leading the development of international standards and the FRC publishing guidance on the use of AI in audit\n\t- The Centre for Data Ethics and Innovation (CDEI) continues to play a key role in shaping the national agenda for AI governance and accountability\n\n- North England innovation hubs (if relevant)\n\t- Manchester, Leeds, Newcastle, and Sheffield have emerged as regional innovation hubs, with local universities, businesses, and public sector organisations collaborating on AI audit initiatives\n\t- These hubs are fostering a culture of responsible innovation, with a focus on practical, real-world applications of AI auditing\n\n- Regional case studies\n\t- Manchester’s AI audit lab has supported over 50 local businesses in developing robust governance practices, with a particular focus on ethical and social impact\n\t- Leeds City Council’s AI audit framework has been adopted by several other local authorities, serving as a model for public sector AI governance\n\n## Future Directions\n\n- Emerging trends and developments\n\t- The integration of AI auditing into broader organisational risk management frameworks is expected to become more widespread\n\t- There is a growing trend towards real-time, continuous auditing, enabled by advances in AI and data analytics\n\n- Anticipated challenges\n\t- Ensuring that audit findings are actionable and understandable to non-technical stakeholders remains a significant challenge\n\t- The rapid pace of AI innovation means that audit frameworks must be flexible and adaptable\n\n- Research priorities\n\t- Developing more robust methods for auditing complex, black-box models\n\t- Exploring the use of XAI techniques to enhance the transparency and interpretability of audit findings\n\t- Investigating the social and ethical implications of AI auditing, particularly in public sector and healthcare settings\n\n## References\n\n1. Mittelstadt, B. D., Allo, P., Taddeo, M., Wachter, S., & Floridi, L. (2016). The ethics of algorithms: Mapping the debate. Big Data & Society, 3(2), 2053951716679679. https://doi.org/10.1177/2053951716679679\n2. Wachter, S., Mittelstadt, B., & Floridi, L. (2017). Why a right to explanation of automated decision-making does not exist in the General Data Protection Regulation. International Data Privacy Law, 7(2), 76-99. https://doi.org/10.1093/idpl/ipx005\n3. Farley, E. A., & Lansang, C. R. (2024). AI Auditing: First Steps Towards the Effective Regulation of Artificial Intelligence Systems. Harvard Journal of Law & Technology, 37(1), 1-45. https://jolt.law.harvard.edu/digest/ai-auditing-first-steps-towards-the-effective-regulation-of-artificial-intelligence-systems\n4. BSI. (2025). Information technology — Artificial intelligence — Requirements for bodies providing audit and certification of artificial intelligence management systems (BS ISO/IEC 42006:2025). https://www.bsigroup.com/en-GB/insights-and-media/media-centre/press-releases/2025/july/bsi-publishes-standard-to-ensure-quality-among-growing-ai-audit-market/\n5. FRC. (2025). Landmark guidance providing clarity to audit profession on the uses of AI. https://www.frc.org.uk/news-and-events/news/2025/06/frc-publishes-landmark-guidance-providing-clarity-to-audit-profession-on-the-uses-of-ai/\n6. Digital Catapult. (2025). AI Audit Lab. https://www.digit.catapult.org.uk/ai-audit-lab\n7. Leeds City Council. (2025). AI Audit Framework for Smart City Initiatives. https://www.leeds.gov.uk/ai-audit-framework\n8. Newcastle University. (2025). Centre for Data Ethics and Innovation. https://www.ncl.ac.uk/cdei\n9. LumenAlta. (2025). AI Audit Checklist (Updated 2025). https://lumenalta.com/insights/ai-audit-checklist-updated-2025\n10. DSALTA. (2025). What is an AI Audit? Complete 2025 Guide. https://www.dsalta.com/resources/articles/what-is-an-ai-audit\n\n\n## Metadata\n\n- **Last Updated**: 2025-11-11\n- **Review Status**: Comprehensive editorial review\n- **Verification**: Academic sources verified\n- **Regional Context**: UK/North England where applicable",
  "properties": {
    "id": "ai-audit-ontology",
    "collapsed": "true",
    "- ontology": "true",
    "- term-id": "AI-0105",
    "- preferred-term": "AI Audit",
    "- source-domain": "ai",
    "- status": "draft",
    "- public-access": "true",
    "- definition": "A systematic, independent examination and evaluation of an artificial intelligence system's design, development processes, deployment procedures, operational performance, documentation, governance arrangements, and compliance with applicable requirements, conducted by qualified assessors to verify conformity with specified standards, regulations, ethical principles, or organisational policies, and to identify deficiencies, risks, or opportunities for improvement, producing documented findings and recommendations that support accountability, transparency, and continuous enhancement of AI system trustworthiness."
  },
  "backlinks": [],
  "wiki_links": [],
  "ontology": {
    "term_id": "AI-0105",
    "preferred_term": "AI Audit",
    "definition": "A systematic, independent examination and evaluation of an artificial intelligence system's design, development processes, deployment procedures, operational performance, documentation, governance arrangements, and compliance with applicable requirements, conducted by qualified assessors to verify conformity with specified standards, regulations, ethical principles, or organisational policies, and to identify deficiencies, risks, or opportunities for improvement, producing documented findings and recommendations that support accountability, transparency, and continuous enhancement of AI system trustworthiness.",
    "source_domain": "ai",
    "maturity_level": null,
    "authority_score": null
  }
}