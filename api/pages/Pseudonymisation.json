{
  "title": "Pseudonymisation",
  "content": "- ### OntologyBlock\n  id:: 0427-pseudonymisation-ontology\n  collapsed:: true\n\n  - **Identification**\n    - public-access:: true\n    - ontology:: true\n    - is-subclass-of:: [[ArtificialIntelligenceTechnology]]\n    - term-id:: AI-0427\n    - preferred-term:: Pseudonymisation\n    - source-domain:: ai-grounded\n    - status:: in-progress\n    - version:: 1.0\n    - last-updated:: 2025-10-29\n\n  - **Definition**\n    - definition:: Pseudonymisation is a data protection technique defined in GDPR Article 4(5) as processing personal data such that it can no longer be attributed to a specific data subject without additional information, which is kept separately under technical and organizational measures preventing re-identification. This approach replaces direct identifiers (names, email addresses, national identification numbers) with pseudonyms (aliases, tokens, or encrypted identifiers) while maintaining data utility for analysis, creating reversible anonymization that reduces but does not eliminate re-identification risk unlike full anonymization which irreversibly severs links between data and individuals. Implementation techniques include cryptographic hashing applying one-way hash functions (SHA-256, HMAC) with secret keys converting identifiers to fixed-length pseudonyms deterministically enabling consistent linkage across datasets while preventing reverse lookup without keys, tokenization replacing sensitive identifiers with randomly generated tokens stored in secure mapping tables enabling authorized re-identification when necessary, encryption-based pseudonymisation using symmetric or asymmetric encryption with keys managed separately from pseudonymized data, and deterministic or format-preserving techniques maintaining data structure (preserving ZIP code format, date formats) for compatibility with legacy systems. GDPR recognition appears across multiple articles including Article 4(5) defining the technique, Article 25 recommending pseudonymisation as privacy-by-design measure, Article 32 listing it as appropriate security measure, and Recital 28 noting pseudonymisation reduces risks to data subjects allowing data controllers to meet protection obligations while permitting useful data processing. Benefits include reduced re-identification risk as pseudonymized data presents higher barriers to linking records with real identities, regulatory flexibility with GDPR treating pseudonymized data more favorably than identifiable personal data for certain processing activities, data utility preservation enabling meaningful analytics, reporting, and machine learning on protected datasets while maintaining referential integrity, and breach impact mitigation as stolen pseudonymized data has limited value without corresponding key material or mapping tables. Applications in AI systems span training data protection pseudonymizing subjects in training datasets preventing model memorization of real identities, cross-organizational collaboration enabling data sharing for collaborative ML without exposing participant identities, longitudinal analysis tracking individuals across time periods for behavior modeling while protecting identity, and audit trail privacy maintaining activity logs for security monitoring without storing plaintext user identifiers, though limitations include remaining personal data status under GDPR as pseudonymized data still constitutes personal data subject to regulatory requirements, linkability vulnerabilities where deterministic pseudonymisation enables tracking across contexts potentially revealing behavioral patterns, key management complexity requiring secure storage and access controls for re-identification keys, and potential re-identification through auxiliary information attacks combining pseudonymized data with external datasets to unm ask identities.\n    - maturity:: mature\n    - source:: [[GDPR Article 4(5)]], [[GDPR Article 25]], [[GDPR Article 32]]\n    - authority-score:: 0.95\n\n  - **Semantic Classification**\n    - owl:class:: aigo:Pseudonymisation\n    - owl:physicality:: VirtualEntity\n    - owl:role:: Process\n    - owl:inferred-class:: aigo:VirtualProcess\n    - belongsToDomain:: [[AIEthicsDomain]]\n    - implementedInLayer:: [[ConceptualLayer]]\n\n  - #### Relationships\n    id:: 0427-pseudonymisation-relationships\n\n  - #### OWL Axioms\n    id:: 0427-pseudonymisation-owl-axioms\n    collapsed:: true\n    - ```clojure\n      (Declaration (Class :Pseudonymisation))\n(SubClassOf :Pseudonymisation :PrivacyPreservingTechnique)\n\n;; Core Relationships\n(SubClassOf :Pseudonymisation\n  (ObjectSomeValuesFrom :replaces :DirectIdentifiers))\n(SubClassOf :Pseudonymisation\n  (ObjectSomeValuesFrom :generates :Pseudonyms))\n(SubClassOf :Pseudonymisation\n  (ObjectSomeValuesFrom :maintains :DataUtility))\n(SubClassOf :Pseudonymisation\n  (ObjectSomeValuesFrom :protects :IndirectIdentification))\n(SubClassOf :Pseudonymisation\n  (ObjectSomeValuesFrom :enables :Reversibility))\n(SubClassOf :Pseudonymisation\n  (ObjectSomeValuesFrom :separates :IdentifyingInformation))\n(SubClassOf :Pseudonymisation\n  (ObjectSomeValuesFrom :applies :CryptographicTransformation))\n(SubClassOf :Pseudonymisation\n  (ObjectSomeValuesFrom :preserves :DataRelationships))\n\n;; Pseudonymisation Techniques\n(SubClassOf :Pseudonymisation\n  (ObjectSomeValuesFrom :employs\n    (ObjectUnionOf :CryptographicHashing\n                   :Tokenisation\n                   :EncryptionBased\n                   :RandomIdentifiers\n                   :DeterministicMapping)))\n\n;; Security Properties\n(SubClassOf :Pseudonymisation\n  (ObjectSomeValuesFrom :provides\n    (ObjectIntersectionOf :LinkabilityResistance\n                         :ReversibilityControl\n                         :KeyManagement\n                         :AuditTrail)))\n\n;; Data Properties\n(SubClassOf :Pseudonymisation\n  (DataHasValue :hashAlgorithm xsd:string))\n(SubClassOf :Pseudonymisation\n  (DataHasValue :keyLength xsd:integer))\n(SubClassOf :Pseudonymisation\n  (DataHasValue :reversible xsd:boolean))\n(SubClassOf :Pseudonymisation\n  (DataHasValue :linkabilityRisk\n    (DatatypeRestriction xsd:float (MinInclusive \"0.0\") (MaxInclusive \"1.0\"))))\n\n;; GDPR Recognition\n(SubClassOf :Pseudonymisation\n  (ObjectSomeValuesFrom :recognisedBy\n    (ObjectUnionOf :GDPR_Article4_5 ;; Definition\n                   :GDPR_Article25 ;; Privacy by design\n                   :GDPR_Article32 ;; Security measure\n                   :GDPR_Recital28 ;; Reduced risks)))\n\n;; Application Domains\n(SubClassOf :Pseudonymisation\n  (ObjectSomeValuesFrom :appliesTo\n    (ObjectUnionOf :UserIdentifiers\n                   :MedicalRecords\n                   :TransactionData\n                   :BehaviouralData\n                   :BiometricTemplates)))\n\n;; ML-Specific Uses\n(SubClassOf :Pseudonymisation\n  (ObjectSomeValuesFrom :supports\n    (ObjectUnionOf :ModelTraining\n                   :DataLinkage\n                   :CrossDatasetAnalysis\n                   :AuditableProcessing)))\n      ```",
  "properties": {
    "id": "0427-pseudonymisation-owl-axioms",
    "collapsed": "true",
    "- public-access": "true",
    "- ontology": "true",
    "- is-subclass-of": "[[ArtificialIntelligenceTechnology]]",
    "- term-id": "AI-0427",
    "- preferred-term": "Pseudonymisation",
    "- source-domain": "ai-grounded",
    "- status": "in-progress",
    "- version": "1.0",
    "- last-updated": "2025-10-29",
    "- definition": "Pseudonymisation is a data protection technique defined in GDPR Article 4(5) as processing personal data such that it can no longer be attributed to a specific data subject without additional information, which is kept separately under technical and organizational measures preventing re-identification. This approach replaces direct identifiers (names, email addresses, national identification numbers) with pseudonyms (aliases, tokens, or encrypted identifiers) while maintaining data utility for analysis, creating reversible anonymization that reduces but does not eliminate re-identification risk unlike full anonymization which irreversibly severs links between data and individuals. Implementation techniques include cryptographic hashing applying one-way hash functions (SHA-256, HMAC) with secret keys converting identifiers to fixed-length pseudonyms deterministically enabling consistent linkage across datasets while preventing reverse lookup without keys, tokenization replacing sensitive identifiers with randomly generated tokens stored in secure mapping tables enabling authorized re-identification when necessary, encryption-based pseudonymisation using symmetric or asymmetric encryption with keys managed separately from pseudonymized data, and deterministic or format-preserving techniques maintaining data structure (preserving ZIP code format, date formats) for compatibility with legacy systems. GDPR recognition appears across multiple articles including Article 4(5) defining the technique, Article 25 recommending pseudonymisation as privacy-by-design measure, Article 32 listing it as appropriate security measure, and Recital 28 noting pseudonymisation reduces risks to data subjects allowing data controllers to meet protection obligations while permitting useful data processing. Benefits include reduced re-identification risk as pseudonymized data presents higher barriers to linking records with real identities, regulatory flexibility with GDPR treating pseudonymized data more favorably than identifiable personal data for certain processing activities, data utility preservation enabling meaningful analytics, reporting, and machine learning on protected datasets while maintaining referential integrity, and breach impact mitigation as stolen pseudonymized data has limited value without corresponding key material or mapping tables. Applications in AI systems span training data protection pseudonymizing subjects in training datasets preventing model memorization of real identities, cross-organizational collaboration enabling data sharing for collaborative ML without exposing participant identities, longitudinal analysis tracking individuals across time periods for behavior modeling while protecting identity, and audit trail privacy maintaining activity logs for security monitoring without storing plaintext user identifiers, though limitations include remaining personal data status under GDPR as pseudonymized data still constitutes personal data subject to regulatory requirements, linkability vulnerabilities where deterministic pseudonymisation enables tracking across contexts potentially revealing behavioral patterns, key management complexity requiring secure storage and access controls for re-identification keys, and potential re-identification through auxiliary information attacks combining pseudonymized data with external datasets to unm ask identities.",
    "- maturity": "mature",
    "- source": "[[GDPR Article 4(5)]], [[GDPR Article 25]], [[GDPR Article 32]]",
    "- authority-score": "0.95",
    "- owl:class": "aigo:Pseudonymisation",
    "- owl:physicality": "VirtualEntity",
    "- owl:role": "Process",
    "- owl:inferred-class": "aigo:VirtualProcess",
    "- belongsToDomain": "[[AIEthicsDomain]]",
    "- implementedInLayer": "[[ConceptualLayer]]"
  },
  "backlinks": [],
  "wiki_links": [
    "ArtificialIntelligenceTechnology",
    "AIEthicsDomain",
    "GDPR Article 25",
    "ConceptualLayer",
    "GDPR Article 4(5)",
    "GDPR Article 32"
  ],
  "ontology": {
    "term_id": "AI-0427",
    "preferred_term": "Pseudonymisation",
    "definition": "Pseudonymisation is a data protection technique defined in GDPR Article 4(5) as processing personal data such that it can no longer be attributed to a specific data subject without additional information, which is kept separately under technical and organizational measures preventing re-identification. This approach replaces direct identifiers (names, email addresses, national identification numbers) with pseudonyms (aliases, tokens, or encrypted identifiers) while maintaining data utility for analysis, creating reversible anonymization that reduces but does not eliminate re-identification risk unlike full anonymization which irreversibly severs links between data and individuals. Implementation techniques include cryptographic hashing applying one-way hash functions (SHA-256, HMAC) with secret keys converting identifiers to fixed-length pseudonyms deterministically enabling consistent linkage across datasets while preventing reverse lookup without keys, tokenization replacing sensitive identifiers with randomly generated tokens stored in secure mapping tables enabling authorized re-identification when necessary, encryption-based pseudonymisation using symmetric or asymmetric encryption with keys managed separately from pseudonymized data, and deterministic or format-preserving techniques maintaining data structure (preserving ZIP code format, date formats) for compatibility with legacy systems. GDPR recognition appears across multiple articles including Article 4(5) defining the technique, Article 25 recommending pseudonymisation as privacy-by-design measure, Article 32 listing it as appropriate security measure, and Recital 28 noting pseudonymisation reduces risks to data subjects allowing data controllers to meet protection obligations while permitting useful data processing. Benefits include reduced re-identification risk as pseudonymized data presents higher barriers to linking records with real identities, regulatory flexibility with GDPR treating pseudonymized data more favorably than identifiable personal data for certain processing activities, data utility preservation enabling meaningful analytics, reporting, and machine learning on protected datasets while maintaining referential integrity, and breach impact mitigation as stolen pseudonymized data has limited value without corresponding key material or mapping tables. Applications in AI systems span training data protection pseudonymizing subjects in training datasets preventing model memorization of real identities, cross-organizational collaboration enabling data sharing for collaborative ML without exposing participant identities, longitudinal analysis tracking individuals across time periods for behavior modeling while protecting identity, and audit trail privacy maintaining activity logs for security monitoring without storing plaintext user identifiers, though limitations include remaining personal data status under GDPR as pseudonymized data still constitutes personal data subject to regulatory requirements, linkability vulnerabilities where deterministic pseudonymisation enables tracking across contexts potentially revealing behavioral patterns, key management complexity requiring secure storage and access controls for re-identification keys, and potential re-identification through auxiliary information attacks combining pseudonymized data with external datasets to unm ask identities.",
    "source_domain": "ai-grounded",
    "maturity_level": null,
    "authority_score": 0.95
  }
}