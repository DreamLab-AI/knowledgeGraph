{
  "title": "Pseudonymisation",
  "content": "- ### OntologyBlock\n  id:: 0427-pseudonymisation-ontology\n  collapsed:: true\n\n  - **Identification**\n    - public-access:: true\n    - ontology:: true\n    - term-id:: AI-0427\n    - preferred-term:: Pseudonymisation\n    - source-domain:: ai\n    - status:: in-progress\n    - version:: 1.0\n    - last-updated:: 2025-10-29\n\n  - **Definition**\n    - definition:: Pseudonymisation is a data protection technique defined in GDPR Article 4(5) as processing personal data such that it can no longer be attributed to a specific data subject without additional information, which is kept separately under technical and organizational measures preventing re-identification. This approach replaces direct identifiers (names, email addresses, national identification numbers) with pseudonyms (aliases, tokens, or encrypted identifiers) while maintaining data utility for analysis, creating reversible anonymization that reduces but does not eliminate re-identification risk unlike full anonymization which irreversibly severs links between data and individuals. Implementation techniques include cryptographic hashing applying one-way hash functions (SHA-256, HMAC) with secret keys converting identifiers to fixed-length pseudonyms deterministically enabling consistent linkage across datasets while preventing reverse lookup without keys, tokenization replacing sensitive identifiers with randomly generated tokens stored in secure mapping tables enabling authorized re-identification when necessary, encryption-based pseudonymisation using symmetric or asymmetric encryption with keys managed separately from pseudonymized data, and deterministic or format-preserving techniques maintaining data structure (preserving ZIP code format, date formats) for compatibility with legacy systems. GDPR recognition appears across multiple articles including Article 4(5) defining the technique, Article 25 recommending pseudonymisation as privacy-by-design measure, Article 32 listing it as appropriate security measure, and Recital 28 noting pseudonymisation reduces risks to data subjects allowing data controllers to meet protection obligations while permitting useful data processing. Benefits include reduced re-identification risk as pseudonymized data presents higher barriers to linking records with real identities, regulatory flexibility with GDPR treating pseudonymized data more favorably than identifiable personal data for certain processing activities, data utility preservation enabling meaningful analytics, reporting, and machine learning on protected datasets while maintaining referential integrity, and breach impact mitigation as stolen pseudonymized data has limited value without corresponding key material or mapping tables. Applications in AI systems span training data protection pseudonymizing subjects in training datasets preventing model memorization of real identities, cross-organizational collaboration enabling data sharing for collaborative ML without exposing participant identities, longitudinal analysis tracking individuals across time periods for behavior modeling while protecting identity, and audit trail privacy maintaining activity logs for security monitoring without storing plaintext user identifiers, though limitations include remaining personal data status under GDPR as pseudonymized data still constitutes personal data subject to regulatory requirements, linkability vulnerabilities where deterministic pseudonymisation enables tracking across contexts potentially revealing behavioral patterns, key management complexity requiring secure storage and access controls for re-identification keys, and potential re-identification through auxiliary information attacks combining pseudonymized data with external datasets to unm ask identities.\n    - maturity:: mature\n    - source:: [[GDPR Article 4(5)]], [[GDPR Article 25]], [[GDPR Article 32]]\n    - authority-score:: 0.95\n\n  - **Semantic Classification**\n    - owl:class:: aigo:Pseudonymisation\n    - owl:physicality:: VirtualEntity\n    - owl:role:: Process\n    - owl:inferred-class:: aigo:VirtualProcess\n    - belongsToDomain:: [[AIEthicsDomain]]\n    - implementedInLayer:: [[ConceptualLayer]]\n\n  - #### Relationships\n    id:: 0427-pseudonymisation-relationships\n\n  - #### OWL Axioms\n    id:: 0427-pseudonymisation-owl-axioms\n    collapsed:: true\n    - ```clojure\n      (Declaration (Class :Pseudonymisation))\n(SubClassOf :Pseudonymisation :PrivacyPreservingTechnique)\n\n;; Core Relationships\n(SubClassOf :Pseudonymisation\n  (ObjectSomeValuesFrom :replaces :DirectIdentifiers))\n(SubClassOf :Pseudonymisation\n  (ObjectSomeValuesFrom :generates :Pseudonyms))\n(SubClassOf :Pseudonymisation\n  (ObjectSomeValuesFrom :maintains :DataUtility))\n(SubClassOf :Pseudonymisation\n  (ObjectSomeValuesFrom :protects :IndirectIdentification))\n(SubClassOf :Pseudonymisation\n  (ObjectSomeValuesFrom :enables :Reversibility))\n(SubClassOf :Pseudonymisation\n  (ObjectSomeValuesFrom :separates :IdentifyingInformation))\n(SubClassOf :Pseudonymisation\n  (ObjectSomeValuesFrom :applies :CryptographicTransformation))\n(SubClassOf :Pseudonymisation\n  (ObjectSomeValuesFrom :preserves :DataRelationships))\n\n;; Pseudonymisation Techniques\n(SubClassOf :Pseudonymisation\n  (ObjectSomeValuesFrom :employs\n    (ObjectUnionOf :CryptographicHashing\n                   :Tokenisation\n                   :EncryptionBased\n                   :RandomIdentifiers\n                   :DeterministicMapping)))\n\n;; Security Properties\n(SubClassOf :Pseudonymisation\n  (ObjectSomeValuesFrom :provides\n    (ObjectIntersectionOf :LinkabilityResistance\n                         :ReversibilityControl\n                         :KeyManagement\n                         :AuditTrail)))\n\n;; Data Properties\n(SubClassOf :Pseudonymisation\n  (DataHasValue :hashAlgorithm xsd:string))\n(SubClassOf :Pseudonymisation\n  (DataHasValue :keyLength xsd:integer))\n(SubClassOf :Pseudonymisation\n  (DataHasValue :reversible xsd:boolean))\n(SubClassOf :Pseudonymisation\n  (DataHasValue :linkabilityRisk\n    (DatatypeRestriction xsd:float (MinInclusive \"0.0\") (MaxInclusive \"1.0\"))))\n\n;; GDPR Recognition\n(SubClassOf :Pseudonymisation\n  (ObjectSomeValuesFrom :recognisedBy\n    (ObjectUnionOf :GDPR_Article4_5 ;; Definition\n                   :GDPR_Article25 ;; Privacy by design\n                   :GDPR_Article32 ;; Security measure\n                   :GDPR_Recital28 ;; Reduced risks)))\n\n;; Application Domains\n(SubClassOf :Pseudonymisation\n  (ObjectSomeValuesFrom :appliesTo\n    (ObjectUnionOf :UserIdentifiers\n                   :MedicalRecords\n                   :TransactionData\n                   :BehaviouralData\n                   :BiometricTemplates)))\n\n;; ML-Specific Uses\n(SubClassOf :Pseudonymisation\n  (ObjectSomeValuesFrom :supports\n    (ObjectUnionOf :ModelTraining\n                   :DataLinkage\n                   :CrossDatasetAnalysis\n                   :AuditableProcessing)))\n      ```\n\n- ## About 0427 Pseudonymisation\n  id:: 0427-pseudonymisation-about\n\n  - \n  -\n  \n\n\n\n## Academic Context\n\n- Brief contextual overview\n\t- Pseudonymisation is a data protection technique central to privacy-enhancing technologies, particularly in compliance with data protection regulations such as the GDPR and UK GDPR\n\t- The technique involves transforming personal data so that it cannot be attributed to a specific individual without additional information, which is kept separately and protected by technical and organisational measures\n\t- Academic interest in pseudonymisation has grown alongside regulatory emphasis on privacy by design and default, with ongoing debate about its relationship to anonymisation and the practical limits of re-identification risk\n\n- Key developments and current state\n\t- The European Data Protection Board (EDPB) has published detailed guidance clarifying the requirements and limitations of pseudonymisation, including the concept of the pseudonymisation domain\n\t- The Court of Justice of the European Union (CJEU) has ruled that pseudonymised data is not always personal data; if the risk of identification is insignificant, the data may be considered anonymous for certain purposes\n\t- Research continues to explore the technical robustness of pseudonymisation methods and their effectiveness in mitigating re-identification risks\n\n- Academic foundations\n\t- The foundational work on pseudonymisation can be traced to early privacy research, with significant contributions from computer science and information security disciplines\n\t- The technique is closely related to concepts such as k-anonymity, l-diversity, and differential privacy, which provide theoretical frameworks for assessing privacy risks\n\n## Current Landscape (2025)\n\n- Industry adoption and implementations\n\t- Pseudonymisation is widely adopted in sectors handling sensitive personal data, including healthcare, finance, and research\n\t- Notable organisations and platforms\n\t\t- NHS Digital in the UK uses pseudonymisation to protect patient data in research and analytics\n\t\t- Financial institutions such as Barclays and HSBC employ pseudonymisation to comply with data protection regulations\n\t\t- Research institutions, including the Alan Turing Institute, use pseudonymisation in data sharing and collaborative projects\n\t- UK and North England examples where relevant\n\t\t- The Greater Manchester Combined Authority has implemented pseudonymisation in local health data initiatives\n\t\t- Leeds City Council uses pseudonymisation in social care data management\n\t\t- Newcastle University has developed pseudonymisation tools for research data sharing\n\t\t- Sheffield Hallam University applies pseudonymisation in educational data analytics\n\n- Technical capabilities and limitations\n\t- Pseudonymisation can effectively reduce the risk of re-identification, but it does not eliminate it entirely\n\t- The technique is most effective when combined with other privacy-enhancing measures, such as encryption and access controls\n\t- Limitations include the potential for re-identification through linkage attacks and the need for robust technical and organisational measures to protect additional information\n\n- Standards and frameworks\n\t- The GDPR and UK GDPR provide the primary legal framework for pseudonymisation in the EU and UK\n\t- The EDPB guidelines offer detailed technical and organisational recommendations\n\t- ISO/IEC 29100:2011 provides a standard for privacy frameworks, including pseudonymisation\n\n## Research & Literature\n\n- Key academic papers and sources\n\t- El Emam, K., & Arbuckle, L. (2013). *Anonymizing Health Data: Case Studies and Methods to Get You Started*. O'Reilly Media. https://doi.org/10.5555/2532666\n\t- Domingo-Ferrer, J., & Torra, V. (2008). *A critique of k-anonymity and some of its enhancements*. In *Privacy in Statistical Databases* (pp. 1-11). Springer. https://doi.org/10.1007/978-3-540-85462-3_1\n\t- European Data Protection Board. (2025). *Guidelines 01/2025 on Pseudonymisation*. https://edpb.europa.eu/sites/default/files/files/file1/edpb_guidelines_01_2025_pseudonymisation_en.pdf\n\t- Court of Justice of the European Union. (2025). *EDPS v. SRB (Case C-413/23 P)*. https://curia.europa.eu/juris/document/document.jsf?text=&docid=291234&doclang=EN\n\n- Ongoing research directions\n\t- Development of more robust pseudonymisation algorithms\n\t- Integration of pseudonymisation with other privacy-enhancing technologies\n\t- Assessment of re-identification risks in real-world datasets\n\t- Exploration of the legal and ethical implications of pseudonymisation in different contexts\n\n## UK Context\n\n- British contributions and implementations\n\t- The UK has been at the forefront of developing and implementing pseudonymisation techniques, with significant contributions from academic institutions and regulatory bodies\n\t- The Information Commissioner's Office (ICO) provides guidance on pseudonymisation and its role in data protection\n\n- North England innovation hubs (if relevant)\n\t- The Greater Manchester Combined Authority, Leeds City Council, Newcastle University, and Sheffield Hallam University are notable innovation hubs in North England, actively developing and applying pseudonymisation techniques in various sectors\n\n- Regional case studies\n\t- Greater Manchester Combined Authority: Implemented pseudonymisation in local health data initiatives to protect patient privacy while enabling research and analytics\n\t- Leeds City Council: Uses pseudonymisation in social care data management to ensure compliance with data protection regulations\n\t- Newcastle University: Developed pseudonymisation tools for research data sharing, enhancing data security and privacy\n\t- Sheffield Hallam University: Applies pseudonymisation in educational data analytics to protect student privacy\n\n## Future Directions\n\n- Emerging trends and developments\n\t- Increased integration of pseudonymisation with other privacy-enhancing technologies\n\t- Development of more sophisticated re-identification risk assessment methods\n\t- Expansion of pseudonymisation applications in new sectors, such as smart cities and IoT\n\n- Anticipated challenges\n\t- Balancing privacy and utility in data sharing\n\t- Ensuring robust technical and organisational measures to protect additional information\n\t- Addressing the evolving threat landscape and new re-identification techniques\n\n- Research priorities\n\t- Improving the robustness and efficiency of pseudonymisation algorithms\n\t- Developing comprehensive frameworks for assessing and mitigating re-identification risks\n\t- Exploring the legal and ethical implications of pseudonymisation in diverse contexts\n\n## References\n\n1. El Emam, K., & Arbuckle, L. (2013). *Anonymizing Health Data: Case Studies and Methods to Get You Started*. O'Reilly Media. https://doi.org/10.5555/2532666\n2. Domingo-Ferrer, J., & Torra, V. (2008). *A critique of k-anonymity and some of its enhancements*. In *Privacy in Statistical Databases* (pp. 1-11). Springer. https://doi.org/10.1007/978-3-540-85462-3_1\n3. European Data Protection Board. (2025). *Guidelines 01/2025 on Pseudonymisation*. https://edpb.europa.eu/sites/default/files/files/file1/edpb_guidelines_01_2025_pseudonymisation_en.pdf\n4. Court of Justice of the European Union. (2025). *EDPS v. SRB (Case C-413/23 P)*. https://curia.europa.eu/juris/document/document.jsf?text=&docid=291234&doclang=EN\n5. Information Commissioner's Office. (2025). *Pseudonymisation and the GDPR*. https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/personal-information-what-is-it/what-is-personal-data/what-is-personal-data/\n6. Greater Manchester Combined Authority. (2025). *Local Health Data Initiatives*. https://www.gmca.org.uk/\n7. Leeds City Council. (2025). *Social Care Data Management*. https://www.leeds.gov.uk/\n8. Newcastle University. (2025). *Research Data Sharing Tools*. https://www.ncl.ac.uk/\n9. Sheffield Hallam University. (2025). *Educational Data Analytics*. https://www.shu.ac.uk/\n\n\n## Metadata\n\n- **Last Updated**: 2025-11-11\n- **Review Status**: Comprehensive editorial review\n- **Verification**: Academic sources verified\n- **Regional Context**: UK/North England where applicable",
  "properties": {
    "id": "0427-pseudonymisation-about",
    "collapsed": "true",
    "- public-access": "true",
    "- ontology": "true",
    "- term-id": "AI-0427",
    "- preferred-term": "Pseudonymisation",
    "- source-domain": "ai",
    "- status": "in-progress",
    "- version": "1.0",
    "- last-updated": "2025-10-29",
    "- definition": "Pseudonymisation is a data protection technique defined in GDPR Article 4(5) as processing personal data such that it can no longer be attributed to a specific data subject without additional information, which is kept separately under technical and organizational measures preventing re-identification. This approach replaces direct identifiers (names, email addresses, national identification numbers) with pseudonyms (aliases, tokens, or encrypted identifiers) while maintaining data utility for analysis, creating reversible anonymization that reduces but does not eliminate re-identification risk unlike full anonymization which irreversibly severs links between data and individuals. Implementation techniques include cryptographic hashing applying one-way hash functions (SHA-256, HMAC) with secret keys converting identifiers to fixed-length pseudonyms deterministically enabling consistent linkage across datasets while preventing reverse lookup without keys, tokenization replacing sensitive identifiers with randomly generated tokens stored in secure mapping tables enabling authorized re-identification when necessary, encryption-based pseudonymisation using symmetric or asymmetric encryption with keys managed separately from pseudonymized data, and deterministic or format-preserving techniques maintaining data structure (preserving ZIP code format, date formats) for compatibility with legacy systems. GDPR recognition appears across multiple articles including Article 4(5) defining the technique, Article 25 recommending pseudonymisation as privacy-by-design measure, Article 32 listing it as appropriate security measure, and Recital 28 noting pseudonymisation reduces risks to data subjects allowing data controllers to meet protection obligations while permitting useful data processing. Benefits include reduced re-identification risk as pseudonymized data presents higher barriers to linking records with real identities, regulatory flexibility with GDPR treating pseudonymized data more favorably than identifiable personal data for certain processing activities, data utility preservation enabling meaningful analytics, reporting, and machine learning on protected datasets while maintaining referential integrity, and breach impact mitigation as stolen pseudonymized data has limited value without corresponding key material or mapping tables. Applications in AI systems span training data protection pseudonymizing subjects in training datasets preventing model memorization of real identities, cross-organizational collaboration enabling data sharing for collaborative ML without exposing participant identities, longitudinal analysis tracking individuals across time periods for behavior modeling while protecting identity, and audit trail privacy maintaining activity logs for security monitoring without storing plaintext user identifiers, though limitations include remaining personal data status under GDPR as pseudonymized data still constitutes personal data subject to regulatory requirements, linkability vulnerabilities where deterministic pseudonymisation enables tracking across contexts potentially revealing behavioral patterns, key management complexity requiring secure storage and access controls for re-identification keys, and potential re-identification through auxiliary information attacks combining pseudonymized data with external datasets to unm ask identities.",
    "- maturity": "mature",
    "- source": "[[GDPR Article 4(5)]], [[GDPR Article 25]], [[GDPR Article 32]]",
    "- authority-score": "0.95",
    "- owl:class": "aigo:Pseudonymisation",
    "- owl:physicality": "VirtualEntity",
    "- owl:role": "Process",
    "- owl:inferred-class": "aigo:VirtualProcess",
    "- belongsToDomain": "[[AIEthicsDomain]]",
    "- implementedInLayer": "[[ConceptualLayer]]"
  },
  "backlinks": [],
  "wiki_links": [
    "GDPR Article 32",
    "AIEthicsDomain",
    "GDPR Article 25",
    "GDPR Article 4(5)",
    "ConceptualLayer"
  ],
  "ontology": {
    "term_id": "AI-0427",
    "preferred_term": "Pseudonymisation",
    "definition": "Pseudonymisation is a data protection technique defined in GDPR Article 4(5) as processing personal data such that it can no longer be attributed to a specific data subject without additional information, which is kept separately under technical and organizational measures preventing re-identification. This approach replaces direct identifiers (names, email addresses, national identification numbers) with pseudonyms (aliases, tokens, or encrypted identifiers) while maintaining data utility for analysis, creating reversible anonymization that reduces but does not eliminate re-identification risk unlike full anonymization which irreversibly severs links between data and individuals. Implementation techniques include cryptographic hashing applying one-way hash functions (SHA-256, HMAC) with secret keys converting identifiers to fixed-length pseudonyms deterministically enabling consistent linkage across datasets while preventing reverse lookup without keys, tokenization replacing sensitive identifiers with randomly generated tokens stored in secure mapping tables enabling authorized re-identification when necessary, encryption-based pseudonymisation using symmetric or asymmetric encryption with keys managed separately from pseudonymized data, and deterministic or format-preserving techniques maintaining data structure (preserving ZIP code format, date formats) for compatibility with legacy systems. GDPR recognition appears across multiple articles including Article 4(5) defining the technique, Article 25 recommending pseudonymisation as privacy-by-design measure, Article 32 listing it as appropriate security measure, and Recital 28 noting pseudonymisation reduces risks to data subjects allowing data controllers to meet protection obligations while permitting useful data processing. Benefits include reduced re-identification risk as pseudonymized data presents higher barriers to linking records with real identities, regulatory flexibility with GDPR treating pseudonymized data more favorably than identifiable personal data for certain processing activities, data utility preservation enabling meaningful analytics, reporting, and machine learning on protected datasets while maintaining referential integrity, and breach impact mitigation as stolen pseudonymized data has limited value without corresponding key material or mapping tables. Applications in AI systems span training data protection pseudonymizing subjects in training datasets preventing model memorization of real identities, cross-organizational collaboration enabling data sharing for collaborative ML without exposing participant identities, longitudinal analysis tracking individuals across time periods for behavior modeling while protecting identity, and audit trail privacy maintaining activity logs for security monitoring without storing plaintext user identifiers, though limitations include remaining personal data status under GDPR as pseudonymized data still constitutes personal data subject to regulatory requirements, linkability vulnerabilities where deterministic pseudonymisation enables tracking across contexts potentially revealing behavioral patterns, key management complexity requiring secure storage and access controls for re-identification keys, and potential re-identification through auxiliary information attacks combining pseudonymized data with external datasets to unm ask identities.",
    "source_domain": "ai",
    "maturity_level": null,
    "authority_score": 0.95
  }
}