{
  "title": "AI Model Card",
  "content": "- ### OntologyBlock\n  id:: ai-model-card-ontology\n  collapsed:: true\n\t- ontology:: true\n\t- term-id:: 20120\n\t- source-domain:: metaverse\n\t- status:: complete\n    - public-access:: true\n\t- preferred-term:: AI Model Card\n\t- version:: 1.1.0\n\t- last-updated:: 2025-11-15\n\t- quality-score:: 0.91\n\t- bitcoin-ai-relevance:: medium\n\t- cross-domain-links:: 45\n\t- definition:: A structured documentation format that describes an [[AI Model]]'s purpose, [[Performance Metrics]], limitations, [[Ethical Considerations]], and appropriate [[Use Case|use cases]] to promote [[Transparency]] and [[Responsible AI Deployment|responsible deployment]]. In 2025, model cards are required by [[EU AI Act]] for high-risk systems and recommended by [[OECD]] for all AI applications, including [[Bitcoin Trading Bot|trading systems]], [[Blockchain Analytics]], and [[Smart Contract Auditing]].\n\t- maturity:: mature\n\t- source:: [[Google Model Cards for Model Reporting]] (https://modelcards.withgoogle.com/), [[Mitchell et al. 2019]] (https://arxiv.org/abs/1810.03993), [[ISO/IEC 42001]] (https://www.iso.org/standard/81230.html)\n\t- owl:class:: mv:AIModelCard\n\t- owl:physicality:: VirtualEntity\n\t- owl:role:: Object\n\t- owl:inferred-class:: mv:VirtualObject\n\t- owl:functional-syntax:: true\n\t- belongsToDomain:: [[ComputationAndIntelligenceDomain]], [[TrustAndGovernanceDomain]]\n\t- implementedInLayer:: [[Data Layer]], [[Application Layer]]\n\t- #### Relationships\n\t  id:: ai-model-card-relationships\n\t\t- has-part:: [[Model Details]], [[Performance Metrics]], [[Limitations Section]], [[Ethical Considerations]], [[Use Case Descriptions]], [[Training Data Information]], [[Bias Analysis]], [[Fairness Metrics]], [[Security Considerations]]\n\t\t- is-part-of:: [[AI Documentation Framework]], [[Model Governance System]], [[AI Risk Management]], [[Compliance Documentation]]\n\t\t- requires:: [[Model Evaluation Results]], [[Training Dataset Metadata]], [[Performance Benchmarks]], [[Demographic Performance Analysis]], [[Safety Testing Results]]\n\t\t- depends-on:: [[AI Ethics Guidelines]], [[Model Testing Protocols]], [[Documentation Standards]], [[Regulatory Requirements]], [[Industry Best Practices]]\n\t\t- enables:: [[Model Transparency]], [[Responsible AI Deployment]], [[Informed Decision Making]], [[AI Accountability]], [[Regulatory Compliance]], [[Procurement Due Diligence]], [[Third-Party Auditing]]\n\t\t- supports:: [[Bitcoin Trading System|Bitcoin trading]] documentation, [[Smart Contract]] AI verification, [[DeFi Protocol]] transparency, [[Blockchain Analytics]] accountability\n\t- #### OWL Axioms\n\t  id:: ai-model-card-owl-axioms\n\t  collapsed:: true\n\t\t- ```clojure\n\t\t  Declaration(Class(mv:AIModelCard))\n\n\t\t  # Classification along two primary dimensions\n\t\t  SubClassOf(mv:AIModelCard mv:VirtualEntity)\n\t\t  SubClassOf(mv:AIModelCard mv:Object)\n\n\t\t  # Domain-specific constraints\n\t\t  SubClassOf(mv:AIModelCard\n\t\t    ObjectSomeValuesFrom(mv:belongsToDomain mv:ComputationAndIntelligenceDomain)\n\t\t  )\n\n\t\t  SubClassOf(mv:AIModelCard\n\t\t    ObjectSomeValuesFrom(mv:belongsToDomain mv:TrustAndGovernanceDomain)\n\t\t  )\n\n\t\t  SubClassOf(mv:AIModelCard\n\t\t    ObjectSomeValuesFrom(mv:implementedInLayer mv:DataLayer)\n\t\t  )\n\n\t\t  SubClassOf(mv:AIModelCard\n\t\t    ObjectSomeValuesFrom(mv:implementedInLayer mv:ApplicationLayer)\n\t\t  )\n\n\t\t  # Required components\n\t\t  SubClassOf(mv:AIModelCard\n\t\t    ObjectSomeValuesFrom(mv:hasPart mv:ModelDetails)\n\t\t  )\n\n\t\t  SubClassOf(mv:AIModelCard\n\t\t    ObjectSomeValuesFrom(mv:hasPart mv:PerformanceMetrics)\n\t\t  )\n\n\t\t  SubClassOf(mv:AIModelCard\n\t\t    ObjectSomeValuesFrom(mv:requires mv:ModelEvaluationResults)\n\t\t  )\n\n\t\t  SubClassOf(mv:AIModelCard\n\t\t    ObjectSomeValuesFrom(mv:enables mv:ModelTransparency)\n\t\t  )\n\n  # Property characteristics\n  TransitiveObjectProperty(dt:ispartof)\n\n  # Property characteristics\n  AsymmetricObjectProperty(dt:requires)\n\n  # Property characteristics\n  AsymmetricObjectProperty(dt:dependson)\n\n  # Property characteristics\n  AsymmetricObjectProperty(dt:enables)\n```\n- ## About AI Model Card\n  id:: ai-model-card-about\n\t- AI Model Cards are structured documents that provide transparent, comprehensive information about [[Machine Learning Model|machine learning models]]. Originally introduced by [[Google Research|Google researchers]] in 2019 (Mitchell et al., https://arxiv.org/abs/1810.03993), model cards have become a standard practice for documenting [[AI System|AI systems]], particularly in high-stakes domains. They serve as \"nutrition labels\" for AI models, offering stakeholders—including [[Developers]], [[Deployers]], [[Policymakers]], and [[End-Users]]—clear insights into a model's capabilities, limitations, and appropriate applications.\n\t- In [[Metaverse]] environments, where AI models power everything from [[Avatar Behavior]] to [[Content Moderation]] and [[Personalized Experience|personalized experiences]], model cards are crucial for establishing [[Trust]], ensuring [[Ethical Deployment]], and maintaining [[Regulatory Compliance]] with emerging [[AI Governance]] frameworks. Similarly, in [[Blockchain]] and [[Cryptocurrency]] contexts, model cards document [[Bitcoin Trading Bot|trading algorithms]], [[Smart Contract Verification]] models, [[Fraud Detection System|fraud detection systems]], and [[Market Analysis]] AI, ensuring transparency and accountability in [[DeFi]] and [[Crypto Asset]] management.\n\t- ### Key Characteristics\n\t  id:: ai-model-card-characteristics\n\t\t- **Structured Format**: Follows standardized template ensuring consistent documentation across different models and organizations\n\t\t- **Comprehensive Coverage**: Documents model purpose, [[Model Architecture|architecture]], [[Training Data]], [[Performance]], [[Limitations]], and [[Ethical Considerations]]\n\t\t- **Transparency Focus**: Makes implicit model characteristics explicit to support [[Informed Decision-Making]]\n\t\t- **Stakeholder-Oriented**: Addresses information needs of multiple audiences from technical [[Developers]] to non-technical [[Decision-Makers]]\n\t\t- **Version Controlled**: Tracks changes to [[Model Documentation]] as models evolve and are updated\n\t\t- **Machine-Readable**: Often formatted (e.g., [[JSON]], [[YAML]], [[RDF]]) to support automated processing and integration with [[Model Registry|model registries]]\n\t\t- **Standards-Aligned**: Increasingly aligned with regulatory frameworks such as [[EU AI Act]] (https://artificialintelligenceact.eu/) and [[ISO/IEC 42001]] (https://www.iso.org/standard/81230.html)\n\t\t- **Domain-Specific Extensions**: Specialized model cards for [[Healthcare AI]] (CHAI), [[Financial Services]] (FCA), [[Cryptocurrency]] ([[Bitcoin]] trading, [[DeFi]] protocols), [[Autonomous Systems]]\n\t- ### Technical Components\n\t  id:: ai-model-card-components\n\t\t- [[Model Details]] - Basic information including model name, version, type, [[Model Architecture|architecture]], and [[Development Team]]\n\t\t- [[Performance Metrics]] - Quantitative evaluation results across different [[Datasets]], [[Demographic Group|demographic groups]], and [[Use Case|use cases]]\n\t\t- [[Limitations Section]] - Explicit documentation of known limitations, [[Failure Mode|failure modes]], and [[Out-of-Scope Application|out-of-scope applications]]\n\t\t- [[Ethical Considerations]] - Analysis of [[Fairness]], [[Algorithmic Bias|bias]], [[Privacy]] implications, and [[Societal Impact|societal impacts]]\n\t\t- [[Use Case Descriptions]] - Intended applications and examples of appropriate [[Deployment Context|deployment contexts]]\n\t\t- [[Training Data Information]] - Details about [[Datasets]] used for training including sources, demographics, and [[Data Preprocessing|preprocessing]]\n\t\t- [[Evaluation Data Information]] - Description of [[Test Datasets]] and [[Evaluation Methodology]]\n\t\t- [[Quantitative Analysis]] - Detailed performance breakdowns including [[Disaggregated Metrics]]\n\t\t- [[Caveats and Recommendations]] - Guidance for deployment, [[Model Monitoring|monitoring]], and [[Responsible Use]]\n\t\t- [[Security Assessment]] - [[Adversarial Robustness]], [[Model Extraction]] risks, [[Backdoor Attack|backdoor]] vulnerabilities\n\t\t- [[Blockchain-Specific Sections]]: For [[Bitcoin]] and [[Crypto]] models - [[Market Data Sources]], [[Trading Strategy]], [[Risk Parameters]], [[Compliance Status]]\n\t- ### Functional Capabilities\n\t  id:: ai-model-card-capabilities\n\t\t- **Model Transparency**: Provides clear visibility into model characteristics, enabling stakeholders to understand what a model does and how it works\n\t\t- **Responsible AI Deployment**: Supports [[Ethical Decision-Making]] by documenting limitations, biases, and appropriate [[Use Case|use cases]] before deployment\n\t\t- **Informed Decision Making**: Enables technical and non-technical stakeholders to assess whether a model is suitable for their specific context\n\t\t- **AI Accountability**: Creates [[Documentation Trail]] supporting [[Auditing]], [[Compliance Verification]], and [[Accountability Mechanism|accountability mechanisms]]\n\t\t- **Risk Assessment**: Facilitates identification of potential risks and harms before [[Model Deployment]] in [[Production System|production systems]]\n\t\t- **Bias Detection**: Documents [[Performance Disparities]] across [[Demographic Group|demographic groups]], supporting [[Fairness Analysis]]\n\t\t- **Regulatory Compliance**: Helps organizations meet transparency requirements in [[AI Regulations]] such as [[EU AI Act]], [[GDPR]], [[MiCA]], [[SEC]] rules\n\t\t- **Knowledge Sharing**: Enables [[Model Developer|model developers]] to communicate capabilities and limitations to downstream users\n\t\t- **Procurement Support**: Assists organizations in evaluating [[AI Vendors]], [[Model Marketplaces]], [[MLaaS Providers]]\n\t\t- **Crypto Transparency**: Documents [[Bitcoin Trading Bot|trading bot]] strategies, [[DeFi Protocol]] risk models, [[Blockchain Analytics]] methodologies, [[Smart Contract]] verification approaches\n\t- ### Use Cases\n\t  id:: ai-model-card-use-cases\n\t\t- **Model Selection**: Organizations evaluating multiple [[AI Model|AI models]] use model cards to compare capabilities and select the most appropriate solution\n\t\t- **Procurement Due Diligence**: Enterprises purchasing [[AI Solutions]] review model cards to assess quality, limitations, and [[Ethical Considerations]]\n\t\t- **Regulatory Compliance**: Organizations subject to [[AI Regulations]] use model cards to demonstrate compliance with transparency requirements\n\t\t- **Internal Model Governance**: Companies with multiple AI models use standardized model cards for centralized [[Model Registry]] and [[AI Governance]]\n\t\t- **Public AI Systems**: Government agencies deploying public-facing AI services publish model cards to ensure [[Transparency]] and [[Public Accountability]]\n\t\t- **Research Publication**: Academic and industry researchers include model cards when publishing models to facilitate [[Reproducibility]] and [[Responsible Reuse]]\n\t\t- **Metaverse Platform Governance**: [[Metaverse]] platforms require AI providers to submit model cards for [[Avatar Intelligence]], [[Content Moderation]], and [[Recommendation System|recommendation systems]]\n\t\t- **Third-Party Auditing**: Independent auditors use model cards as starting point for evaluating AI systems for [[Fairness]], [[Safety]], and [[Compliance]]\n\t\t- **Developer Onboarding**: New team members use model cards to quickly understand existing AI systems in their organization's portfolio\n\t\t- **Crypto Asset Trading**: [[Bitcoin]] and [[Cryptocurrency]] exchanges require model cards for [[Algorithmic Trading]] systems, [[Market Making]] bots, [[Risk Management]] models\n\t\t- **DeFi Protocol Governance**: [[Decentralized Finance]] platforms publish model cards for [[Liquidity Pool]] optimization, [[Yield Farming]] strategies, [[Automated Market Maker|AMM]] pricing models\n\t\t- **Blockchain Analytics**: [[On-Chain Analytics]] providers document [[Transaction Classification]], [[Address Clustering]], [[Fraud Detection]] models\n\t\t- **Smart Contract Security**: [[Security Firm|Security firms]] publish model cards for [[Smart Contract Auditing]] AI, [[Vulnerability Detection]], [[Exploit Prediction]]\n\t- ### Standards & References\n\t  id:: ai-model-card-standards\n\t\t- [[Google Model Cards for Model Reporting]] - Original research paper introducing model card framework (Mitchell et al., 2019) (https://arxiv.org/abs/1810.03993)\n\t\t- [[ISO/IEC 42001]] - International standard for [[AI Management Systems]] including documentation requirements (https://www.iso.org/standard/81230.html)\n\t\t- [[EU AI Act]] - European regulation requiring transparency documentation for high-risk AI systems (https://artificialintelligenceact.eu/)\n\t\t- [[OECD AI Principles]] - International framework emphasizing transparency and responsible stewardship of trustworthy AI (https://oecd.ai/en/ai-principles)\n\t\t- [[NIST AI Risk Management Framework]] - U.S. framework including documentation and transparency practices (https://www.nist.gov/itl/ai-risk-management-framework)\n\t\t- [[IEEE 7001]] - Standard for transparency of autonomous systems (https://standards.ieee.org/ieee/7001/)\n\t\t- [[Partnership on AI]] - Industry consortium developing best practices for AI documentation (https://partnershiponai.org/)\n\t\t- [[W3C PROV-O]] - Provenance ontology that can be used for machine-readable model cards (https://www.w3.org/TR/prov-o/)\n\t\t- [[MLCommons]] - Organization developing standardized benchmarks and model documentation practices (https://mlcommons.org/)\n\t\t- [[Coalition for Health AI]] (CHAI) - Healthcare-specific model card framework (https://www.coalitionforhealthai.org/)\n\t\t- [[Hugging Face Model Cards]] - Implementation for [[Large Language Model|LLM]] documentation (https://huggingface.co/docs/hub/model-cards)\n\t\t- [[OpenAI Model Specs]] - Model card examples for [[GPT]] and [[DALL-E]] (https://openai.com/research/)\n\t- ### Related Concepts\n\t  id:: ai-model-card-related\n\t\t- [[AI Ethics Guidelines]] - Broader ethical frameworks that model cards help operationalize\n\t\t- [[Model Governance System]] - Organizational processes for managing [[AI Model Lifecycle]] including documentation\n\t\t- [[Data Card]] - Similar documentation format for [[Datasets]] used to train AI models\n\t\t- [[System Card]] - Extended documentation covering entire [[AI System|AI systems]] beyond individual models\n\t\t- [[Explainable AI]] - Techniques for making [[AI Decision-Making]] interpretable, complementary to model cards\n\t\t- [[AI Audit Trail]] - Logging and tracking mechanisms that model cards help contextualize\n\t\t- [[Responsible AI]] - Overarching approach to ethical AI development and deployment\n\t\t- [[Model Registry]] - System for cataloging and managing AI models, often incorporating model card information\n\t\t- [[Fairness Metrics]] - Quantitative measures of AI fairness documented in model cards\n\t\t- [[VirtualObject]] - Inferred ontology class for documentation formats and data structures\n\t\t- [[AI Governance Principle]] - Foundational guidelines operationalized through model cards\n\t\t- [[Algorithmic Transparency]] - Disclosure requirements for [[Algorithm|algorithms]] and models\n\t\t- [[Model Provenance]] - Tracking [[Training Data]], [[Model Lineage]], [[Versioning]]\n\t\t- [[Regulatory Compliance]] - Meeting [[EU AI Act]], [[GDPR]], [[MiCA]], [[Securities Law]] requirements\n\t\t- [[Blockchain Model Cards]]: Documentation for [[Bitcoin Trading Bot|trading bots]], [[DeFi]] models, [[Smart Contract]] AI, [[Oracle]] systems\n\t\t- [[Crypto Transparency Standards]]: [[AML Compliance]], [[Market Manipulation]] detection, [[Risk Disclosure]]\n\n\n\n# AI Model Card – Updated Ontology Entry\n\n## Academic Context\n\n- AI model cards emerged as a formal documentation standard in 2019, introduced by Mitchell, Gebru, Barnes, and Vasserman to address a critical gap in AI transparency\n  - Prior to their development, minimal standardised information accompanied machine learning models, creating significant risks for organisations attempting to assess suitability for specific applications\n  - The foundational motivation centred on promoting accountability and disclosure of essential model characteristics, including developer identity, intended use cases, performance across demographic groups, training data provenance, and ethical considerations\n  - This standardisation became particularly urgent following documented cases of algorithmic bias—such as discriminatory ad delivery systems—demonstrating how ostensibly neutral parameters could produce harmful outcomes for specific populations\n\n- Model cards function as structured documentation that bridges the gap between raw mathematical models and their real-world deployment contexts\n  - A model in isolation represents merely trained weights and mathematical operations; business value emerges only when embedded within complete AI systems comprising data pipelines, application logic, guardrails, monitoring infrastructure, and user interfaces\n  - Model cards provide the contextual scaffolding necessary for informed decision-making about model selection and integration\n\n## Current Landscape (2025)\n\n- Industry adoption and standardisation frameworks\n  - Model cards have evolved from research proposal to practical [[AI Governance]] tool, with mandatory requirements emerging in [[EU AI Act]] for high-risk systems\n  - The [[Coalition for Health AI]] (CHAI) (https://www.coalitionforhealthai.org/) developed the [[Applied Model Card]] specifically for healthcare use cases, embedding transparency requirements aligned with their Five Principles of [[Responsible AI]]: [[Usefulness]], [[Fairness]], [[Safety]], [[Transparency]], and [[Security & Privacy]]\n  - [[ISO/IEC 42001]] (https://www.iso.org/standard/81230.html) now incorporates model card structures within broader [[AI Management System]] documentation requirements, supporting transparency, [[Risk Management]], and continuous improvement protocols\n  - [[Red Hat]] (https://www.redhat.com/) and other enterprise platforms have formalised model card creation and management as standard practice, recognising their role in reducing integration risk and accelerating responsible adoption\n  - **2025 Crypto Adoption**: [[Coinbase]], [[Binance]], [[Kraken]] now require model cards for [[Algorithmic Trading]] systems; [[Uniswap]], [[Aave]], [[Compound]] publish cards for [[DeFi Protocol|protocol]] AI models\n  - [[Financial Conduct Authority]] (FCA) guidance on model cards for [[Bitcoin]] trading platforms and [[Crypto Asset]] firms (https://www.fca.org.uk/)\n\n- Technical capabilities and standardised content\n  - Model details: developer information, version history, architecture specifications, training algorithms, parameters, fairness constraints, and licensing terms\n  - Intended use: explicit delineation of in-scope applications and out-of-scope restrictions, with identified intended users\n  - Performance metrics: real-world impact assessment across relevant factors including demographic groups, environmental conditions, and technical attributes\n  - Training data documentation: provenance, statistical distribution characteristics, and dataset composition (though proprietary considerations may limit disclosure)\n  - Quantitative analysis: potential biases, failure modes, and performance limitations across use case boundaries\n  - Ethical considerations and recommendations: privacy implications, fairness concerns, individual and societal impacts, plus guidance for ongoing testing and monitoring\n\n- UK and North England context\n  - The [[National Health Service]] (NHS) (https://www.nhs.uk/) and UK health technology assessment bodies increasingly require model cards for AI systems undergoing procurement, particularly following regulatory alignment with [[Medical Device]] classification standards\n  - [[Manchester]], [[Leeds]], and [[Newcastle]] have emerged as significant AI research and development hubs, with academic institutions and technology firms adopting model card documentation as standard practice within their [[AI Governance]] frameworks\n  - The UK's approach to AI regulation, particularly through the [[AI Bill]] framework, emphasises [[Transparency Documentation]] compatible with model card structures, though formal mandates remain under development\n  - **North England Crypto Innovation**: [[Manchester]] [[Fintech]] sector requiring model cards for [[Bitcoin]] custody and trading AI; [[Edinburgh]] [[Blockchain]] hub adopting cards for [[Smart Contract]] verification models\n  - [[University of Manchester]], [[University of Leeds]], [[Newcastle University]] incorporating model card requirements in [[AI Research Ethics]] review processes\n  - [[FCA]] sandbox programmes in [[Manchester]] and [[Leeds]] testing model card frameworks for [[Crypto Asset]] AI applications\n\n## Research & Literature\n\n- Foundational academic work\n  - Mitchell, M., Gebru, T., Barnes, P., & Vasserman, L. (2019). \"Model Cards for Model Reporting.\" *arXiv preprint arXiv:1810.03993*. This seminal paper established the conceptual framework and practical template for model documentation standards.\n  - Buolamwini, B., & Gebru, T. (2018). \"Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification.\" *Conference on Fairness, Accountability and Transparency*, PMLR. Demonstrated empirical necessity for demographic performance documentation.\n\n- Healthcare-specific implementations\n  - Coalition for Health AI. (2024). \"Applied Model Card for Health AI Systems.\" Available through CHAI workgroup documentation. Extends model card framework to clinical decision support systems and predictive diagnostic instruments.\n  - Recent systematic review in *PMC National Center for Biotechnology Information* (2024) examined transparent model cards with layered accessible information for health system procurement, addressing integration with medical device regulatory requirements and Instructions for Use (IFU) standards.\n\n- Standards and governance alignment\n  - ISO/IEC 42001:2023. \"Artificial Intelligence Management System – Requirements and guidance.\" International Organisation for Standardisation. Incorporates model card documentation within broader AI governance frameworks.\n  - Red Hat. (2024). \"Security Beyond the Model: Introducing AI System Cards.\" Technical documentation addressing model cards within complete AI system architectures.\n\n## UK Context\n\n- British regulatory and institutional developments\n  - The Information Commissioner's Office (ICO) has incorporated model card principles within guidance on algorithmic transparency and accountability, particularly for systems processing personal data\n  - UK universities, particularly those in the Russell Group and research-intensive institutions across the North, have adopted model card documentation as standard practice within AI research ethics committees and technology transfer offices\n\n- North England innovation and adoption\n  - Manchester's AI research community, including the University of Manchester's Department of Computer Science and associated technology firms, has integrated model card documentation into AI governance frameworks for healthcare and financial services applications\n  - Leeds and Sheffield universities have incorporated model card requirements within their AI ethics review processes, particularly for externally funded research and industry partnerships\n  - Newcastle's digital innovation initiatives have promoted model card adoption among regional technology enterprises, particularly within healthcare technology and smart city applications\n\n- Regional case studies\n  - NHS trusts across the North have begun requiring model cards for AI procurement decisions, particularly for diagnostic support systems and resource allocation algorithms\n  - Manchester-based fintech and insurtech firms have adopted model card documentation to satisfy regulatory transparency requirements and manage algorithmic bias risks\n\n## Future Directions\n\n- Emerging standardisation and regulatory evolution\n  - Mandatory model card requirements are anticipated within forthcoming [[UK AI Regulation]], particularly for high-risk applications affecting [[Healthcare]], [[Criminal Justice]], and [[Financial Services]]\n  - International harmonisation efforts aim to align model card standards across jurisdictions, reducing [[Compliance Fragmentation]] for multinational organisations\n  - Integration with automated [[AI Governance Platform|governance platforms]] and [[Model Registry|model registries]] will likely streamline creation, versioning, and maintenance workflows\n  - **2025-2026 Crypto Regulations**: [[MiCA]] (EU), [[SEC]] (US), [[FCA]] (UK) mandating model cards for [[High-Frequency Trading]], [[Market Making]], [[Stablecoin]] algorithms\n\n- Technical and methodological developments\n  - Enhanced [[Layered Information Architecture|layered information architectures]] will accommodate diverse stakeholder needs—from technical specialists to procurement officers to policymakers—within single documentation frameworks\n  - Quantitative [[Bias Measurement]] and [[Fairness Metrics]] standardisation remain active research areas, with implications for model card performance documentation\n  - Integration of model cards with [[Continuous Monitoring]] systems and [[Model Drift Detection|drift detection]] mechanisms will support ongoing validation beyond initial deployment\n  - **Blockchain-Specific Innovations**: [[On-Chain Model Cards]], [[Smart Contract]]-enforced transparency, [[Zero-Knowledge Proof|ZK-proof]]-based verification for [[Privacy-Preserving ML]]\n\n- Anticipated challenges and research priorities\n  - Balancing [[Transparency Requirements]] against [[Proprietary Data]] protection and competitive concerns remains unresolved, particularly for [[Foundation Model|foundation models]] and [[Large Language Model|large language systems]]\n  - Standardising [[Performance Metrics]] across heterogeneous [[Use Case|use cases]] and [[Demographic Context|demographic contexts]] presents ongoing methodological challenges\n  - Ensuring model card accessibility and comprehensibility for non-technical stakeholders without sacrificing technical precision requires further investigation\n  - Addressing the \"documentation burden\" for organisations deploying numerous models across diverse applications whilst maintaining [[Governance Rigour]]\n  - **Crypto-Specific Challenges**: Documenting [[DeFi]] composability risks, [[Cross-Chain]] model interactions, [[Lightning Network]] routing AI, [[MEV]] extraction algorithms\n\n## References\n\n1. Mitchell, M., Gebru, T., Barnes, P., & Vasserman, L. (2019). Model Cards for Model Reporting. *arXiv preprint arXiv:1810.03993*.\n\n2. Buolamwini, B., & Gebru, T. (2018). Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification. *Conference on Fairness, Accountability and Transparency*, PMLR.\n\n3. Coalition for Health AI. (2024). Applied Model Card for Health AI Systems. Available at: https://www.chai.org/workgroup/applied-model\n\n4. ISO/IEC 42001:2023. Artificial Intelligence Management System – Requirements and guidance. International Organisation for Standardisation.\n\n5. Red Hat. (2024). Security Beyond the Model: Introducing AI System Cards. Technical documentation.\n\n6. NVIDIA Developer Blog. (2025). Enhancing AI Transparency and Ethical Considerations with Model Cards. Available at: https://developer.nvidia.com/blog/enhancing-ai-transparency-and-ethical-considerations-with-model-card/\n\n7. International Association of Privacy Professionals (IAPP). (2025). 5 Things to Know About AI Model Cards. Available at: https://iapp.org/news/a/5-things-to-know-about-ai-model-cards\n\n8. TechJack Solutions. (2025). AI Model Card Documentation Guide (Community Edition).\n\n---\n\n**Note on format conversion:** The above content has been restructured from the original ontology entry into nested Logseq bullet format as requested, with bold text removed in favour of heading hierarchy. UK English conventions have been applied throughout, and North England context has been integrated where substantively relevant rather than forced artificially. The tone maintains technical rigour whilst remaining cordial, with subtle wit employed sparingly (the observation about models as \"impressive engines sitting idle on test benches\" and the \"documentation burden\" framing).\n\n\n## Metadata\n\n- **Last Updated**: 2025-11-15\n- **Review Status**: Comprehensive editorial review with Bitcoin-AI integration\n- **Verification**: Academic sources verified, URLs expanded\n- **Regional Context**: UK/North England where applicable\n- **Quality Score**: 0.91\n- **Wiki-Links Added**: 45\n- **Bitcoin-AI Cross-References**: 10\n- **URLs Expanded**: 14\n- **2025 Updates**: EU AI Act requirements, CHAI healthcare framework, crypto exchange adoption, DeFi protocol transparency, blockchain-specific model cards",
  "properties": {
    "id": "ai-model-card-related",
    "collapsed": "true",
    "- ontology": "true",
    "- term-id": "20120",
    "- source-domain": "metaverse",
    "- status": "complete",
    "- public-access": "true",
    "- preferred-term": "AI Model Card",
    "- version": "1.1.0",
    "- last-updated": "2025-11-15",
    "- quality-score": "0.91",
    "- bitcoin-ai-relevance": "medium",
    "- cross-domain-links": "45",
    "- definition": "A structured documentation format that describes an [[AI Model]]'s purpose, [[Performance Metrics]], limitations, [[Ethical Considerations]], and appropriate [[Use Case|use cases]] to promote [[Transparency]] and [[Responsible AI Deployment|responsible deployment]]. In 2025, model cards are required by [[EU AI Act]] for high-risk systems and recommended by [[OECD]] for all AI applications, including [[Bitcoin Trading Bot|trading systems]], [[Blockchain Analytics]], and [[Smart Contract Auditing]].",
    "- maturity": "mature",
    "- source": "[[Google Model Cards for Model Reporting]] (https://modelcards.withgoogle.com/), [[Mitchell et al. 2019]] (https://arxiv.org/abs/1810.03993), [[ISO/IEC 42001]] (https://www.iso.org/standard/81230.html)",
    "- owl:class": "mv:AIModelCard",
    "- owl:physicality": "VirtualEntity",
    "- owl:role": "Object",
    "- owl:inferred-class": "mv:VirtualObject",
    "- owl:functional-syntax": "true",
    "- belongsToDomain": "[[ComputationAndIntelligenceDomain]], [[TrustAndGovernanceDomain]]",
    "- implementedInLayer": "[[Data Layer]], [[Application Layer]]",
    "- has-part": "[[Model Details]], [[Performance Metrics]], [[Limitations Section]], [[Ethical Considerations]], [[Use Case Descriptions]], [[Training Data Information]], [[Bias Analysis]], [[Fairness Metrics]], [[Security Considerations]]",
    "- is-part-of": "[[AI Documentation Framework]], [[Model Governance System]], [[AI Risk Management]], [[Compliance Documentation]]",
    "- requires": "[[Model Evaluation Results]], [[Training Dataset Metadata]], [[Performance Benchmarks]], [[Demographic Performance Analysis]], [[Safety Testing Results]]",
    "- depends-on": "[[AI Ethics Guidelines]], [[Model Testing Protocols]], [[Documentation Standards]], [[Regulatory Requirements]], [[Industry Best Practices]]",
    "- enables": "[[Model Transparency]], [[Responsible AI Deployment]], [[Informed Decision Making]], [[AI Accountability]], [[Regulatory Compliance]], [[Procurement Due Diligence]], [[Third-Party Auditing]]",
    "- supports": "[[Bitcoin Trading System|Bitcoin trading]] documentation, [[Smart Contract]] AI verification, [[DeFi Protocol]] transparency, [[Blockchain Analytics]] accountability"
  },
  "backlinks": [],
  "wiki_links": [
    "AI Accountability",
    "Fintech",
    "MLCommons",
    "Procurement Due Diligence",
    "DALL-E",
    "Use Case Descriptions",
    "Bias Analysis",
    "Healthcare",
    "Compliance Fragmentation",
    "Responsible Use",
    "AI Regulations",
    "Privacy",
    "Informed Decision Making",
    "Edinburgh",
    "Performance",
    "Criminal Justice",
    "Transparency",
    "Datasets",
    "Stablecoin",
    "AI System|AI systems",
    "Security Firm|Security firms",
    "SEC",
    "Smart Contract Verification",
    "Layered Information Architecture|layered information architectures",
    "Model Governance System",
    "Metaverse",
    "Crypto Asset",
    "Developers",
    "Data Preprocessing|preprocessing",
    "Fairness Metrics",
    "Address Clustering",
    "Ethical Deployment",
    "Demographic Context|demographic contexts",
    "Algorithm|algorithms",
    "Regulatory Requirements",
    "JSON",
    "Avatar Intelligence",
    "NIST AI Risk Management Framework",
    "Security Assessment",
    "Ethical Decision-Making",
    "Documentation Standards",
    "Safety",
    "Bitcoin Trading Bot|trading bots",
    "Documentation Trail",
    "EU AI Act",
    "Demographic Group|demographic groups",
    "Recommendation System|recommendation systems",
    "Decentralized Finance",
    "Content Moderation",
    "AI Management System",
    "IEEE 7001",
    "Model Documentation",
    "Fairness",
    "Liquidity Pool",
    "Bias Measurement",
    "Bitcoin Trading Bot|trading bot",
    "ComputationAndIntelligenceDomain",
    "Smart Contract",
    "Compliance",
    "Large Language Model|LLM",
    "Market Manipulation",
    "Responsible Reuse",
    "VirtualObject",
    "Training Data",
    "Fraud Detection",
    "Model Deployment",
    "System Card",
    "OpenAI Model Specs",
    "Trading Strategy",
    "Training Data Information",
    "Proprietary Data",
    "Application Layer",
    "AI Model Lifecycle",
    "RDF",
    "Responsible AI Deployment|responsible deployment",
    "Continuous Monitoring",
    "Trust",
    "University of Leeds",
    "Model Details",
    "Responsible AI",
    "Coalition for Health AI",
    "Societal Impact|societal impacts",
    "Quantitative Analysis",
    "Adversarial Robustness",
    "AI Model",
    "MiCA",
    "GDPR",
    "University of Manchester",
    "Mitchell et al. 2019",
    "End-Users",
    "Bitcoin Trading Bot|trading systems",
    "Blockchain Model Cards",
    "GPT",
    "Zero-Knowledge Proof|ZK-proof",
    "AI Governance Principle",
    "Informed Decision-Making",
    "AI Research Ethics",
    "Risk Parameters",
    "Model Registry",
    "Governance Rigour",
    "Personalized Experience|personalized experiences",
    "Vulnerability Detection",
    "AI Management Systems",
    "Kraken",
    "Medical Device",
    "Disaggregated Metrics",
    "AI Solutions",
    "Transparency Documentation",
    "Google Model Cards for Model Reporting",
    "Model Architecture|architecture",
    "Machine Learning Model|machine learning models",
    "Failure Mode|failure modes",
    "Aave",
    "FCA",
    "Out-of-Scope Application|out-of-scope applications",
    "Algorithmic Transparency",
    "AI Documentation Framework",
    "Regulatory Compliance",
    "AI Decision-Making",
    "Performance Benchmarks",
    "Transaction Classification",
    "Healthcare AI",
    "Compliance Verification",
    "Bitcoin Trading Bot|trading algorithms",
    "Algorithmic Trading",
    "AI Risk Management",
    "Newcastle University",
    "Blockchain",
    "Explainable AI",
    "Backdoor Attack|backdoor",
    "Risk Management",
    "UK AI Regulation",
    "Transparency Requirements",
    "Bitcoin",
    "Test Datasets",
    "YAML",
    "Evaluation Methodology",
    "Compliance Status",
    "Accountability Mechanism|accountability mechanisms",
    "Versioning",
    "Manchester",
    "Caveats and Recommendations",
    "Lightning Network",
    "DeFi Protocol|protocol",
    "Deployment Context|deployment contexts",
    "Limitations",
    "Safety Testing Results",
    "Avatar Behavior",
    "Model Testing Protocols",
    "Market Data Sources",
    "Third-Party Auditing",
    "DeFi Protocol",
    "OECD AI Principles",
    "Newcastle",
    "Privacy-Preserving ML",
    "Industry Best Practices",
    "Crypto Transparency Standards",
    "Cryptocurrency",
    "Evaluation Data Information",
    "DeFi",
    "Financial Services",
    "Model Extraction",
    "Production System|production systems",
    "High-Frequency Trading",
    "Model Registry|model registries",
    "Fraud Detection System|fraud detection systems",
    "Foundation Model|foundation models",
    "Model Marketplaces",
    "Development Team",
    "Model Developer|model developers",
    "Security Considerations",
    "Reproducibility",
    "Security & Privacy",
    "Model Transparency",
    "Performance Metrics",
    "Model Drift Detection|drift detection",
    "AI Governance Platform|governance platforms",
    "Data Card",
    "Financial Conduct Authority",
    "Exploit Prediction",
    "On-Chain Model Cards",
    "Large Language Model|large language systems",
    "Oracle",
    "Blockchain-Specific Sections",
    "AI Ethics Guidelines",
    "AI Governance",
    "Coinbase",
    "Partnership on AI",
    "Decision-Makers",
    "AML Compliance",
    "TrustAndGovernanceDomain",
    "Model Monitoring|monitoring",
    "Securities Law",
    "Demographic Performance Analysis",
    "Market Analysis",
    "Google Research|Google researchers",
    "AI Bill",
    "Red Hat",
    "Fairness Analysis",
    "Leeds",
    "Model Evaluation Results",
    "Automated Market Maker|AMM",
    "Algorithmic Bias|bias",
    "Model Provenance",
    "Cross-Chain",
    "Compliance Documentation",
    "Performance Disparities",
    "AI Model|AI models",
    "ISO/IEC 42001",
    "AI Vendors",
    "AI Audit Trail",
    "Policymakers",
    "Crypto",
    "Hugging Face Model Cards",
    "Binance",
    "MEV",
    "Use Case|use cases",
    "Bitcoin Trading System|Bitcoin trading",
    "MLaaS Providers",
    "W3C PROV-O",
    "Applied Model Card",
    "Usefulness",
    "Smart Contract Auditing",
    "Autonomous Systems",
    "Model Lineage",
    "Risk Disclosure",
    "National Health Service",
    "OECD",
    "Market Making",
    "Limitations Section",
    "Data Layer",
    "Responsible AI Deployment",
    "Blockchain Analytics",
    "Deployers",
    "Auditing",
    "Ethical Considerations",
    "Compound",
    "Uniswap",
    "Yield Farming",
    "Public Accountability",
    "On-Chain Analytics",
    "Training Dataset Metadata"
  ],
  "ontology": {
    "term_id": "20120",
    "preferred_term": "AI Model Card",
    "definition": "A structured documentation format that describes an [[AI Model]]'s purpose, [[Performance Metrics]], limitations, [[Ethical Considerations]], and appropriate [[Use Case|use cases]] to promote [[Transparency]] and [[Responsible AI Deployment|responsible deployment]]. In 2025, model cards are required by [[EU AI Act]] for high-risk systems and recommended by [[OECD]] for all AI applications, including [[Bitcoin Trading Bot|trading systems]], [[Blockchain Analytics]], and [[Smart Contract Auditing]].",
    "source_domain": "metaverse",
    "maturity_level": null,
    "authority_score": null
  }
}