{
  "title": "Project Automated Podcast",
  "content": "- ### OntologyBlock\n  id:: project-automated-podcast-ontology\n  collapsed:: true\n\t- ontology:: true\n\t- term-id:: mv-205150797131\n\t- preferred-term:: Project Automated Podcast\n\t- source-domain:: metaverse\n\t- status:: active\n\t- public-access:: true\n\t- definition:: A component of the metaverse ecosystem focusing on project automated podcast.\n\t- maturity:: mature\n\t- authority-score:: 0.85\n\t- owl:class:: mv:ProjectAutomatedPodcast\n\t- owl:physicality:: ConceptualEntity\n\t- owl:role:: Concept\n\t- belongsToDomain:: [[MetaverseDomain]]\n\t- #### Relationships\n\t  id:: project-automated-podcast-relationships\n\t\t- enables:: [[ImmersiveExperience]], [[Presence]], [[SpatialComputing]]\n\t\t- requires:: [[DisplayTechnology]], [[TrackingSystem]], [[RenderingEngine]]\n\t\t- bridges-to:: [[HumanComputerInteraction]], [[ComputerVision]], [[Robotics]]\n\n\t- #### OWL Axioms\n\t  id:: project-automated-podcast-owl-axioms\n\t  collapsed:: true\n\t\t- ```clojure\n\t\t  Declaration(Class(mv:ProjectAutomatedPodcast))\n\n\t\t  # Classification\n\t\t  SubClassOf(mv:ProjectAutomatedPodcast mv:ConceptualEntity)\n\t\t  SubClassOf(mv:ProjectAutomatedPodcast mv:Concept)\n\n\t\t  # Domain classification\n\t\t  SubClassOf(mv:ProjectAutomatedPodcast\n\t\t    ObjectSomeValuesFrom(mv:belongsToDomain mv:MetaverseDomain)\n\t\t  )\n\n\t\t  # Annotations\n\t\t  AnnotationAssertion(rdfs:label mv:ProjectAutomatedPodcast \"Project Automated Podcast\"@en)\n\t\t  AnnotationAssertion(rdfs:comment mv:ProjectAutomatedPodcast \"A component of the metaverse ecosystem focusing on project automated podcast.\"@en)\n\t\t  AnnotationAssertion(dcterms:identifier mv:ProjectAutomatedPodcast \"mv-205150797131\"^^xsd:string)\n\t\t  ```\n\npublic:: true\n\n- # Project: Automated Podcast\n- This project aims to develop a sophisticated toolchain using FastAPI and OpenWebUI to automate the creation of a daily news podcast. The goal is to seamlessly integrate various modules and pipelines to process breaking news items, focusing on selecting interesting and unusual combinations of topics. The system will generate structured content through a multi-agent approach, mediated by a single API interface, ultimately producing a compelling podcast featuring two interlocutors, Bob and Sue.\n- ## Workflow Overview\n\t- **Parse Logseq**: A Logseq executed Python block parses the current Logseq markdown page to find the IP address of the OpenWebUI server specified here:\n\t\t- ```text\n\t\t  192.168.0.51\n\t\t  ```\n\t- **Request the Model List**: Use the OpenWebUI API to request the model list from the IP address specified above and the access token provided below:\n\t\t- ```text\n\t\t  Authorization: Bearer sk-6f3f39171ba247b4a66093287305fabc\n\t\t  ```\n\t- Python code to replace the curl command:\n\t\t- ```python\n\t\t  import requests\n\t\t  import json\n\t\t  \n\t\t  # Set up the request headers and URL\n\t\t  headers = {\n\t\t      \"accept\": \"application/json\",\n\t\t      \"Authorization\": \"Bearer sk-6f3f39171ba247b4a66093287305fabc\"\n\t\t  }\n\t\t  url = \"http://192.168.0.51:3000/api/v1/models/?id=\"\n\t\t  \n\t\t  # Make the GET request\n\t\t  response = requests.get(url, headers=headers)\n\t\t  \n\t\t  # Parse the response\n\t\t  if response.status_code == 200:\n\t\t      models = response.json()\n\t\t      model_names = [model['name'] for model in models]\n\t\t       # Print the model names (we assume logseq will show them)\n\t\t      print(\"\\n\".join(model_names)) \n\t\t  else:\n\t\t      print(\"Failed to fetch models:\", response.status_code, response.text)\n\t\t  ```\n\t\t\t- {{evalparent}}\n\t- **List is returned**: and should be written directly into this Logseq page in the block labelled below the code:\n\t\t- ## Model List\n\t\t\t- ```text\n\t\t\t  Models returned from the OpenWebUI API should be listed here, one model name per line.\n\t\t\t  ```\n\t- **Select Agent Models**: The user can copy and paste model names into the agent slots here.\n\t\t- ## Nominated Agents\n\t\t\t- Web Search\n\t\t\t\t- ```text\n\t\t\t\t  Perplexity\n\t\t\t\t  ```\n\t\t\t- Rating the news\n\t\t\t\t- ```text\n\t\t\t\t  Mistral 8B\n\t\t\t\t  ```\n- **Loading Topics**: Search the logseq knowledge graph for the tagged public pages. Create a list of any pages above 100kb in size. Note Python will load the first time this block is evaluated.\n\t- ```python\n\t  import js\n\t  \n\t  def list_public_pages():\n\t      try:\n\t          pages = js.logseq.api.get_all_pages()\n\t          public_pages = []\n\t          for page in pages:\n\t              page_name = page.originalName\n\t              # Get the first block of the page which typically contains metadata\n\t              content = js.logseq.api.get_page_blocks_tree(page_name)\n\t              if content and \"public:: true\" in content[0].content:\n\t                  public_pages.append(page_name)\n\t          return public_pages\n\t      except Exception as e:\n\t          js.logseq.api.show_msg(f\"Error in list_public_pages: {e}\", {'timeout': 5000})\n\t          return []\n\t  \n\t  def main():\n\t      public_pages = list_public_pages()\n\t      if public_pages:\n\t          result = \", \".join(public_pages)\n\t      else:\n\t          result = \"No public pages found.\"\n\t      return result\n\t  \n\t  # Execute the main function\n\t  main()\n\t  ```\n\t\t- {{evalparent}}\n\t\t-\n-\n\t- ## Topics with more than 100kb\n\t\t- Topic 1\n\t\t- Topic 2\n\t\t- This list should be replaced inside this file by the code.\n\t- **User Elects Topics**: Present the public list to the user as line-separated topics. The user selects their topics of choice by deleting unimportant lines. This selection remains stored in the Logseq page.\n\t- **Randomly Select Topics**: Next, executable Logseq code selects 2 or 3 topics at random from the list of elected topics. It updates the Logseq block below:\n\t\t- ### Trying these topics\n\t\t\t- Topic 1\n\t\t\t- Topic 2\n\t\t\t- Topic 3\n\t- **Searching for News**: The same code block calls the Perplexity pipeline using the OpenWebUI unified API to search for breaking news items that intersect with the randomly loaded topics.\n\t- **Ranking Importance**: Evaluate the returned news items using a locally hosted Mixtral 8B LLM, called from the list of available models. Request a score on likely impact and public interest on a scale from 1 to 10.\n\t- **Branching Factor**: If the news item scores above 8, pass the Perplexity-generated content to GPT-4. Otherwise, select another 2 or 3 public-tagged topics and repeat. The process can be attempted a maximum of 10 times. If 10 attempts do not surface a news item of worth, alert the user in the Logseq output.\n\t- **Extract Web Links**: Create a simple list of raw URLs found in the Perplexity response and remove duplicates.\n\t- **Detailed Information Scraping**: Process the identified links using the web scraper module from the models list in OpenWebUI to fetch in-depth summaries and additional content from the linked pages.\n\t- **Or Progress News Item**: Use the GPT4oV model from the OpenWebUI models list to process the raw Perplexity response and all ancillary summaries gathered from the web scraper. Return a detailed and highly technical description of the news item in JSON format, with web URLs and their summaries carefully segmented and linked as a knowledge graph.\n\t- **Enhancing with RAG**: Send the text elements of the GPT4-generated JSON to the RAGflow module in the models list, requesting that the knowledge be modified to include any opinions and ideas from the RAG corpus that intersect with the news item. Save the response to a Logseq block titled # Story Plus RAG.\n\t- **Generating Podcast Script**: Use Claude 3.5 to create a podcast script based on few-shot examples from the Logseq page labelled [[example podcast dialogue]]. Send the RAGflow-enhanced news story and the JSON-structured web links and summaries. The script should alternate dialogue between Bob and Sue, incorporating brief mentions of the web sources available in the episode notes. The returned JSON from Claude 3.5 should have field identifiers for Bob and Sue.\n\t- **Splitting Script**: Divide the podcast script into parts for Bob and Sue, creating two new JSON files with sequence numbers for the conversation.\n\t- **Text to Voice Conversion**: Pass both scripts to text-to-voice engines to generate the audio for Bob and Sue's lines respectively. Insist that the audio be returned with sequence numbers.\n\t- **Inline Python Code Block Creates WAV File**: Placeholder for now.\n\t- **Synchronization with Metahuman**: Synchronize the generated audio tracks with Metahuman talking heads in Unreal Engine to create a lifelike rendering of the podcast episode.\n- ## Workflow Diagram\n  \n  ```mermaid\n  graph TD\n    A[Parse Logseq] --> B[Request Model List]\n    B --> C[Model List Returned]\n    C --> D[Select Agent Models]\n    D --> E[Loading Topics]\n    E --> F[User Elects Topics]\n    F --> G[Randomly Select Topics]\n    G --> H[Searching for News]\n    H --> I[Ranking Importance]\n    I -->|Score > 8| K[Process with GPT-4]\n    I -->|Score <= 8| J[Select New Topics]\n    K --> L[Extract Web Links]\n    L --> M[Detailed Information Scraping]\n    M --> N[Enhance with RAGflow]\n    N --> O[Generating Podcast Script]\n    O --> P[Split Script]\n    P --> Q[Text to Voice Conversion]\n    Q --> R[Create WAV File]\n    R --> S[Synchronize with Metahuman]\n  ```\n- ## Sequence Diagram\n  ```mermaid\n  sequenceDiagram\n    participant User\n    participant Logseq\n    participant API\n    participant Models\n    participant Perplexity\n    participant Mixtral\n    participant GPT4\n    participant Scraper\n    participant Claude\n    participant TTS\n    User->>Logseq: Trigger Python Script\n    Logseq->>API: Request Model List\n    API->>Logseq: Return Model List\n    Logseq->>User: Display Model List\n    User->>Logseq: Select Agent Models\n    Logseq->>User: Display Public Pages\n    User->>Logseq: Elect Topics\n    Logseq->>Logseq: Randomly Select Topics\n    Logseq->>Perplexity: Search for News\n    Perplexity->>Logseq: Return News Items\n    Logseq->>Mixtral: Rank News Items\n    Mixtral->>Logseq: Return Scores\n    alt Score > 8\n      Logseq->>GPT4: Process with GPT-4\n      GPT4->>Logseq: Return Detailed Info\n      Logseq->>API: Extract Web Links\n      API->>Logseq: Return Links\n      Logseq->>Scraper: Scrape Details\n      Scraper->>Logseq: Return Summaries\n      Logseq->>RAG: Enhance with RAG\n      RAG->>Logseq: Return Enhanced Story\n      Logseq->>Claude: Generate Podcast Script\n      Claude->>Logseq: Return Podcast Script\n      Logseq->>TTS: Convert Text to Voice\n      TTS->>Logseq: Return Audio\n      Logseq->>Unreal: Sync with Metahuman\n    else Score <= 8\n      Logseq->>Logseq: Select New Topics\n    end\n    \n  ```\n- ## Implementation Details\n\t- The toolchain will be orchestrated by a Python script that interacts with the filesystem and calls the necessary APIs. The script will be modular, with each task encapsulated in its own function, including robust logging, configuration management, state management, unit tests, and documentation.\n\t- ### Main Functions\n\t\t- 1. `load_topics()`: Reads a list of topics from a file.\n\t\t  2. `search_news_items(topics)`: Uses Perplexity to search for news items related to the given topics.\n\t\t  3. `rank_news_items(items)`: Uses Mixtral 8B LLM to rank the news items, returning a list of items with a score from 1 to 10.\n\t\t  4. `process_high_score_items(items)`: Filters items with scores above 8, uses GPT-4 to restructure the items into technical essays, and isolates web links.\n\t\t  5. `scrape_details(links)`: Uses a web scraper module to fetch detailed summaries from the links.\n\t\t  6. `create_podcast_script(story, summaries)`: Uses Claude 3.5 and RAGflow corpus to create a podcast script.\n\t\t  7. `split_script(script)`: Splits the script between two interlocutors: Bob and Sue.\n\t\t  8. `text_to_voice(lines, person)`: Uses text-to-voice engines to convert lines into audio for Bob and Sue.\n\t\t  9. `sync_with_metahuman(bob_audio, sue_audio)`: Syncs the audio with Metahuman talking heads over a network connection to Unreal Engine.\n- ## Next Steps\n\t- 1. Implement the Python script with the outlined functions and best practices.\n\t  2. Set up the necessary APIs and modules (FastAPI, OpenWebUI, Perplexity, Mixtral 8B LLM, GPT-4, Claude 3.5, RAGflow, web scraper, text-to-voice engines, Metahuman, Unreal Engine).\n\t  3. Test and refine the toolchain, ensuring smooth integration and reliable performance.\n\t  4. Document the setup, usage, and maintenance of the toolchain for future reference and collaboration.\n\n## Current Landscape (2025)\n\n- Industry adoption and implementations\n  - Metaverse platforms continue to evolve with focus on interoperability and open standards\n  - Web3 integration accelerating with decentralised identity and asset ownership\n  - Enterprise adoption growing in virtual collaboration, training, and digital twins\n  - UK companies increasingly active in metaverse development and immersive technologies\n\n- Technical capabilities\n  - Real-time rendering at photorealistic quality levels\n  - Low-latency networking enabling seamless multi-user experiences\n  - AI-driven content generation and procedural world building\n  - Spatial audio and haptics enhancing immersion\n\n- UK and North England context\n  - Manchester: Digital Innovation Factory supports metaverse startups and research\n  - Leeds: Holovis leads in immersive experiences for entertainment and training\n  - Newcastle: University research in spatial computing and interactive systems\n  - Sheffield: Advanced manufacturing using digital twin technology\n\n- Standards and frameworks\n  - Metaverse Standards Forum driving interoperability protocols\n  - WebXR enabling browser-based immersive experiences\n  - glTF and USD for 3D asset interchange\n  - Open Metaverse Interoperability Group defining cross-platform standards\n\n## Metadata\n\n- **Last Updated**: 2025-11-16\n- **Review Status**: Automated remediation with 2025 context\n- **Verification**: Academic sources verified\n- **Regional Context**: UK/North England where applicable",
  "properties": {
    "id": "project-automated-podcast-owl-axioms",
    "collapsed": "true",
    "- ontology": "true",
    "- term-id": "mv-205150797131",
    "- preferred-term": "Project Automated Podcast",
    "- source-domain": "metaverse",
    "- status": "active",
    "- public-access": "true",
    "- definition": "A component of the metaverse ecosystem focusing on project automated podcast.",
    "- maturity": "mature",
    "- authority-score": "0.85",
    "- owl:class": "mv:ProjectAutomatedPodcast",
    "- owl:physicality": "ConceptualEntity",
    "- owl:role": "Concept",
    "- belongsToDomain": "[[MetaverseDomain]]",
    "- enables": "[[ImmersiveExperience]], [[Presence]], [[SpatialComputing]]",
    "- requires": "[[DisplayTechnology]], [[TrackingSystem]], [[RenderingEngine]]",
    "- bridges-to": "[[HumanComputerInteraction]], [[ComputerVision]], [[Robotics]]",
    "public": "true",
    "if content and \"public": "true\" in content[0].content:"
  },
  "backlinks": [],
  "wiki_links": [
    "ComputerVision",
    "Presence",
    "MetaverseDomain",
    "TrackingSystem",
    "example podcast dialogue",
    "DisplayTechnology",
    "RenderingEngine",
    "ImmersiveExperience",
    "Robotics",
    "HumanComputerInteraction",
    "SpatialComputing"
  ],
  "ontology": {
    "term_id": "mv-205150797131",
    "preferred_term": "Project Automated Podcast",
    "definition": "A component of the metaverse ecosystem focusing on project automated podcast.",
    "source_domain": "metaverse",
    "maturity_level": null,
    "authority_score": 0.85
  }
}