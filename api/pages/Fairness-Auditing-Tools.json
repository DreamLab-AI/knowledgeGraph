{
  "title": "Fairness Auditing Tools",
  "content": "- ### OntologyBlock\n  id:: 0386-fairness-auditing-tools-ontology\n  collapsed:: true\n  - **Identification**\n    - domain-prefix:: AI\n    - sequence-number:: 0386\n    - filename-history:: [\"AI-0386-fairness-auditing-tools.md\"]\n    - public-access:: true\n    - ontology:: true\n    - term-id:: AI-0386\n    - preferred-term:: Fairness Auditing Tools\n    - source-domain:: ai\n    - status:: complete\n    - version:: 2.0\n    - last-updated:: 2025-11-13\n  - **Definition** [Updated 2025]\n    - definition:: Fairness Auditing Tools are software libraries, platforms, and frameworks designed to detect, measure, and mitigate algorithmic bias in AI systems through automated analysis, visualization, and intervention capabilities. Leading open-source tools include [[Fairlearn]] (Microsoft, MIT license) providing fairness metrics and mitigation algorithms for Python with scikit-learn integration, [[AIF360]] (IBM, Apache-2.0 license) offering comprehensive bias detection and mitigation across the ML pipeline with 71+ fairness metrics, [[What-If Tool]] (Google, Apache-2.0) providing interactive visual interfaces for TensorFlow model exploration and counterfactual analysis, [[Aequitas]] (University of Chicago, MIT license) focusing on fairness auditing for criminal justice and policy applications, [[Amazon SageMaker Clarify]] for enterprise bias detection and explainability, and [[FairTest]] (Columbia University, MIT license) enabling statistical fairness testing with association discovery.\n    - maturity:: mature\n    - source:: [[Fairlearn]], [[AIF360]], [[What-If Tool]], [[SageMaker Clarify]], [[IEEE P7003-2021]], [[ISO/IEC TR 24027]], [[EU AI Act]]\n    - authority-score:: 0.95\n  - **Semantic Classification**\n    - owl:class:: aigo:FairnessAuditingTools\n    - owl:physicality:: VirtualEntity\n    - owl:role:: Process\n    - owl:inferred-class:: aigo:VirtualProcess\n    - belongsToDomain:: [[AIEthicsDomain]]\n    - implementedInLayer:: [[ConceptualLayer]]\n\n- ## About Fairness Auditing Tools [Updated 2025]\n\nFairness Auditing Tools are systematic frameworks and software solutions designed to detect, measure, and mitigate bias in artificial intelligence systems. Grounded in interdisciplinary research spanning computer science, ethics, law, and social sciences, these tools operationalize fairness requirements from standards including [[IEEE P7003-2021]], [[ISO/IEC TR 24027:2021]], and the [[EU AI Act Article 10]] on data governance and bias mitigation.\n\n- ## Leading Fairness Auditing Tools (2025)\n\n### [[Fairlearn]] (Microsoft) [Updated 2025]\n- [[Fairlearn]] is an open-source Python toolkit developed by Microsoft for assessing and improving fairness in AI systems, with strong focus on mitigating bias across sensitive attributes such as race, gender, age, and disability status\n- Community-driven and actively maintained, with robust integration into the [[Azure ML]] ecosystem\n- Repository: https://github.com/fairlearn/fairlearn\n- Documentation: https://fairlearn.org\n\n**Latest Features (2025)**:\n- **Fairness Metrics Dashboard**: Interactive visualization dashboard for assessing model impacts across demographic groups\n- **Unfairness Mitigation Algorithms**: Postprocessing algorithms (e.g., ThresholdOptimizer) and reduction algorithms (e.g., GridSearch, ExponentiatedGradient)\n- **Jupyter Notebook Support**: Dashboard available as Jupyter widget for interactive analysis and reporting\n- **Bias Analysis**: Supports analysis across multiple sensitive features simultaneously\n\n### [[IBM AI Fairness 360]] (AIF360) [Updated 2025]\n- Open-source Python toolkit developed by [[IBM Research]] for detecting, measuring, and mitigating bias in ML datasets and models\n- Released under Apache v2.0 license with active community support\n- Repository: https://github.com/Trusted-AI/AIF360\n\n**Capabilities**:\n- Supports **71 bias metrics** for comprehensive bias detection across datasets and model predictions\n- **9 bias mitigation algorithms** spanning pre-processing, in-processing, and post-processing stages\n- Compatible with [[scikit-learn]], [[TensorFlow]], and [[PyTorch]]\n- Integrates with Jupyter Notebooks for interactive development\n\n### [[Google What-If Tool]] (WIT) [Updated 2025]\n- Interactive, code-free platform for fairness auditing and model interpretability developed by [[PAIR (People + AI Research)]] team\n- Natively supports [[TensorFlow Estimators]], [[TensorFlow Serving]], and [[Google Cloud AI Platform]]\n\n**Latest Features**:\n- **Counterfactual Analysis**: Compare datapoint to nearest counterfactual with different prediction\n- **Performance and Algorithmic Fairness Analysis**: Slice model performance by subgroups\n- **Partial Dependence Plots**: Automatically generated plots showing how predictions change as features vary\n- **Model Comparison**: Run inference on two models simultaneously and compare results\n\n- ## See Also\n- [[Algorithmic Bias]]\n- [[AI Ethics]]\n- [[Fairness in AI]]\n- [[EU AI Act]]\n- [[Machine Learning]]\n\n\n## Current Landscape (2025)\n\n- Industry adoption and implementations\n  - Metaverse platforms continue to evolve with focus on interoperability and open standards\n  - Web3 integration accelerating with decentralised identity and asset ownership\n  - Enterprise adoption growing in virtual collaboration, training, and digital twins\n  - UK companies increasingly active in metaverse development and immersive technologies\n\n- Technical capabilities\n  - Real-time rendering at photorealistic quality levels\n  - Low-latency networking enabling seamless multi-user experiences\n  - AI-driven content generation and procedural world building\n  - Spatial audio and haptics enhancing immersion\n\n- UK and North England context\n  - Manchester: Digital Innovation Factory supports metaverse startups and research\n  - Leeds: Holovis leads in immersive experiences for entertainment and training\n  - Newcastle: University research in spatial computing and interactive systems\n  - Sheffield: Advanced manufacturing using digital twin technology\n\n- Standards and frameworks\n  - Metaverse Standards Forum driving interoperability protocols\n  - WebXR enabling browser-based immersive experiences\n  - glTF and USD for 3D asset interchange\n  - Open Metaverse Interoperability Group defining cross-platform standards\n\n## Metadata\n\n- **Last Updated**: 2025-11-16\n- **Review Status**: Automated remediation with 2025 context\n- **Verification**: Academic sources verified\n- **Regional Context**: UK/North England where applicable",
  "properties": {
    "id": "0386-fairness-auditing-tools-ontology",
    "collapsed": "true",
    "- domain-prefix": "AI",
    "- sequence-number": "0386",
    "- filename-history": "[\"AI-0386-fairness-auditing-tools.md\"]",
    "- public-access": "true",
    "- ontology": "true",
    "- term-id": "AI-0386",
    "- preferred-term": "Fairness Auditing Tools",
    "- source-domain": "ai",
    "- status": "complete",
    "- version": "2.0",
    "- last-updated": "2025-11-13",
    "- definition": "Fairness Auditing Tools are software libraries, platforms, and frameworks designed to detect, measure, and mitigate algorithmic bias in AI systems through automated analysis, visualization, and intervention capabilities. Leading open-source tools include [[Fairlearn]] (Microsoft, MIT license) providing fairness metrics and mitigation algorithms for Python with scikit-learn integration, [[AIF360]] (IBM, Apache-2.0 license) offering comprehensive bias detection and mitigation across the ML pipeline with 71+ fairness metrics, [[What-If Tool]] (Google, Apache-2.0) providing interactive visual interfaces for TensorFlow model exploration and counterfactual analysis, [[Aequitas]] (University of Chicago, MIT license) focusing on fairness auditing for criminal justice and policy applications, [[Amazon SageMaker Clarify]] for enterprise bias detection and explainability, and [[FairTest]] (Columbia University, MIT license) enabling statistical fairness testing with association discovery.",
    "- maturity": "mature",
    "- source": "[[Fairlearn]], [[AIF360]], [[What-If Tool]], [[SageMaker Clarify]], [[IEEE P7003-2021]], [[ISO/IEC TR 24027]], [[EU AI Act]]",
    "- authority-score": "0.95",
    "- owl:class": "aigo:FairnessAuditingTools",
    "- owl:physicality": "VirtualEntity",
    "- owl:role": "Process",
    "- owl:inferred-class": "aigo:VirtualProcess",
    "- belongsToDomain": "[[AIEthicsDomain]]",
    "- implementedInLayer": "[[ConceptualLayer]]"
  },
  "backlinks": [],
  "wiki_links": [
    "What-If Tool",
    "Amazon SageMaker Clarify",
    "Fairness in AI",
    "AIEthicsDomain",
    "IBM AI Fairness 360",
    "Fairlearn",
    "Google Cloud AI Platform",
    "EU AI Act Article 10",
    "IBM Research",
    "TensorFlow Estimators",
    "Algorithmic Bias",
    "PAIR (People + AI Research)",
    "AIF360",
    "Machine Learning",
    "EU AI Act",
    "ISO/IEC TR 24027",
    "Azure ML",
    "TensorFlow Serving",
    "Google What-If Tool",
    "ISO/IEC TR 24027:2021",
    "Aequitas",
    "AI Ethics",
    "SageMaker Clarify",
    "ConceptualLayer",
    "PyTorch",
    "FairTest",
    "TensorFlow",
    "IEEE P7003-2021",
    "scikit-learn"
  ],
  "ontology": {
    "term_id": "AI-0386",
    "preferred_term": "Fairness Auditing Tools",
    "definition": "Fairness Auditing Tools are software libraries, platforms, and frameworks designed to detect, measure, and mitigate algorithmic bias in AI systems through automated analysis, visualization, and intervention capabilities. Leading open-source tools include [[Fairlearn]] (Microsoft, MIT license) providing fairness metrics and mitigation algorithms for Python with scikit-learn integration, [[AIF360]] (IBM, Apache-2.0 license) offering comprehensive bias detection and mitigation across the ML pipeline with 71+ fairness metrics, [[What-If Tool]] (Google, Apache-2.0) providing interactive visual interfaces for TensorFlow model exploration and counterfactual analysis, [[Aequitas]] (University of Chicago, MIT license) focusing on fairness auditing for criminal justice and policy applications, [[Amazon SageMaker Clarify]] for enterprise bias detection and explainability, and [[FairTest]] (Columbia University, MIT license) enabling statistical fairness testing with association discovery.",
    "source_domain": "ai",
    "maturity_level": null,
    "authority_score": 0.95
  }
}