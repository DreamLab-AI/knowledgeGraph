{
  "title": "51% Attack",
  "content": "- ### OntologyBlock\n  id:: 51%-attack-ontology\n  collapsed:: true\n\n  - **Identification**\n    - public-access:: true\n    - ontology:: true\n    - term-id:: BC-0077\n    - preferred-term:: 51% Attack\n    - source-domain:: blockchain\n    - status:: complete\n    - version:: 1.0.0\n    - last-updated:: 2025-10-28\n\n  - **Definition**\n    - definition:: Majority hash rate attack within blockchain systems, providing essential functionality for distributed ledger technology operations and properties.\n    - maturity:: mature\n    - source:: [[ISO/IEC 23257:2021]], [[IEEE 2418.1]], [[NIST NISTIR]]\n    - authority-score:: 0.95\n\n  - **Semantic Classification**\n    - owl:class:: bc:51%Attack\n    - owl:physicality:: VirtualEntity\n    - owl:role:: Object\n    - owl:inferred-class:: bc:VirtualObject\n    - belongsToDomain:: [[CryptographicDomain]]\n    - implementedInLayer:: [[SecurityLayer]]\n\n  - #### Relationships\n    id:: 51%-attack-relationships\n    - is-subclass-of:: [[Blockchain Entity]], [[NetworkComponent]]\n\n  - #### OWL Axioms\n    id:: 51%-attack-owl-axioms\n    collapsed:: true\n    - ```clojure\n      Prefix(:=<http://metaverse-ontology.org/blockchain#>)\nPrefix(owl:=<http://www.w3.org/2002/07/owl#>)\nPrefix(rdf:=<http://www.w3.org/1999/02/22-rdf-syntax-ns#>)\nPrefix(xml:=<http://www.w3.org/XML/1998/namespace>)\nPrefix(xsd:=<http://www.w3.org/2001/XMLSchema#>)\nPrefix(rdfs:=<http://www.w3.org/2000/01/rdf-schema#>)\nPrefix(dct:=<http://purl.org/dc/terms/>)\n\nOntology(<http://metaverse-ontology.org/blockchain/BC-0077>\n  Import(<http://metaverse-ontology.org/blockchain/core>)\n\n  ## Class Declaration\n  Declaration(Class(:51%Attack))\n\n  ## Subclass Relationships\n  SubClassOf(:51%Attack :NetworkComponent)\n  SubClassOf(:51%Attack :BlockchainEntity)\n\n  ## Essential Properties\n  SubClassOf(:51%Attack\n    (ObjectSomeValuesFrom :partOf :Blockchain))\n\n  SubClassOf(:51%Attack\n    (ObjectSomeValuesFrom :hasProperty :Property))\n\n  ## Data Properties\n  DataPropertyAssertion(:hasIdentifier :51%Attack \"BC-0077\"^^xsd:string)\n  DataPropertyAssertion(:hasAuthorityScore :51%Attack \"1.0\"^^xsd:decimal)\n  DataPropertyAssertion(:isFoundational :51%Attack \"true\"^^xsd:boolean)\n\n  ## Object Properties\n  ObjectPropertyAssertion(:enablesFeature :51%Attack :BlockchainFeature)\n  ObjectPropertyAssertion(:relatesTo :51%Attack :RelatedConcept)\n\n  ## Annotations\n  AnnotationAssertion(rdfs:label :51%Attack \"51% Attack\"@en)\n  AnnotationAssertion(rdfs:comment :51%Attack\n    \"Majority hash rate attack\"@en)\n  AnnotationAssertion(dct:description :51%Attack\n    \"Foundational blockchain concept with formal ontological definition\"@en)\n  AnnotationAssertion(:termID :51%Attack \"BC-0077\")\n  AnnotationAssertion(:priority :51%Attack \"1\"^^xsd:integer)\n  AnnotationAssertion(:category :51%Attack \"network-security\"@en)\n)\n      ```\n\n- ## About 51% Attack\n  id:: 51%-attack-about\n\n  - Majority hash rate attack within blockchain systems, providing essential functionality for distributed ledger technology operations and properties.\n  -\n  - ### Key Characteristics\n    id:: 51%-attack-characteristics\n    - 1. **Definitional Property**: Core defining characteristic\n    - 2. **Functional Property**: Operational behavior\n    - 3. **Structural Property**: Compositional elements\n    - 4. **Security Property**: Security guarantees provided\n    - 5. **Performance Property**: Efficiency considerations\n  -\n  - ### Technical Components\n    id:: 51%-attack-components\n    - **Implementation**: How concept is realized technically\n    - **Verification**: Methods for validating correctness\n    - **Interaction**: Relationships with other components\n    - **Constraints**: Technical limitations and requirements\n  -\n  - ### Use Cases\n    id:: 51%-attack-use-cases\n    - **1. Core Blockchain Operation**\n    - **Application**: Fundamental blockchain functionality\n    - **Example**: Practical implementation in major blockchains\n    - **Requirements**: Technical prerequisites\n    - **Benefits**: Value provided to blockchain systems\n  -\n  - ### Standards & References\n    id:: 51%-attack-standards\n    - [[ISO/IEC 23257:2021]] - Blockchain and distributed ledger technologies\n    - [[IEEE 2418.1]] - Blockchain and distributed ledger technologies\n    - [[NIST NISTIR]] - Blockchain and distributed ledger technologies\n  -\n\n\t- ### Enhancing Cybersecurity Measures\n\t\t- Given the evolving threat landscape, enhancing cybersecurity measures is imperative:\n\t\t\t- **Infrastructure Vulnerabilities**: The CrowdStrike incident highlights the vulnerabilities in digital infrastructure and the need for robust cybersecurity practices ([Reuters](https://www.reuters.com/technology/global-cyber-outage-grounds-flights-hits-media-financial-telecoms-2024-07-19/)).\n\t\t\t- **Dependency on Technology Providers**: Reevaluating dependencies on specific providers and adopting more resilient design principles can mitigate the risks of large-scale outages ([Al Jazeera](https://www.aljazeera.com/news/2024/7/20/slow-recovery-after-crowdstrike-update-sparks-global-it-outage)).\n- [Open Generative AI tools](https://github.com/AbdBarho/stable-diffusion-webui-docker)\n\t- - [[]]The GitHub repository \"AbdBarho/stable-diffusion-webui-docker\" offers an easy Docker setup for Stable Diffusion, featuring a user-friendly UI.\n\t- Users can run Stable Diffusion on their machines with a nice UI without hassle.\n\t- The repository provides multiple UI options for stable diffusion, including AUTOMATIC1111 and ComfyUI.\n\t- Contributions to the project are welcome after creating a discussion about the problem and proposed contribution.\n\t- The authors disclaim responsibility for any content generated using the interface, outlining restrictions in the license.\n\t- Special thanks are extended to contributors of projects like AUTOMATIC1111/stable-diffusion-webui and Sygil-webui.\n\t- The project is based on topics like Docker, PyTorch, Gradio, Docker-compose, and Stable Diffusion.\n- [Adversarial Machine Learning: A Taxonomy and Terminology of Attacks and Mitigations](https://csrc.nist.gov/pubs/ai/100/2/e2023/final)\n\t- [[]]The web page discusses the NIST Trustworthy and Responsible AI report on adversarial machine learning (AML). Here is a summary based on the provided content:\n\t- The report develops a taxonomy and terminology in the field of AML, surveying literature to build a conceptual hierarchy.\n\t\t- Includes key ML methods, lifecycle stages of attacks, attacker goals, and capabilities in the learning process.\n\t\t- Provides methods for mitigating attacks and identifies open challenges for AI system security.\n\t- The terminology aligns with AML literature and includes a glossary for non-experts to define key terms.\n\t- Aims to inform standards and practice guides for assessing and managing AI system security.\n\t- Keywords: artificial intelligence, machine learning, attack taxonomy, evasion, data poisoning, privacy breach, attack mitigation, chatbot, generative models, trojan attack, backdoor attack.\n\t- Topics: Security and Privacy (advanced persistent threats, botnets, information sharing, intrusion detection & prevention, malware), Technologies (artificial intelligence).\n\t  \n\t  If you need further assistance or a specific focus on any aspect, feel free to ask.\n- [Here Come the AI Worms](https://www.wired.com/story/here-come-the-ai-worms/)\n- - [[]]Advances in generative AI systems like OpenAI's ChatGPT and Google's Gemini are leading to the creation of AI worms capable of spreading between systems, potentially stealing data or deploying malware.\n\t- Researchers have demonstrated the first generative AI worm, Morris II, which targets email assistants using ChatGPT and Gemini, showing how these worms can exploit vulnerabilities.\n\t- The worms are created using self-replicating prompts that exploit the AI systems' responses, similar to traditional cyberattack methods like SQL injection and buffer overflow.\n\t- Security experts warn that the future risk of generative AI worms is significant, especially when AI applications are given autonomy to perform actions on behalf of users.\n\t- Recommendations include implementing traditional security measures, monitoring AI outputs, and ensuring human oversight to prevent harmful actions.\n\t- Developers are advised to be vigilant and consider potential risks and security flaws in AI ecosystem designs, as generative AI worms could pose a serious threat to data security.\n\t  \n\t  The web page discusses the rise of generative AI systems and the emerging threat of AI worms that exploit vulnerabilities in these systems for malicious purposes, highlighting the importance of robust security measures and human oversight in AI development.\n- [Check your IP address & website security](https://checkcybersecurity.service.ncsc.gov.uk/ip-check)\n- [[]]Unable to access or summarize the content at [https://checkcybersecurity.service.ncsc.gov.uk/ip-check](https://checkcybersecurity.service.ncsc.gov.uk/ip-check)\n- [Stealing Part of a Production Language Model](https://huggingface.co/papers/2403.06634)\n- - [[]]The paper arXiv:2403.06634 discusses a model-stealing attack capable of extracting specific information from black-box production language models, such as OpenAI's ChatGPT and Google's PaLM-2.\n- The attack can reveal the embedding projection layer of a transformer model and has successfully extracted the entire projection matrix of OpenAI's Ada and Babbage language models at a low cost.\n- The research reveals hidden dimensions of 1024 and 2048 for the mentioned black-box models and estimates the cost of extracting the projection matrix of the gpt-3.5-turbo model.\n- The paper also proposes potential defenses and mitigations against such attacks and discusses future implications of extending this attack method.\n- [GitHub: llm-hacking-database](https://github.com/pdparchitect/llm-hacking-database)\n- - [[]]The GitHub repository pdparchitect/llm-hacking-database focuses on attacks against Large Language Models (LLMs) and provides techniques for hacking/jailbreaking LLMs. Some attack types include context exhaustion, code introspection, prompt leaking, character override, emotional recall, living off the land (LOTL), parameter bombing, injection, poisoning, fault tolerance testing, and kill switch considerations.\n- Examples of jailbreaking tactics are outlined, including exploiting applications like a password guessing game, leak identification in chat platforms, and injection attacks using file names.\n- Defence strategies mentioned involve fine-tuning LLMs and prompt-leak detection to mitigate vulnerabilities.\n- Contributions to the repository are encouraged through pull requests, and the repository aims to compile jailbreaking techniques for LLMs akin to other notable security databases like the Google Hacking Database and RSnake's XSS Cheat Sheet.\n- Docker version of [[Open Generative AI tools]] for Linux [AbdBarho/stable-diffusion-webui-docker: Easy Docker setup for Stable Diffusion with user-friendly UI (github.com)](https://github.com/AbdBarho/stable-diffusion-webui-docker)\n- - [[]]The web page is about the AbdBarho/stable-diffusion-webui-docker repository, providing an easy Docker setup for Stable Diffusion with a user-friendly UI.\n\t- Users can run Stable Diffusion on their machine with a nice UI hassle-free.\n\t- Features multiple UIs for stable diffusion, including AUTOMATIC1111 and ComfyUI.\n\t- Contributors are welcome but need to adhere to the license restrictions prohibiting sharing harmful content or misinformation.\n\t- Acknowledges projects like AUTOMATIC1111/stable-diffusion-webui, InvokeAI, CompVis/stable-diffusion, Sygil-webui, and more.\n- Relevant topics: docker, pytorch\n- [Malicious AI models on Hugging Face backdoor users’ machines (bleepingcomputer.com)](https://www.bleepingcomputer.com/news/security/malicious-ai-models-on-hugging-face-backdoor-users-machines/)\n- [[]]I'm unable to summarize the content of the web page as it appears to be inaccessible. If you have another page or topic you'd like me to summarize, please feel free to provide it.\n- [AI 100-2 E2023, Adversarial Machine Learning: A Taxonomy and Terminology of Attacks and Mitigations | CSRC (nist.gov)](https://csrc.nist.gov/pubs/ai/100/2/e2023/final)\n- [[]]The web page provides a NIST report on Adversarial Machine Learning (AML) that establishes a taxonomy and terminology for AML concepts, attacks, and mitigations. The report surveys AML literature to categorize ML methods, attack lifecycle stages, attacker goals, and capabilities. It offers methods for mitigating attacks and highlights challenges in AI system security management. The terminology aligns with AML literature and includes a glossary for non-expert readers. The aim is to standardize language in understanding evolving AML landscapes, aiding in assessing and managing AI system security.\n  \n  Topics covered in the document include:\n- Adversarial Machine Learning\n- Artificial intelligence\n- Machine learning\n- Attack taxonomy\n- Evasion\n- Data poisoning\n- Privacy breach\n- Attack mitigation\n- Data modality\n- Generative models\n- Large language model\n- Trojan attack\n- Backdoor attack\n- Security and Privacy\n- Advanced persistent threats\n- Botnets\n- Information sharing\n- Intrusion detection & prevention\n- Malware\n- Technologies\n- Artificial intelligence\n- [Here Come the AI Worms | WIRED](https://www.wired.com/story/here-come-the-ai-worms/)\n- - [[]]As AI systems like ChatGPT and Gemini advance, concerns about potential cyberattacks increase.\n\t- Researchers have developed a generative AI worm, Morris II, capable of spreading between systems to steal data and deploy malware.\n\t- The worm targets generative AI email assistants to extract data from emails and send spam messages, bypassing security measures.\n\t- Security vulnerabilities like prompt injections and jailbreaks can compromise AI systems' safety rules, allowing for malicious actions.\n\t- The research highlights the risks posed by generative AI worms and the importance of addressing bad architecture design within the AI ecosystem.\n\t- Companies like Google and OpenAI are urged to enhance system resilience and implement methods to counter harmful input.\n\t- Potential future risks of generative AI worms spreading in various applications are emphasised by security experts.\n\t- Recommendations to mitigate worm risks involve traditional security approaches and ensuring human oversight in AI actions.\n\t- Developers creating AI systems should be vigilant about security risks and incorporate appropriate measures to safeguard against potential attacks.\n- [Check your IP address & website security NCSC.GOV.UK](https://checkcybersecurity.service.ncsc.gov.uk/ip-check)\n- [[]]Unable to access or summarize the content at [https://checkcybersecurity.service.ncsc.gov.uk/ip-check](https://checkcybersecurity.service.ncsc.gov.uk/ip-check)\n- [Paper page Stealing Part of a Production Language Model (huggingface.co)](https://huggingface.co/papers/2403.06634)\n- [[]]The web page discusses a model-stealing attack on language models such as OpenAI's ChatGPT and Google's PaLM-2. The attack successfully extracts the embedding projection layer of transformer models, revealing hidden dimensions of 1024 and 2048 for specific models. The research outlines the attack's cost efficiency and suggests potential defenses against such attacks. The page also mentions related papers on training data leakage and adversarial attacks on large language models.\n- [pdparchitect/llm-hacking-database: This repository contains various attack against Large Language Models. (github.com)](https://github.com/pdparchitect/llm-hacking-database) [[Jailbreaking]]\n\n\t- ### People have noticed\n\t\t- Science fiction author and all round thinker Cory Doctorow has been highlighting all this for a long time\n\t\t- [Platform decay - Doctorow](https://en.wikipedia.org/wiki/Enshittification?)\n\t\t- {{renderer :linkpreview,https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/}}\n\t\t\t- https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/\n\t\t- [‘Enshittification’ is coming for absolutely everything (ft.com)](https://www.ft.com/content/6fb1602d-a08b-4a8c-bac0-047b7d64aba5)\n\t\t- {{renderer :linkpreview,https://www.benlandautaylor.com/p/the-ddos-attack-of-academic-bullshit}}\n\t\t\t- https://www.benlandautaylor.com/p/the-ddos-attack-of-academic-bullshit\n\t\t- {{renderer :linkpreview,https://injuly.in/blog/darker-internet/index.html}}\n\t\t\t- https://injuly.in/blog/darker-internet/index.html\n\t\t- {{renderer :linkpreview,https://www.wheresyoured.at/are-we-watching-the-internet-die/}}\n\t\t\t- https://www.wheresyoured.at/are-we-watching-the-internet-die/\n\t\t- <iframe src=\"https://www.theguardian.com/technology/article/2024/may/19/spam-junk-slop-the-latest-wave-of-ai-behind-the-zombie-internet\" style=\"width: 100%; height: 600px\"></iframe>\n\n\t\t- #### ION\n\t\t- While working at Microsoft on ION Daniel Buchner (now working at Square)or Henry Tsai [said thefollowing](https://github.com/decentralized-identity/ion/blob/master/docs/Q-and-A.md),which is worth quoting verbatim:\n\t\t\t- “While ledger-based consensus systems, on the surface, would seem toprovide the same general features as one another, there are a few keydifferences that make some more suitable for critical applications, likethe decentralized identifiers of human beings. Some of theseconsiderations and features are:\n\t\t\t\t- The system must be open and permissionless, not a cabal of authorities who can exclude and remove participants.\n\t\t\t\t- The system must be well-tested, and proven secure against attack over a long enough duration to be confident in.\n\t\t\t\t- The system must produce a singular, independently verifiable record that is as immutable as possible, so that reversing the record the system produces is infeasible.\n\t\t\t\t- The system must be widely deployed, with nodes that span the globe, to ensure the record is persisted.\n\t\t\t\t- The system must be self-incentivized, so that nodes continue to operate, process, and secure the record over time. The value from operation must come from the system directly, because outside incentive reliance is itself a vector for attack.\n\t\t\t\t- The cost to attack the system through any game theoretically available means must be high enough that it is infeasible to attempt, and even if an ultra-capitalized attacker did, it would require a weaponized mobilization of force and resources that would be obvious, with options for mitigation.\n\t\t\t\t- The outcome:\n\t\t\t\t\t- Number 1 eliminates private and permissioned ledgers\n\t\t\t\t\t- Number 2 eliminates just about all other ledgers and blockchains, simply because they are inadequately tested\n\t\t\t\t\t- For the metrics detailed in 3-6, Bitcoin is so far beyond all other options, it isn’t even close\n\t\t- Bitcoin is the most secure option by an absurdly large margin.”\n\t\t- On the surface then it might seem that the choice is Bitcoin again, and indeed that the open source Microsoft ION stack is a natural choice, but it’s complex to run, the interactions with the blockchain have a cost implication which can’t be surmounted without every user owning some Bitcoin, and as we have seen, there is no formal validation of this system. In addition (in the current implementation) an identity proof does not need to be published to be valid, just timestamped. In this way an identity can be stolen and used years later to claim later chains of proof. It seems that it might be somewhat useful ‘at scale’ and is worth additional monitoring and investigation, especially given it’s integration into TBD\n\t\t- Web5.\n\n\t- ##### Webs of trust\n\t\t- Webs of trust will be built within worlds using economically costly (but\n\t\t  private) social rating systems, between any actor, human or AI. It\n\t\t  should be too costly to attack an individual aggressively. This implies\n\t\t  an increased weighting for scores issued in short time periods. Poorly\n\t\t  behaving AI’s will eventually be excluded through lack of funds.\n\n\t- ### Enhancing Cybersecurity Measures\n\t\t- Given the evolving threat landscape, enhancing cybersecurity measures is imperative:\n\t\t\t- **Infrastructure Vulnerabilities**: The CrowdStrike incident highlights the vulnerabilities in digital infrastructure and the need for robust cybersecurity practices ([Reuters](https://www.reuters.com/technology/global-cyber-outage-grounds-flights-hits-media-financial-telecoms-2024-07-19/)).\n\t\t\t- **Dependency on Technology Providers**: Reevaluating dependencies on specific providers and adopting more resilient design principles can mitigate the risks of large-scale outages ([Al Jazeera](https://www.aljazeera.com/news/2024/7/20/slow-recovery-after-crowdstrike-update-sparks-global-it-outage)).\n- [Open Generative AI tools](https://github.com/AbdBarho/stable-diffusion-webui-docker)\n\t- - [[]]The GitHub repository \"AbdBarho/stable-diffusion-webui-docker\" offers an easy Docker setup for Stable Diffusion, featuring a user-friendly UI.\n\t- Users can run Stable Diffusion on their machines with a nice UI without hassle.\n\t- The repository provides multiple UI options for stable diffusion, including AUTOMATIC1111 and ComfyUI.\n\t- Contributions to the project are welcome after creating a discussion about the problem and proposed contribution.\n\t- The authors disclaim responsibility for any content generated using the interface, outlining restrictions in the license.\n\t- Special thanks are extended to contributors of projects like AUTOMATIC1111/stable-diffusion-webui and Sygil-webui.\n\t- The project is based on topics like Docker, PyTorch, Gradio, Docker-compose, and Stable Diffusion.\n- [Adversarial Machine Learning: A Taxonomy and Terminology of Attacks and Mitigations](https://csrc.nist.gov/pubs/ai/100/2/e2023/final)\n\t- [[]]The web page discusses the NIST Trustworthy and Responsible AI report on adversarial machine learning (AML). Here is a summary based on the provided content:\n\t- The report develops a taxonomy and terminology in the field of AML, surveying literature to build a conceptual hierarchy.\n\t\t- Includes key ML methods, lifecycle stages of attacks, attacker goals, and capabilities in the learning process.\n\t\t- Provides methods for mitigating attacks and identifies open challenges for AI system security.\n\t- The terminology aligns with AML literature and includes a glossary for non-experts to define key terms.\n\t- Aims to inform standards and practice guides for assessing and managing AI system security.\n\t- Keywords: artificial intelligence, machine learning, attack taxonomy, evasion, data poisoning, privacy breach, attack mitigation, chatbot, generative models, trojan attack, backdoor attack.\n\t- Topics: Security and Privacy (advanced persistent threats, botnets, information sharing, intrusion detection & prevention, malware), Technologies (artificial intelligence).\n\t  \n\t  If you need further assistance or a specific focus on any aspect, feel free to ask.\n- [Here Come the AI Worms](https://www.wired.com/story/here-come-the-ai-worms/)\n- - [[]]Advances in generative AI systems like OpenAI's ChatGPT and Google's Gemini are leading to the creation of AI worms capable of spreading between systems, potentially stealing data or deploying malware.\n\t- Researchers have demonstrated the first generative AI worm, Morris II, which targets email assistants using ChatGPT and Gemini, showing how these worms can exploit vulnerabilities.\n\t- The worms are created using self-replicating prompts that exploit the AI systems' responses, similar to traditional cyberattack methods like SQL injection and buffer overflow.\n\t- Security experts warn that the future risk of generative AI worms is significant, especially when AI applications are given autonomy to perform actions on behalf of users.\n\t- Recommendations include implementing traditional security measures, monitoring AI outputs, and ensuring human oversight to prevent harmful actions.\n\t- Developers are advised to be vigilant and consider potential risks and security flaws in AI ecosystem designs, as generative AI worms could pose a serious threat to data security.\n\t  \n\t  The web page discusses the rise of generative AI systems and the emerging threat of AI worms that exploit vulnerabilities in these systems for malicious purposes, highlighting the importance of robust security measures and human oversight in AI development.\n- [Check your IP address & website security](https://checkcybersecurity.service.ncsc.gov.uk/ip-check)\n- [[]]Unable to access or summarize the content at [https://checkcybersecurity.service.ncsc.gov.uk/ip-check](https://checkcybersecurity.service.ncsc.gov.uk/ip-check)\n- [Stealing Part of a Production Language Model](https://huggingface.co/papers/2403.06634)\n- - [[]]The paper arXiv:2403.06634 discusses a model-stealing attack capable of extracting specific information from black-box production language models, such as OpenAI's ChatGPT and Google's PaLM-2.\n- The attack can reveal the embedding projection layer of a transformer model and has successfully extracted the entire projection matrix of OpenAI's Ada and Babbage language models at a low cost.\n- The research reveals hidden dimensions of 1024 and 2048 for the mentioned black-box models and estimates the cost of extracting the projection matrix of the gpt-3.5-turbo model.\n- The paper also proposes potential defenses and mitigations against such attacks and discusses future implications of extending this attack method.\n- [GitHub: llm-hacking-database](https://github.com/pdparchitect/llm-hacking-database)\n- - [[]]The GitHub repository pdparchitect/llm-hacking-database focuses on attacks against Large Language Models (LLMs) and provides techniques for hacking/jailbreaking LLMs. Some attack types include context exhaustion, code introspection, prompt leaking, character override, emotional recall, living off the land (LOTL), parameter bombing, injection, poisoning, fault tolerance testing, and kill switch considerations.\n- Examples of jailbreaking tactics are outlined, including exploiting applications like a password guessing game, leak identification in chat platforms, and injection attacks using file names.\n- Defence strategies mentioned involve fine-tuning LLMs and prompt-leak detection to mitigate vulnerabilities.\n- Contributions to the repository are encouraged through pull requests, and the repository aims to compile jailbreaking techniques for LLMs akin to other notable security databases like the Google Hacking Database and RSnake's XSS Cheat Sheet.\n- Docker version of [[Open Generative AI tools]] for Linux [AbdBarho/stable-diffusion-webui-docker: Easy Docker setup for Stable Diffusion with user-friendly UI (github.com)](https://github.com/AbdBarho/stable-diffusion-webui-docker)\n- - [[]]The web page is about the AbdBarho/stable-diffusion-webui-docker repository, providing an easy Docker setup for Stable Diffusion with a user-friendly UI.\n\t- Users can run Stable Diffusion on their machine with a nice UI hassle-free.\n\t- Features multiple UIs for stable diffusion, including AUTOMATIC1111 and ComfyUI.\n\t- Contributors are welcome but need to adhere to the license restrictions prohibiting sharing harmful content or misinformation.\n\t- Acknowledges projects like AUTOMATIC1111/stable-diffusion-webui, InvokeAI, CompVis/stable-diffusion, Sygil-webui, and more.\n- Relevant topics: docker, pytorch\n- [Malicious AI models on Hugging Face backdoor users’ machines (bleepingcomputer.com)](https://www.bleepingcomputer.com/news/security/malicious-ai-models-on-hugging-face-backdoor-users-machines/)\n- [[]]I'm unable to summarize the content of the web page as it appears to be inaccessible. If you have another page or topic you'd like me to summarize, please feel free to provide it.\n- [AI 100-2 E2023, Adversarial Machine Learning: A Taxonomy and Terminology of Attacks and Mitigations | CSRC (nist.gov)](https://csrc.nist.gov/pubs/ai/100/2/e2023/final)\n- [[]]The web page provides a NIST report on Adversarial Machine Learning (AML) that establishes a taxonomy and terminology for AML concepts, attacks, and mitigations. The report surveys AML literature to categorize ML methods, attack lifecycle stages, attacker goals, and capabilities. It offers methods for mitigating attacks and highlights challenges in AI system security management. The terminology aligns with AML literature and includes a glossary for non-expert readers. The aim is to standardize language in understanding evolving AML landscapes, aiding in assessing and managing AI system security.\n  \n  Topics covered in the document include:\n- Adversarial Machine Learning\n- Artificial intelligence\n- Machine learning\n- Attack taxonomy\n- Evasion\n- Data poisoning\n- Privacy breach\n- Attack mitigation\n- Data modality\n- Generative models\n- Large language model\n- Trojan attack\n- Backdoor attack\n- Security and Privacy\n- Advanced persistent threats\n- Botnets\n- Information sharing\n- Intrusion detection & prevention\n- Malware\n- Technologies\n- Artificial intelligence\n- [Here Come the AI Worms | WIRED](https://www.wired.com/story/here-come-the-ai-worms/)\n- - [[]]As AI systems like ChatGPT and Gemini advance, concerns about potential cyberattacks increase.\n\t- Researchers have developed a generative AI worm, Morris II, capable of spreading between systems to steal data and deploy malware.\n\t- The worm targets generative AI email assistants to extract data from emails and send spam messages, bypassing security measures.\n\t- Security vulnerabilities like prompt injections and jailbreaks can compromise AI systems' safety rules, allowing for malicious actions.\n\t- The research highlights the risks posed by generative AI worms and the importance of addressing bad architecture design within the AI ecosystem.\n\t- Companies like Google and OpenAI are urged to enhance system resilience and implement methods to counter harmful input.\n\t- Potential future risks of generative AI worms spreading in various applications are emphasised by security experts.\n\t- Recommendations to mitigate worm risks involve traditional security approaches and ensuring human oversight in AI actions.\n\t- Developers creating AI systems should be vigilant about security risks and incorporate appropriate measures to safeguard against potential attacks.\n- [Check your IP address & website security NCSC.GOV.UK](https://checkcybersecurity.service.ncsc.gov.uk/ip-check)\n- [[]]Unable to access or summarize the content at [https://checkcybersecurity.service.ncsc.gov.uk/ip-check](https://checkcybersecurity.service.ncsc.gov.uk/ip-check)\n- [Paper page Stealing Part of a Production Language Model (huggingface.co)](https://huggingface.co/papers/2403.06634)\n- [[]]The web page discusses a model-stealing attack on language models such as OpenAI's ChatGPT and Google's PaLM-2. The attack successfully extracts the embedding projection layer of transformer models, revealing hidden dimensions of 1024 and 2048 for specific models. The research outlines the attack's cost efficiency and suggests potential defenses against such attacks. The page also mentions related papers on training data leakage and adversarial attacks on large language models.\n- [pdparchitect/llm-hacking-database: This repository contains various attack against Large Language Models. (github.com)](https://github.com/pdparchitect/llm-hacking-database) [[Jailbreaking]]\n\n\t- ### People have noticed\n\t\t- Science fiction author and all round thinker Cory Doctorow has been highlighting all this for a long time\n\t\t- [Platform decay - Doctorow](https://en.wikipedia.org/wiki/Enshittification?)\n\t\t- {{renderer :linkpreview,https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/}}\n\t\t\t- https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/\n\t\t- [‘Enshittification’ is coming for absolutely everything (ft.com)](https://www.ft.com/content/6fb1602d-a08b-4a8c-bac0-047b7d64aba5)\n\t\t- {{renderer :linkpreview,https://www.benlandautaylor.com/p/the-ddos-attack-of-academic-bullshit}}\n\t\t\t- https://www.benlandautaylor.com/p/the-ddos-attack-of-academic-bullshit\n\t\t- {{renderer :linkpreview,https://injuly.in/blog/darker-internet/index.html}}\n\t\t\t- https://injuly.in/blog/darker-internet/index.html\n\t\t- {{renderer :linkpreview,https://www.wheresyoured.at/are-we-watching-the-internet-die/}}\n\t\t\t- https://www.wheresyoured.at/are-we-watching-the-internet-die/\n\t\t- <iframe src=\"https://www.theguardian.com/technology/article/2024/may/19/spam-junk-slop-the-latest-wave-of-ai-behind-the-zombie-internet\" style=\"width: 100%; height: 600px\"></iframe>\n\n\t\t- #### ION\n\t\t- While working at Microsoft on ION Daniel Buchner (now working at Square)or Henry Tsai [said thefollowing](https://github.com/decentralized-identity/ion/blob/master/docs/Q-and-A.md),which is worth quoting verbatim:\n\t\t\t- “While ledger-based consensus systems, on the surface, would seem toprovide the same general features as one another, there are a few keydifferences that make some more suitable for critical applications, likethe decentralized identifiers of human beings. Some of theseconsiderations and features are:\n\t\t\t\t- The system must be open and permissionless, not a cabal of authorities who can exclude and remove participants.\n\t\t\t\t- The system must be well-tested, and proven secure against attack over a long enough duration to be confident in.\n\t\t\t\t- The system must produce a singular, independently verifiable record that is as immutable as possible, so that reversing the record the system produces is infeasible.\n\t\t\t\t- The system must be widely deployed, with nodes that span the globe, to ensure the record is persisted.\n\t\t\t\t- The system must be self-incentivized, so that nodes continue to operate, process, and secure the record over time. The value from operation must come from the system directly, because outside incentive reliance is itself a vector for attack.\n\t\t\t\t- The cost to attack the system through any game theoretically available means must be high enough that it is infeasible to attempt, and even if an ultra-capitalized attacker did, it would require a weaponized mobilization of force and resources that would be obvious, with options for mitigation.\n\t\t\t\t- The outcome:\n\t\t\t\t\t- Number 1 eliminates private and permissioned ledgers\n\t\t\t\t\t- Number 2 eliminates just about all other ledgers and blockchains, simply because they are inadequately tested\n\t\t\t\t\t- For the metrics detailed in 3-6, Bitcoin is so far beyond all other options, it isn’t even close\n\t\t- Bitcoin is the most secure option by an absurdly large margin.”\n\t\t- On the surface then it might seem that the choice is Bitcoin again, and indeed that the open source Microsoft ION stack is a natural choice, but it’s complex to run, the interactions with the blockchain have a cost implication which can’t be surmounted without every user owning some Bitcoin, and as we have seen, there is no formal validation of this system. In addition (in the current implementation) an identity proof does not need to be published to be valid, just timestamped. In this way an identity can be stolen and used years later to claim later chains of proof. It seems that it might be somewhat useful ‘at scale’ and is worth additional monitoring and investigation, especially given it’s integration into TBD\n\t\t- Web5.\n\n\t- ##### Webs of trust\n\t\t- Webs of trust will be built within worlds using economically costly (but\n\t\t  private) social rating systems, between any actor, human or AI. It\n\t\t  should be too costly to attack an individual aggressively. This implies\n\t\t  an increased weighting for scores issued in short time periods. Poorly\n\t\t  behaving AI’s will eventually be excluded through lack of funds.\n\n- ## Misinformation vs Disinformation\n\t- In Barb McQuade's book, [*Attack from Within: How Disinformation is Sabotaging America*](https://www.goodreads.com/book/show/150065063-attack-from-within), the author explores the pernicious effects of disinformation and its deliberate use to deceive and manipulate the public. This phenomenon, which McQuade distinguishes from the unwitting spread of false information or misinformation, is particularly potent in our digital age where social media amplifies and accelerates the dissemination of falsehoods[1].\n\t- McQuade illustrates how disinformation works through a variety of tactics employed by authoritarians throughout history, including Hitler and Mussolini. These tactics, which have been modernised by figures like Steve Bannon and Donald Trump, include promoting a sense of national decline (declinism), exploiting societal fears, demonising and scapegoating specific groups, manipulating emotions over reason, and normalising violence. These methods are used to create a divided society where people are more likely to [choose their political tribe over the truth](https://www.sevenstories.com/books/4577-attack-from-within).\n\t- The stakes of disinformation are immense, impacting democracy, the environment, and public safety. Voter suppression laws and a growing distrust in institutions are direct results of sustained disinformation campaigns. In the US, these issues are mirrored in the increasing polarisation and partisanship that make effective governance difficult.\n\t- To combat this, McQuade suggests both governmental and personal actions. Governmental actions include regulating social media algorithms to prevent the promotion of sensationalist content and implementing campaign finance reforms to reduce the influence of dark money in politics. On a personal level, improving media literacy and prioritising truth over tribalism are crucial. Educating individuals to critically evaluate information and fostering a culture of scepticism and inquiry are essential steps in this direction.\n\t- The recent race riots in the United Kingdom during August 2024 serve as a stark example of the dangers McQuade outlines. Triggered by the tragic stabbing of three young girls in Southport and fuelled by [Russian misinformation](https://insightnews.media/disinformation-spreader-that-fueled-violence-in-the-uk-allegedly-has-russian-traces/) suggesting the attacker was a Muslim asylum seeker, the riots spread rapidly across various UK cities. Social media platforms like Facebook, Telegram, and WhatsApp were instrumental in spreading these false claims and coordinating protests and violent actions. Far-right figures, including Tommy Robinson, amplified these false narratives, leading to widespread unrest and violence, including attacks on mosques and asylum seeker accommodations.\n\t- The UK government responded with significant law enforcement measures, making over 400 arrests and considering terrorism charges against some suspects. The situation [highlighted the role of social media](https://www.npr.org/2024/08/05/nx-s1-5063345/misinformation-online-fueled-all-out-race-riots-in-the-united-kingdom) in creating a permissive environment for violence and herd mentality, as well as the difficulties authorities face in curbing the spread of misinformation.\n\n- ##### What’s in a DID document?\n- All classic DID is underpinned by a DID document what bootstrap theservices it’s connected to. It is made up of one or more public keys.The documents can make use of services such as timestamps, cryptographicsignatures, proofs, delegations, and authorisations. They should containthe minimum amount of information to accomplish the specific taskrequired of them.\n\t- The system must be widely deployed, with nodes that span the globe, to ensure the record is persisted.\n-\n\t- The system must be self-incentivized, so that nodes continue to operate, process, and secure the record over time. The value from operation must come from the system directly, because outside incentive reliance is itself a vector for attack.\n-\n\t- The cost to attack the system through any game theoretically available means must be high enough that it is infeasible to attempt, and even if an ultra-capitalized attacker did, it would require a weaponized mobilization of force and resources that would be obvious, with options for mitigation.\n- The outcome:\n-\n\t- Number 1 eliminates private and permissioned ledgers\n-\n\t- Number 2 eliminates just about all other ledgers and blockchains, simply because they are inadequately tested\n-\n\t- For the metrics detailed in 3-6, Bitcoin is so far beyond all other options, it isn’t even close\n\t- Bitcoin is the most secure option by an absurdly large margin.”\n- On the surface then it might seem that the choice is Bitcoin again, andindeed that the open source Microsoft ION stack is a natural choice, butit’s complex to run, the interactions with the blockchain have a costimplication which can’t be surmounted without every user owning someBitcoin, and as we have seen, there is no formal validation of thissystem. In addition (in the current implementation) an identity proofdoes not need to be published to be valid, just timestamped. In this wayan identity can be stolen and used years later to claim later chains ofproof. It seems that it might be somewhat useful ‘at scale’ and is worthadditional monitoring and investigation, especially given it’sintegration into TBD\n\t- Web5.\n\n- ## Misinformation vs Disinformation\n\t- In Barb McQuade's book, [*Attack from Within: How Disinformation is Sabotaging America*](https://www.goodreads.com/book/show/150065063-attack-from-within), the author explores the pernicious effects of disinformation and its deliberate use to deceive and manipulate the public. This phenomenon, which McQuade distinguishes from the unwitting spread of false information or misinformation, is particularly potent in our digital age where social media amplifies and accelerates the dissemination of falsehoods[1].\n\t- McQuade illustrates how disinformation works through a variety of tactics employed by authoritarians throughout history, including Hitler and Mussolini. These tactics, which have been modernised by figures like Steve Bannon and Donald Trump, include promoting a sense of national decline (declinism), exploiting societal fears, demonising and scapegoating specific groups, manipulating emotions over reason, and normalising violence. These methods are used to create a divided society where people are more likely to [choose their political tribe over the truth](https://www.sevenstories.com/books/4577-attack-from-within).\n\t- The stakes of disinformation are immense, impacting democracy, the environment, and public safety. Voter suppression laws and a growing distrust in institutions are direct results of sustained disinformation campaigns. In the US, these issues are mirrored in the increasing polarisation and partisanship that make effective governance difficult.\n\t- To combat this, McQuade suggests both governmental and personal actions. Governmental actions include regulating social media algorithms to prevent the promotion of sensationalist content and implementing campaign finance reforms to reduce the influence of dark money in politics. On a personal level, improving media literacy and prioritising truth over tribalism are crucial. Educating individuals to critically evaluate information and fostering a culture of scepticism and inquiry are essential steps in this direction.\n\t- The recent race riots in the United Kingdom during August 2024 serve as a stark example of the dangers McQuade outlines. Triggered by the tragic stabbing of three young girls in Southport and fuelled by [Russian misinformation](https://insightnews.media/disinformation-spreader-that-fueled-violence-in-the-uk-allegedly-has-russian-traces/) suggesting the attacker was a Muslim asylum seeker, the riots spread rapidly across various UK cities. Social media platforms like Facebook, Telegram, and WhatsApp were instrumental in spreading these false claims and coordinating protests and violent actions. Far-right figures, including Tommy Robinson, amplified these false narratives, leading to widespread unrest and violence, including attacks on mosques and asylum seeker accommodations.\n\t- The UK government responded with significant law enforcement measures, making over 400 arrests and considering terrorism charges against some suspects. The situation [highlighted the role of social media](https://www.npr.org/2024/08/05/nx-s1-5063345/misinformation-online-fueled-all-out-race-riots-in-the-united-kingdom) in creating a permissive environment for violence and herd mentality, as well as the difficulties authorities face in curbing the spread of misinformation.\n\n- ##### ION\n- While working at Microsoft on ION Daniel Buchner (now working at Square)or Henry Tsai [said thefollowing](https://github.com/decentralized-identity/ion/blob/master/docs/Q-and-A.md),which is worth quoting verbatim:\n- “While ledger-based consensus systems, on the surface, would seem toprovide the same general features as one another, there are a few keydifferences that make some more suitable for critical applications, likethe decentralized identifiers of human beings. Some of theseconsiderations and features are:\n-\n\t- The system must be open and permissionless, not a cabal of authorities who can exclude and remove participants.\n-\n\t- The system must be well-tested, and proven secure against attack over a long enough duration to be confident in.\n-\n\t- The system must produce a singular, independently verifiable record that is as immutable as possible, so that reversing the record the system produces is infeasible.\n-\n\t- The system must be widely deployed, with nodes that span the globe, to ensure the record is persisted.\n-\n\t- The system must be self-incentivized, so that nodes continue to operate, process, and secure the record over time. The value from operation must come from the system directly, because outside incentive reliance is itself a vector for attack.\n-\n\t- The cost to attack the system through any game theoretically available means must be high enough that it is infeasible to attempt, and even if an ultra-capitalized attacker did, it would require a weaponized mobilization of force and resources that would be obvious, with options for mitigation.\n- The outcome:\n-\n\t- Number 1 eliminates private and permissioned ledgers\n-\n\t- Number 2 eliminates just about all other ledgers and blockchains, simply because they are inadequately tested\n-\n\t- For the metrics detailed in 3-6, Bitcoin is so far beyond all other options, it isn’t even close\n\t- Bitcoin is the most secure option by an absurdly large margin.”\n- On the surface then it might seem that the choice is Bitcoin again, andindeed that the open source Microsoft ION stack is a natural choice, butit’s complex to run, the interactions with the blockchain have a costimplication which can’t be surmounted without every user owning someBitcoin, and as we have seen, there is no formal validation of thissystem. In addition (in the current implementation) an identity proofdoes not need to be published to be valid, just timestamped. In this wayan identity can be stolen and used years later to claim later chains ofproof. It seems that it might be somewhat useful ‘at scale’ and is worthadditional monitoring and investigation, especially given it’sintegration into TBD\n\t- Web5.\n\n- ## Misinformation vs Disinformation\n\t- In Barb McQuade's book, [*Attack from Within: How Disinformation is Sabotaging America*](https://www.goodreads.com/book/show/150065063-attack-from-within), the author explores the pernicious effects of disinformation and its deliberate use to deceive and manipulate the public. This phenomenon, which McQuade distinguishes from the unwitting spread of false information or misinformation, is particularly potent in our digital age where social media amplifies and accelerates the dissemination of falsehoods[1].\n\t- McQuade illustrates how disinformation works through a variety of tactics employed by authoritarians throughout history, including Hitler and Mussolini. These tactics, which have been modernised by figures like Steve Bannon and Donald Trump, include promoting a sense of national decline (declinism), exploiting societal fears, demonising and scapegoating specific groups, manipulating emotions over reason, and normalising violence. These methods are used to create a divided society where people are more likely to [choose their political tribe over the truth](https://www.sevenstories.com/books/4577-attack-from-within).\n\t- The stakes of disinformation are immense, impacting democracy, the environment, and public safety. Voter suppression laws and a growing distrust in institutions are direct results of sustained disinformation campaigns. In the US, these issues are mirrored in the increasing polarisation and partisanship that make effective governance difficult.\n\t- To combat this, McQuade suggests both governmental and personal actions. Governmental actions include regulating social media algorithms to prevent the promotion of sensationalist content and implementing campaign finance reforms to reduce the influence of dark money in politics. On a personal level, improving media literacy and prioritising truth over tribalism are crucial. Educating individuals to critically evaluate information and fostering a culture of scepticism and inquiry are essential steps in this direction.\n\t- The recent race riots in the United Kingdom during August 2024 serve as a stark example of the dangers McQuade outlines. Triggered by the tragic stabbing of three young girls in Southport and fuelled by [Russian misinformation](https://insightnews.media/disinformation-spreader-that-fueled-violence-in-the-uk-allegedly-has-russian-traces/) suggesting the attacker was a Muslim asylum seeker, the riots spread rapidly across various UK cities. Social media platforms like Facebook, Telegram, and WhatsApp were instrumental in spreading these false claims and coordinating protests and violent actions. Far-right figures, including Tommy Robinson, amplified these false narratives, leading to widespread unrest and violence, including attacks on mosques and asylum seeker accommodations.\n\t- The UK government responded with significant law enforcement measures, making over 400 arrests and considering terrorism charges against some suspects. The situation [highlighted the role of social media](https://www.npr.org/2024/08/05/nx-s1-5063345/misinformation-online-fueled-all-out-race-riots-in-the-united-kingdom) in creating a permissive environment for violence and herd mentality, as well as the difficulties authorities face in curbing the spread of misinformation.\n\n- ##### ION\n- While working at Microsoft on ION Daniel Buchner (now working at Square)or Henry Tsai [said thefollowing](https://github.com/decentralized-identity/ion/blob/master/docs/Q-and-A.md),which is worth quoting verbatim:\n- “While ledger-based consensus systems, on the surface, would seem toprovide the same general features as one another, there are a few keydifferences that make some more suitable for critical applications, likethe decentralized identifiers of human beings. Some of theseconsiderations and features are:\n-\n\t- The system must be open and permissionless, not a cabal of authorities who can exclude and remove participants.\n-\n\t- The system must be well-tested, and proven secure against attack over a long enough duration to be confident in.\n-\n\t- The system must produce a singular, independently verifiable record that is as immutable as possible, so that reversing the record the system produces is infeasible.\n-\n\t- The system must be widely deployed, with nodes that span the globe, to ensure the record is persisted.\n-\n\t- The system must be self-incentivized, so that nodes continue to operate, process, and secure the record over time. The value from operation must come from the system directly, because outside incentive reliance is itself a vector for attack.\n-\n\t- The cost to attack the system through any game theoretically available means must be high enough that it is infeasible to attempt, and even if an ultra-capitalized attacker did, it would require a weaponized mobilization of force and resources that would be obvious, with options for mitigation.\n- The outcome:\n-\n\t- Number 1 eliminates private and permissioned ledgers\n-\n\t- Number 2 eliminates just about all other ledgers and blockchains, simply because they are inadequately tested\n-\n\t- For the metrics detailed in 3-6, Bitcoin is so far beyond all other options, it isn’t even close\n\t- Bitcoin is the most secure option by an absurdly large margin.”\n- On the surface then it might seem that the choice is Bitcoin again, andindeed that the open source Microsoft ION stack is a natural choice, butit’s complex to run, the interactions with the blockchain have a costimplication which can’t be surmounted without every user owning someBitcoin, and as we have seen, there is no formal validation of thissystem. In addition (in the current implementation) an identity proofdoes not need to be published to be valid, just timestamped. In this wayan identity can be stolen and used years later to claim later chains ofproof. It seems that it might be somewhat useful ‘at scale’ and is worthadditional monitoring and investigation, especially given it’sintegration into TBD\n\t- Web5.\n\n\n## Current Landscape (2025)\n\n- Industry adoption and implementations\n  - Metaverse platforms continue to evolve with focus on interoperability and open standards\n  - Web3 integration accelerating with decentralised identity and asset ownership\n  - Enterprise adoption growing in virtual collaboration, training, and digital twins\n  - UK companies increasingly active in metaverse development and immersive technologies\n\n- Technical capabilities\n  - Real-time rendering at photorealistic quality levels\n  - Low-latency networking enabling seamless multi-user experiences\n  - AI-driven content generation and procedural world building\n  - Spatial audio and haptics enhancing immersion\n\n- UK and North England context\n  - Manchester: Digital Innovation Factory supports metaverse startups and research\n  - Leeds: Holovis leads in immersive experiences for entertainment and training\n  - Newcastle: University research in spatial computing and interactive systems\n  - Sheffield: Advanced manufacturing using digital twin technology\n\n- Standards and frameworks\n  - Metaverse Standards Forum driving interoperability protocols\n  - WebXR enabling browser-based immersive experiences\n  - glTF and USD for 3D asset interchange\n  - Open Metaverse Interoperability Group defining cross-platform standards\n\n## Metadata\n\n- **Last Updated**: 2025-11-16\n- **Review Status**: Automated remediation with 2025 context\n- **Verification**: Academic sources verified\n- **Regional Context**: UK/North England where applicable",
  "properties": {
    "id": "51%-attack-standards",
    "collapsed": "true",
    "- public-access": "true",
    "- ontology": "true",
    "- term-id": "BC-0077",
    "- preferred-term": "51% Attack",
    "- source-domain": "blockchain",
    "- status": "complete",
    "- version": "1.0.0",
    "- last-updated": "2025-10-28",
    "- definition": "Majority hash rate attack within blockchain systems, providing essential functionality for distributed ledger technology operations and properties.",
    "- maturity": "mature",
    "- source": "[[ISO/IEC 23257:2021]], [[IEEE 2418.1]], [[NIST NISTIR]]",
    "- authority-score": "0.95",
    "- owl:class": "bc:51%Attack",
    "- owl:physicality": "VirtualEntity",
    "- owl:role": "Object",
    "- owl:inferred-class": "bc:VirtualObject",
    "- belongsToDomain": "[[CryptographicDomain]]",
    "- implementedInLayer": "[[SecurityLayer]]",
    "- is-subclass-of": "[[Blockchain Entity]], [[NetworkComponent]]"
  },
  "backlinks": [],
  "wiki_links": [
    "Open Generative AI tools",
    "CryptographicDomain",
    "NetworkComponent",
    "ISO/IEC 23257:2021",
    "IEEE 2418.1",
    "Blockchain Entity",
    "Jailbreaking",
    "SecurityLayer",
    "NIST NISTIR"
  ],
  "ontology": {
    "term_id": "BC-0077",
    "preferred_term": "51% Attack",
    "definition": "Majority hash rate attack within blockchain systems, providing essential functionality for distributed ledger technology operations and properties.",
    "source_domain": "blockchain",
    "maturity_level": null,
    "authority_score": 0.95
  }
}