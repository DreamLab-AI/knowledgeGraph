{
  "title": "Comfy UI for Fashion and Brands",
  "content": "- ### OntologyBlock\n  id:: comfy-ui-for-fashion-and-brands-ontology\n  collapsed:: true\n\t- ontology:: true\n\t- term-id:: mv-772799585390\n\t- preferred-term:: Comfy UI for Fashion and Brands\n\t- source-domain:: metaverse\n\t- status:: active\n\t- public-access:: true\n\t- definition:: A component of the metaverse ecosystem focusing on comfy ui for fashion and brands.\n\t- maturity:: mature\n\t- authority-score:: 0.85\n\t- owl:class:: mv:ComfyUiForFashionAndBrands\n\t- owl:physicality:: ConceptualEntity\n\t- owl:role:: Concept\n\t- belongsToDomain:: [[MetaverseDomain]]\n\t- #### Relationships\n\t  id:: comfy-ui-for-fashion-and-brands-relationships\n\t\t- enables:: [[ImmersiveExperience]], [[Presence]], [[SpatialComputing]]\n\t\t- requires:: [[DisplayTechnology]], [[TrackingSystem]], [[RenderingEngine]]\n\t\t- bridges-to:: [[HumanComputerInteraction]], [[ComputerVision]], [[Robotics]]\n\n\t- #### OWL Axioms\n\t  id:: comfy-ui-for-fashion-and-brands-owl-axioms\n\t  collapsed:: true\n\t\t- ```clojure\n\t\t  Declaration(Class(mv:ComfyUiForFashionAndBrands))\n\n\t\t  # Classification\n\t\t  SubClassOf(mv:ComfyUiForFashionAndBrands mv:ConceptualEntity)\n\t\t  SubClassOf(mv:ComfyUiForFashionAndBrands mv:Concept)\n\n\t\t  # Domain classification\n\t\t  SubClassOf(mv:ComfyUiForFashionAndBrands\n\t\t    ObjectSomeValuesFrom(mv:belongsToDomain mv:MetaverseDomain)\n\t\t  )\n\n\t\t  # Annotations\n\t\t  AnnotationAssertion(rdfs:label mv:ComfyUiForFashionAndBrands \"Comfy UI for Fashion and Brands\"@en)\n\t\t  AnnotationAssertion(rdfs:comment mv:ComfyUiForFashionAndBrands \"A component of the metaverse ecosystem focusing on comfy ui for fashion and brands.\"@en)\n\t\t  AnnotationAssertion(dcterms:identifier mv:ComfyUiForFashionAndBrands \"mv-772799585390\"^^xsd:string)\n\t\t  ```\n\npublic:: true\n\n- ## [EVENT INVITE](https://www.eventbrite.co.uk/e/comfy-ui-for-fashion-and-brands-tickets-894342842517)\n- # GUEST WIFI - is the one labelled guest WiFi and you can put any old email in.\n- # j.ohare5@salford.ac.uk\n- # MayEvent\n-\n\t- ## About me\n\t\t- {{embed ((661d5f74-f334-4872-ba92-51244c2fb490))}}\n\t- {{embed ((661d5f74-5dfe-4569-9374-37b63637b3d8))}}\n\t- {{embed ((66314bd7-86ef-4ca2-8f39-704e133ac0a3))}}\n\t- ## Diffusion models from [[Overview of Machine Learning Techniques]]\n\t  collapsed:: true\n\t\t- {{embed ((661d5f76-bb78-4920-949e-76c3dbf66efe))}}\n\t\t- {{embed ((661d5f76-3ffa-4f10-9027-6f8e90601162))}}\n\t- {{embed ((66446c0e-93be-431d-93d4-1e5fa36848c5))}}\n\t- {{embed ((66408f9e-30e0-442b-9aba-9eb51e36a739))}}\n\t- # ComfyUI\n\t\t- Started out as a project by a single coder\n\t\t- Now adopted by the Stability team as their in house engine\n\t\t- Tens of thousands of models and add ons, hundreds of thousands of users\n\t\t- Can form the foundation of a deployable product\n\t\t\t- API for Comfy iteself\n\t\t\t- It's just chaining python scripts, you can isolate those and build\n\t\t- ## Tradeoffs\n\t\t\t- Faster.\n\t\t\t- Incredible control.\n\t\t\t- Steep learning curve.\n\t\t\t- Hard to setup, hard to keep running.\n\t\t- ## Finding all the tools.\n\t\t\t- https://github.com/comfyanonymous/ComfyUI\n\t\t\t- {{renderer :linkpreview,https://github.com/comfyanonymous/ComfyUI}}\n\t\t\t- https://huggingface.co/\n\t\t\t- {{renderer :linkpreview,https://huggingface.co/}}\n\t\t\t- https://civitai.com/\n\t\t\t- {{renderer :linkpreview,https://civitai.com/}}\n\t\t\t- https://www.comfyworkflows.com\n\t\t\t- {{renderer :linkpreview,https://www.comfyworkflows.com}}\n\t- ## Lots of modules, extensions\n\t\t- Papers from the GenAI community get rapidly converted to ComfyUI very quickly.\n\t\t- ### Segmentation\n\t\t\t- ![Segmentation for fashion](https://raw.githubusercontent.com/cozymantis/human-parser-comfyui-node/main/assets/lipexample.png)\n\t\t\t-\n\t\t- ### IpAdapter\n\t\t\t- Image to image conditioning, which is [[style transfer]], which is mashing images together.\n\t\t\t- ![](https://raw.githubusercontent.com/cubiq/ComfyUI_IPAdapter_plus/main/examples/demo_workflow.jpg)\n\t\t- ### 3D models for AR and VR\n\t\t\t- ![image.png](../assets/image_1715528397803_0.png)\n\t\t\t- ![image.png](../assets/image_1715584894585_0.png)\n\t-\n- # May Event workflow with 3D models and VTON try it on.\n\t- [memoryEfficient.json](../assets/memoryEfficient_1715084451554_0.json)\n- # Marco presentation\n\t- ![20240507 - Manchester Hackathon.pdf](../assets/20240507_-_Manchester_Hackathon_1715878110413_0.pdf)\n\t- < link not working let >\n- # Pre event buildout notes (here be dragons)\n  collapsed:: true\n\t- DONE Infrastructure build\n\t\t- DONE Get Ollama bridge working\n\t\t  collapsed:: true\n\t\t\t- [stavsap/comfyui-ollama (github.com)](https://github.com/stavsap/comfyui-ollama)\n\t\t\t- [MinusZoneAI/ComfyUI-Prompt-MZ: 基于llama.cpp的一些和提示词相关的节点，目前包括美化提示词和类似clip-interrogator的图片反推 | Use llama.cpp to assist in generating some nodes related to prompt words, including beautifying prompt words and image recognition similar to clip-interrogator (github.com)](https://github.com/MinusZoneAI/ComfyUI-Prompt-MZ)\n\t\t\t- [xXAdonesXx/NodeGPT: ComfyUI Extension Nodes for Automated Text Generation. (github.com)](https://github.com/xXAdonesXx/NodeGPT)\n\t\t\t- [stavsap/comfyui-ollama (github.com)](https://github.com/stavsap/comfyui-ollama)\n\t\t\t  id:: 6633f4c0-358f-44cf-bf05-d43c75febe36\n\t\t- DONE Backup the working docker\n\t\t- DONE sort the vpn and port forwarding\n\t\t- DONE Check the security\n\t\t- DONE Install the rest of the feature set\n\t\t- DONE Sort the models and Loras\n\t\t- DONE Fire up 3 instances\n\t\t\t- DONE TripoSR (no point, feature dropped)\n\t\t\t- DONE [Zero123](https://github.com/SUDO-AI-3D/zero123plus) (no point, feature dropped\n\t\t\t- DONE CRM\n\t\t- DONE [yisol/IDM-VTON: IDM-VTON : Improving Diffusion Models for Authentic Virtual Try-on in the Wild (github.com)](https://github.com/yisol/IDM-VTON)\n\t\t  collapsed:: true\n\t\t\t- [TemryL/ComfyUI-IDM-VTON: ComfyUI adaptation of IDM-VTON for virtual try-on. (github.com)](https://github.com/TemryL/ComfyUI-IDM-VTON)\n\t\t- TODO [Lllava 8b?](https://huggingface.co/collections/xtuner/llava-llama-3-8b-662a5f95adbe8d58799d7fdb) for descriptions\n\t\t  :LOGBOOK:\n\t\t  CLOCK: [2024-05-06 Mon 09:23:58]--[2024-05-06 Mon 09:23:58] =>  00:00:00\n\t\t  CLOCK: [2024-05-06 Mon 09:23:59]--[2024-05-06 Mon 09:24:00] =>  00:00:01\n\t\t  :END:\n\t\t- DONE Face swap\n\t\t- DONE NSFW filter\n\t\t- DONE Annotations and instructions\n\t\t  :LOGBOOK:\n\t\t  CLOCK: [2024-05-06 Mon 09:25:33]--[2024-05-06 Mon 12:16:24] =>  02:50:51\n\t\t  :END:\n\t\t- DONE Send to Pete to test\n\t\t- DONE Presentation outlines?\n\t\t- DONE Talk to Marco\n\t\t- DONE Next need to fix insightface [as here](https://github.com/cubiq/ComfyUI_IPAdapter_plus/issues/162) but\n\t\t\t- DONE backup first\n\t\t\t  :LOGBOOK:\n\t\t\t  CLOCK: [2024-05-06 Mon 10:23:31]--[2024-05-06 Mon 10:23:31] =>  00:00:00\n\t\t\t  :END:\n\t\t- TODO New nets and workflows? Pete?\n\t\t- DONE Confirm the compute arriving.\n\t\t- DONE Confirm the TV in time?\n\t\t- DONE Fix the windows laptop for delegates\n\t\t- DONE Condition the mac for delegates (come in monday afternoon)\n\t\t- DONE Charge the Rundiffusion account (talking to Tony this afternoon).\n\t\t- DONE Catering\n\t\t- DONE Talk to Marco\n\t\t- DONE Make a presentation for the day (logseq based for me)\n\t\t  :LOGBOOK:\n\t\t  CLOCK: [2024-05-12 Sun 16:41:41]--[2024-05-14 Tue 22:17:47] =>  53:36:06\n\t\t  :END:\n\t\t- DONE Delegate advance communications\n\t\t  :LOGBOOK:\n\t\t  CLOCK: [2024-05-11 Sat 19:58:36]--[2024-05-12 Sun 16:41:31] =>  20:42:55\n\t\t  CLOCK: [2024-05-12 Sun 16:41:35]--[2024-05-14 Tue 22:17:50] =>  53:36:15\n\t\t  :END:\n\t- ## Technical Elements\n\t\t- ## Technical notes\n\t\t\t- For the A6000 CRM docker\n\t\t\t\t- ```text\n\t\t\t\t  machinelearn@MLAI:/mnt/mldata/GenerativeAI$ cd ../githubs/ComfyUI-Docker/\n\t\t\t\t  machinelearn@MLAI:/mnt/mldata/githubs/ComfyUI-Docker$ ls\n\t\t\t\t  docker-compose.yml  docs     megapak      README.zh.adoc  scripts  storage_known_good\n\t\t\t\t  Dockerfile          LICENSE  README.adoc  rocm            storage\n\t\t\t\t  machinelearn@MLAI:/mnt/mldata/githubs/ComfyUI-Docker$  docker run -d -it --rm --name comfyui-mega --gpus '\"device=1\"' -p 8182:8182 -v \"$(pwd)\"/storage:/root -e CLI_ARGS=\"--port 8182\" yanwk/comfyui-boot:megapak\n\t\t\t\t  ```\n\t\t\t- to contact Ollama from within docker\n\t\t\t\t- ```text\n\t\t\t\t  curl http://172.17.0.1:11434/api/generate -d '{\n\t\t\t\t    \"model\": \"llama3-8B\",\n\t\t\t\t    \"prompt\": \"Why is the sky blue?\"\n\t\t\t\t  }'\n\t\t\t\t  \n\t\t\t\t  ```\n\t- # ComfyUI for Fashion and Brands: Event Instructions\n\t  collapsed:: true\n\t\t- ## Introduction\n\t\t\t- Welcome to the ComfyUI for Fashion and Brands event at Dreamlab in MediaCity! We are excited to have you join us for a day of innovation, collaboration, and exploration of generative AI technology in the realm of fashion and product design.\n\t\t\t- Before the event, please take a moment to review the following instructions and ensure that you have the necessary requirements to fully participate in the hackathon.\n\t\t- ## Timing and how to find us.\n\t\t\t- We’re on the 5th floor of Blue Tower at **[HOST](https://www.hostsalford.com/) ,** MediaCityUK.  The door is [opposite Costa Coffee](https://maps.app.goo.gl/APmHgNU7bvrXpRRa7).\n\t\t\t- You can take the tram to MediaCity, using the [free park and ride](https://tfgm.com/ways-to-travel/park-and-ride/parkway-tram) in Trafford.\n\t\t\t- You can also park at the MediaCity multistory car park but be advised it is expensive.\n\t\t\t- The event starts at 10am and runs to 4pm.\n\t\t- ## Schedule\n\t\t\t- Morning session - presentations from the team and guest speaker.\n\t\t\t- Afternoon - breakout hands on\n\t\t\t- Closeout Q&A\n\t\t- ## Workgroup Alignment\n\t\t\t- To ensure a tailored experience, we have divided the event into three workgroups. Please fill out the following Google Form to let us know which workgroup you would like to join:\n\t\t\t- [Choose your preferred workstream for the hands on event](https://forms.gle/Tg9EJhpRJcNGA42v6) (Google Form)\n\t\t\t- The workgroups are as follows:\n\t\t\t\t- **Novices**: This group will learn ComfyUI online using RunDiffusion with the assistance of a coach. VPN setup is not required for this group.\n\t\t\t\t- **Intermediate**: Participants in this group must set up the VPN (instructions provided below) and will work on a more advanced fashion and brands workflow with a different coach.\n\t\t\t\t- **Advanced / Hackathon**: This is a small group of up to five participants (first-come, first-served) who will work on code development with a specialist.\n\t\t- ## VPN Setup Instructions\n\t\t\t- For the Intermediate workgroup, setting up the VPN is essential. Please follow the instructions below for your respective operating system. On the day of the event, you will receive a username and password. Use these credentials when prompted by the OpenVPN client.\n\t\t- ### Windows\n\t\t\t- Download the OpenVPN client from the official website: [https://openvpn.net/community-downloads/](https://openvpn.net/community-downloads/)\n\t\t\t- Install the OpenVPN client on your laptop.\n\t\t\t- Obtain the `vpn.ovpn` file provided by the event organisers.\n\t\t\t- Launch the OpenVPN client and import the `vpn.ovpn` file.\n\t\t\t- On the day of the event, you will receive a username and password. Use these credentials to connect to the VPN.\n\t\t- ### macOS\n\t\t\t- Download the official OpenVPN Connect client from the App Store: [https://apps.apple.com/us/app/openvpn-connect/id590379981](https://apps.apple.com/us/app/openvpn-connect/id590379981)\n\t\t\t- Install the OpenVPN Connect client on your laptop.\n\t\t\t- Obtain the `vpn.ovpn` file provided by the event organisers.\n\t\t\t- Launch the OpenVPN Connect client and import the `vpn.ovpn` file.\n\t\t\t- On the day of the event, you will receive a username and password. Use these credentials to connect to the VPN.\n\t\t- ### Linux\n\t\t\t- ### GUI Tools for Connecting to OpenVPN\n\t\t\t\t- Both KDE and GNOME offer plugins for their network manager applets that allow VPN connection to an OpenVPN server. The necessary plugins are:\n\t\t\t\t\t- KDE: network-manager-openvpn-kde\n\t\t\t\t\t- GNOME: network-manager-openvpn-gnome\n\t\t\t\t\t\t- More than likely, those plugins will not be installed on the distribution by default. A quick search using the Add/Remove Software utility will allow for the installation of either plugin. Once installed, the use of the network manager applets is quite simple, just follow these steps (I will demonstrate using the KDE network manager applet):\n\t\t\t\t\t- Open up the network manager applet by clicking on the network icon in the notification area (aka System Tray.)\n\t\t\t\t\t- Click on the Manage Connections button.\n\t\t\t\t\t- Select the VPN tab.\n\t\t\t\t\t- Click the Add button to open up the VPN type drop-down.\n\t\t\t\t\t- Select OpenVPN from the list.\n\t\t\t\t\t- Fill out the necessary information on the OpenVPN tab\n\t- We look forward to seeing you at the ComfyUI for Fashion and Brands event! If you have any questions or concerns, please don't hesitate to reach out to the event organisers.\n\t- Remember to bring your laptop and a passion for fashion, innovation, and AI-driven creation. Let's push the boundaries of generative AI together!\n\t- [www.eventbrite.co.uk/e/comfy-ui-for-fashion-and-brands-tickets-894342842517](http://www.eventbrite.co.uk/e/comfy-ui-for-fashion-and-brands-tickets-894342842517)\n\t-\n\n## Current Landscape (2025)\n\n- Industry adoption and implementations\n  - Metaverse platforms continue to evolve with focus on interoperability and open standards\n  - Web3 integration accelerating with decentralised identity and asset ownership\n  - Enterprise adoption growing in virtual collaboration, training, and digital twins\n  - UK companies increasingly active in metaverse development and immersive technologies\n\n- Technical capabilities\n  - Real-time rendering at photorealistic quality levels\n  - Low-latency networking enabling seamless multi-user experiences\n  - AI-driven content generation and procedural world building\n  - Spatial audio and haptics enhancing immersion\n\n- UK and North England context\n  - Manchester: Digital Innovation Factory supports metaverse startups and research\n  - Leeds: Holovis leads in immersive experiences for entertainment and training\n  - Newcastle: University research in spatial computing and interactive systems\n  - Sheffield: Advanced manufacturing using digital twin technology\n\n- Standards and frameworks\n  - Metaverse Standards Forum driving interoperability protocols\n  - WebXR enabling browser-based immersive experiences\n  - glTF and USD for 3D asset interchange\n  - Open Metaverse Interoperability Group defining cross-platform standards\n\n## Metadata\n\n- **Last Updated**: 2025-11-16\n- **Review Status**: Automated remediation with 2025 context\n- **Verification**: Academic sources verified\n- **Regional Context**: UK/North England where applicable",
  "properties": {
    "id": "6633f4c0-358f-44cf-bf05-d43c75febe36",
    "collapsed": "true",
    "- ontology": "true",
    "- term-id": "mv-772799585390",
    "- preferred-term": "Comfy UI for Fashion and Brands",
    "- source-domain": "metaverse",
    "- status": "active",
    "- public-access": "true",
    "- definition": "A component of the metaverse ecosystem focusing on comfy ui for fashion and brands.",
    "- maturity": "mature",
    "- authority-score": "0.85",
    "- owl:class": "mv:ComfyUiForFashionAndBrands",
    "- owl:physicality": "ConceptualEntity",
    "- owl:role": "Concept",
    "- belongsToDomain": "[[MetaverseDomain]]",
    "- enables": "[[ImmersiveExperience]], [[Presence]], [[SpatialComputing]]",
    "- requires": "[[DisplayTechnology]], [[TrackingSystem]], [[RenderingEngine]]",
    "- bridges-to": "[[HumanComputerInteraction]], [[ComputerVision]], [[Robotics]]",
    "public": "true"
  },
  "backlinks": [],
  "wiki_links": [
    "ComputerVision",
    "Presence",
    "MetaverseDomain",
    "TrackingSystem",
    "Overview of Machine Learning Techniques",
    "DisplayTechnology",
    "RenderingEngine",
    "ImmersiveExperience",
    "Robotics",
    "HumanComputerInteraction",
    "SpatialComputing",
    "style transfer"
  ],
  "ontology": {
    "term_id": "mv-772799585390",
    "preferred_term": "Comfy UI for Fashion and Brands",
    "definition": "A component of the metaverse ecosystem focusing on comfy ui for fashion and brands.",
    "source_domain": "metaverse",
    "maturity_level": null,
    "authority_score": 0.85
  }
}