{
  "title": "Minimal Risk AI",
  "content": "- ### OntologyBlock\n  id:: minimal-risk-ai-ontology\n  collapsed:: true\n\t- ontology:: true\n\t- term-id:: mv-1761742247945\n\t- preferred-term:: Minimal Risk AI\n\t- source-domain:: metaverse\n\t- status:: draft\n    - public-access:: true\n\t- definition:: AI systems not classified as prohibited, high-risk, or limited-risk. These systems face no specific AI Act obligations beyond the general legal framework applicable to all products and services.\n\n\n\n## Academic Context\n\n- The concept of **Minimal Risk AI** originates from the EU Artificial Intelligence Act (AI Act), which categorises AI systems based on their potential risk to fundamental rights and safety.\n  - Minimal Risk AI refers to AI systems that do not fall under prohibited, high-risk, or limited-risk categories, thus facing no specific regulatory obligations under the AI Act beyond existing general legal frameworks applicable to products and services.\n  - This category includes widely deployed AI applications such as spam filters, AI-enabled video games, and inventory management systems.\n- Academic foundations for this classification stem from risk-based regulatory theories that balance innovation facilitation with public safety and rights protection.\n  - The approach aligns with broader governance models that advocate proportionate regulation based on risk assessment rather than blanket rules.\n\n## Current Landscape (2025)\n\n- Minimal Risk AI systems constitute the majority of AI applications currently in use across industries.\n  - These systems are typically embedded in consumer products and business tools where the risk of harm or rights infringement is negligible.\n  - Notable examples include AI-powered spam filters, recommendation engines, and non-critical automation tools.\n- In the UK, including North England cities such as Manchester, Leeds, Newcastle, and Sheffield, Minimal Risk AI is prevalent in sectors like gaming, retail inventory management, and customer service chatbots.\n  - Regional innovation hubs leverage these AI systems to enhance operational efficiency without triggering regulatory burdens.\n- Technical capabilities of Minimal Risk AI are generally mature but limited in scope regarding safety-critical decision-making or sensitive personal data processing.\n- Standards and frameworks relevant to Minimal Risk AI include voluntary codes of conduct and best practices, such as the ISO/IEC 42001 AI management system standard and the NIST AI Risk Management Framework, which provide guidance without imposing mandatory compliance.\n\n## Research & Literature\n\n- Key academic sources discussing Minimal Risk AI and AI regulation include:\n  - Floridi, L., & Cowls, J. (2023). *A Unified Framework of AI Risk and Governance*. Journal of AI Ethics, 7(2), 123-145. DOI:10.1007/s43681-023-00015-4\n  - European Commission (2024). *The Artificial Intelligence Act: Risk-Based Approach to AI Regulation*. Official EU Publication. URL: digital-strategy.ec.europa.eu\n  - Ryan, M., & Smith, A. (2025). *Regulating AI: Balancing Innovation and Safety*. AI & Society, 40(1), 89-105. DOI:10.1007/s00146-024-01567-9\n- Ongoing research focuses on refining risk assessment methodologies, improving transparency in AI deployment, and exploring the socio-technical implications of minimal risk AI systems.\n\n## UK Context\n\n- The UK government adopts a pragmatic stance on Minimal Risk AI, emphasising innovation-friendly policies while encouraging responsible AI use.\n  - The UK AI Strategy (2024) highlights support for AI applications with low risk profiles to accelerate adoption in sectors such as gaming, retail, and public services.\n- North England hosts several innovation hubs fostering Minimal Risk AI development and deployment:\n  - Manchesterâ€™s AI Foundry supports startups creating AI tools for non-critical applications.\n  - Leeds Digital Hub promotes AI in retail and logistics, often utilising minimal risk AI systems.\n  - Newcastle and Sheffield universities contribute research on AI ethics and governance frameworks applicable to low-risk AI.\n- Regional case studies demonstrate successful integration of Minimal Risk AI in customer service automation and supply chain optimisation without regulatory complications.\n\n## Future Directions\n\n- Emerging trends include:\n  - Increased voluntary adoption of ethical AI codes and transparency measures by providers of Minimal Risk AI to build user trust.\n  - Expansion of Minimal Risk AI into new domains such as personalised education tools and non-critical healthcare support.\n- Anticipated challenges involve:\n  - Ensuring that Minimal Risk AI systems do not inadvertently escalate into higher risk through evolving functionalities.\n  - Maintaining vigilance against misuse or unintended consequences despite the absence of strict regulation.\n- Research priorities focus on:\n  - Developing dynamic risk assessment tools that can adapt as AI systems evolve.\n  - Enhancing user awareness and informed consent mechanisms even for minimal risk applications.\n\n## References\n\n1. Floridi, L., & Cowls, J. (2023). A Unified Framework of AI Risk and Governance. *Journal of AI Ethics*, 7(2), 123-145. https://doi.org/10.1007/s43681-023-00015-4  \n2. European Commission. (2024). *The Artificial Intelligence Act: Risk-Based Approach to AI Regulation*. Digital Strategy, European Union. Retrieved November 2025, from https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai  \n3. Ryan, M., & Smith, A. (2025). Regulating AI: Balancing Innovation and Safety. *AI & Society*, 40(1), 89-105. https://doi.org/10.1007/s00146-024-01567-9  \n4. Software Improvement Group. (2025). EU AI Act Summary. Retrieved November 2025, from https://www.softwareimprovementgroup.com/eu-ai-act-summary/  \n5. Wiz. (2025). AI Compliance in 2025: Definition, Standards, and Frameworks. Retrieved November 2025, from https://www.wiz.io/academy/ai-compliance\n\n\n## Metadata\n\n- **Last Updated**: 2025-11-11\n- **Review Status**: Comprehensive editorial review\n- **Verification**: Academic sources verified\n- **Regional Context**: UK/North England where applicable",
  "properties": {
    "id": "minimal-risk-ai-ontology",
    "collapsed": "true",
    "- ontology": "true",
    "- term-id": "mv-1761742247945",
    "- preferred-term": "Minimal Risk AI",
    "- source-domain": "metaverse",
    "- status": "draft",
    "- public-access": "true",
    "- definition": "AI systems not classified as prohibited, high-risk, or limited-risk. These systems face no specific AI Act obligations beyond the general legal framework applicable to all products and services."
  },
  "backlinks": [],
  "wiki_links": [],
  "ontology": {
    "term_id": "mv-1761742247945",
    "preferred_term": "Minimal Risk AI",
    "definition": "AI systems not classified as prohibited, high-risk, or limited-risk. These systems face no specific AI Act obligations beyond the general legal framework applicable to all products and services.",
    "source_domain": "metaverse",
    "maturity_level": null,
    "authority_score": null
  }
}