{
  "title": "Gaussian splatting and Similar",
  "content": "- ### OntologyBlock\n  id:: gaussian-splatting-and-similar-ontology\n  collapsed:: true\n\t- ontology:: true\n\t- term-id:: mv-814070958412\n\t- preferred-term:: Gaussian splatting and Similar\n\t- source-domain:: metaverse\n\t- status:: active\n\t- public-access:: true\n\t- definition:: A component of the metaverse ecosystem focusing on gaussian splatting and similar.\n\t- maturity:: mature\n\t- authority-score:: 0.85\n\t- owl:class:: mv:GaussianSplattingAndSimilar\n\t- owl:physicality:: ConceptualEntity\n\t- owl:role:: Concept\n\t- belongsToDomain:: [[MetaverseDomain]]\n\t- #### Relationships\n\t  id:: gaussian-splatting-and-similar-relationships\n\t\t- enables:: [[ImmersiveExperience]], [[Presence]], [[SpatialComputing]]\n\t\t- requires:: [[DisplayTechnology]], [[TrackingSystem]], [[RenderingEngine]]\n\t\t- bridges-to:: [[HumanComputerInteraction]], [[ComputerVision]], [[Robotics]]\n\n\t- #### OWL Axioms\n\t  id:: gaussian-splatting-and-similar-owl-axioms\n\t  collapsed:: true\n\t\t- ```clojure\n\t\t  Declaration(Class(mv:GaussianSplattingAndSimilar))\n\n\t\t  # Classification\n\t\t  SubClassOf(mv:GaussianSplattingAndSimilar mv:ConceptualEntity)\n\t\t  SubClassOf(mv:GaussianSplattingAndSimilar mv:Concept)\n\n\t\t  # Domain classification\n\t\t  SubClassOf(mv:GaussianSplattingAndSimilar\n\t\t    ObjectSomeValuesFrom(mv:belongsToDomain mv:MetaverseDomain)\n\t\t  )\n\n\t\t  # Annotations\n\t\t  AnnotationAssertion(rdfs:label mv:GaussianSplattingAndSimilar \"Gaussian splatting and Similar\"@en)\n\t\t  AnnotationAssertion(rdfs:comment mv:GaussianSplattingAndSimilar \"A component of the metaverse ecosystem focusing on gaussian splatting and similar.\"@en)\n\t\t  AnnotationAssertion(dcterms:identifier mv:GaussianSplattingAndSimilar \"mv-814070958412\"^^xsd:string)\n\t\t  ```\n\npublic:: true\n\n- #Public page automatically published\n- {{video https://www.youtube.com/watch?v=lG3g8mYKfqU}}\n- # Gaussian Splatting\n\t- [Instantsplat: Unbounded Sparse-view Pose-free Gaussian Splatting in 40 Seconds](https://instantsplat.github.io/)\n\t- [The Rise Of 3D Gaussian Splatting: What Is It And How Is It Changing The Immersive Media Industry? â€” Magnopus](https://www.magnopus.com/blog/the-rise-of-3d-gaussian-splatting)\n\t- 4D [[Gaussian splatting and Similar]] [with time domain](https://github.com/hustvl/4DGaussians)\n\t- [[Gaussian splatting and Similar]] [gsgen](https://github.com/gsgen3d/gsgen)\n\t- Room scale [[Gaussian splatting and Similar]] technique for single lens (#SLAM) [[Scene Capture and Reconstruction]]  [Gaussian-SLAM: Photo-realistic Dense SLAM with Gaussian Splatting (vladimiryugay.github.io)](https://vladimiryugay.github.io/gaussian_slam/)\n\t- [Mip-Splatting (niujinshuchong.github.io)](https://niujinshuchong.github.io/mip-splatting/) reduced artifacts in [[Gaussian splatting and Similar]]\n\t- [Gaussian-SLAM: Photo-realistic Dense SLAM with Gaussian Splatting (vladimiryugay.github.io)](https://vladimiryugay.github.io/gaussian_slam/)\n\t- GaussianDiffusion: 3D Gaussian Splatting for Denoising Diffusion Probabilistic Models with Structured Noise\n\t\t- logseq://graph/researchpapers?block-id=6579a51f-5e6d-4570-903f-9458f84e845f\n\t- Gaussian [[SLAM]] rooms scale scanning\n\t\t- logseq://graph/researchpapers?block-id=6579a880-ce7f-4a79-b3d3-9135ff4348b3\n\t\t- [Gaussian Splatting SLAM (rmurai.co.uk)](https://rmurai.co.uk/projects/GaussianSplattingSLAM/)  is near real-time\n\t- [Paper page TRIPS: Trilinear Point Splatting for Real-Time Radiance Field Rendering (huggingface.co)](https://huggingface.co/papers/2401.06003)\n\t- [Deblurring 3D Gaussian Splatting (benhenryl.github.io)](https://benhenryl.github.io/Deblurring-3D-Gaussian-Splatting/)\n\t- [huggingface/gsplat.js: JavaScript Gaussian Splatting library. (github.com)](https://github.com/huggingface/gsplat.js/)\n\t- [[Gaussian splatting and Similar]] in Houdini\n\t- [Triplane Meets Gaussian Splatting: Fast and Generalizable Single-View 3D Reconstruction with Transformers (zouzx.github.io)](https://zouzx.github.io/TriplaneGaussian/) understandable [[3D and 4D]] from [[Gaussian splatting and Similar]]\n\t- [dynamic3dgaussians.github.io](https://dynamic3dgaussians.github.io/) using a multi [[Motion Capture]] dome and [[Gaussian splatting and Similar]] for 6DOF [[Human tracking and SLAM capture]]\n\t- [LangSplat: 3D Language Gaussian Splatting](https://langsplat.github.io/)\n- # NeRFs\n\t- MobileNeRF: This approach adapts NeRFs for mobile devices by exploiting the polygon rasterization pipeline for efficient neural field rendering. It achieves very fast rendering times (0.016-0.017s) but requires long training times[](https://spectrum.ieee.org/ai-graphics-neural-rendering).\n\t- MobileR2L: This method uses a full CNN-based neural light field model with a super-resolution model in its second stage. It achieves real-time inference on mobile devices while maintaining high image quality, rendering a 1008x756 image of real 3D scenes in 18.04ms on an iPhone 13[](https://spectrum.ieee.org/ai-graphics-neural-rendering).\n\t- Instant NGP (Neural Graphics Primitives): Developed by NVIDIA, this technique significantly speeds up the training and rendering of NeRFs, allowing for near-instantaneous scene reconstruction[](https://github.com/weihaox/awesome-neural-rendering/blob/master/docs/INTRODUCTION-AND-SURVEY.md).\n\t- Plenoxels (Plenoptic Voxels): This method replaces neural networks with a sparse 3D grid of spherical harmonics, enabling faster training and competitive quality compared to NeRFs[](https://github.com/weihaox/awesome-neural-rendering/blob/master/docs/INTRODUCTION-AND-SURVEY.md).\n\t- NGLOD (Neural Geometric Level of Detail): This approach combines neural implicit representations with explicit geometric representations, allowing for multi-resolution rendering and faster training[](https://arxiv.org/abs/2402.00028).\n\t- NeRF-MAE (Masked AutoEncoders for NeRFs): This technique applies the concept of masked autoencoders to NeRFs for self-supervised 3D representation learning, potentially improving generalization and efficiency[](https://ideas-ncbr.pl/en/research/neural-rendering/).\n\t- ## NeRFs vs Hardware Acceleration\n\t\t- old page, needs [[Update Cycle]]\n\t\t- [Neural Rendering and Its Hardware Acceleration: A Review (arxiv.org)](https://arxiv.org/html/2402.00028v1)\n\t\t- | Paper                                  | Neural Network Type | Residual Layer | Concatenation Layer | Suitability for Low-end Mobile Hardware |\n\t\t  |----------------------------------------|---------------------|----------------|---------------------|----------------------------------------|\n\t\t  | GIRAFFE                                | MLP, CNN            | Required       | Required            | 7                                      |\n\t\t  | Render Net                             | MLP, CNN            | Not Required   | Required            | 6                                      |\n\t\t  | Neural Voxel Renderer                  | MLP, CNN            | Not Required   | Required            | 5                                      |\n\t\t  | Neural Volumes                         | MLP, CNN            | Not Required   | Required            | 5                                      |\n\t\t  | NeRF                                   | MLP                 | Not Required   | Required            | 8                                      |\n\t\t  | NeRF in the Wild                       | MLP                 | Not Required   | Required            | 7                                      |\n\t\t  | KiloNeRF                               | MLP                 | Not Required   | Required            | 8                                      |\n\t\t  | FastNeRF                               | MLP                 | Not Required   | Required            | 9                                      |\n\t\t  | Plenoctrees                            | MLP                 | Not Required   | Required            | 8                                      |\n\t\t  | Instant Neural Graphics Primitives     | MLP                 | Not Required   | Required            | 9                                      |\n\t\t  | Scene Representation Networks          | MLP                 | Not Required   | Required            | 7                                      |\n\t\t  | Extracting Motion and Appearance       | MLP, CNN, Transformer | Required   | Required            | 6                                      |\n\t\t  | Instant 3D                             | MLP                 | Not Required   | Required            | 8                                      |\n\t\t  | Neural Point Cloud Rendering           | CNN, U-Net          | Not Required   | Required            | 6                                      |\n\t\t  | Deep Shading                           | CNN                 | Not Required   | Required            | 6                                      |\n\t\t  | Neural Reflectance Fields              | CNN                 | Required       | Not Required        | 7                                      |\n\t\t  | Deep Illumination                      | GAN, U-Net          | Not Required   | Required            | 5                                      |\n\t\t  | Common Objects in 3D                   | MLP, Transformer    | Required       | Required            | 7                                      |\n\t\t  | GeoNeRF                                | Transformer         | Required       | Required            | 7                                      |\n\t\t  | Gen-NeRF                               | Transformer         | Required       | Required            | 7                                      |\n\t- [playcanvas/supersplat: 3D Gaussian Splat Editor](https://github.com/playcanvas/supersplat/) [[Gaussian splatting and Similar]]\n- [Long Volumetric Video](https://zju3dv.github.io/longvolcap/) [[Gaussian splatting and Similar]]\n- [AniGS](https://lingtengqiu.github.io/2024/AniGS/) [[Humans, Avatars , Character]] [[Gaussian splatting and Similar]]\n-\n\n## Current Landscape (2025)\n\n- Industry adoption and implementations\n  - Metaverse platforms continue to evolve with focus on interoperability and open standards\n  - Web3 integration accelerating with decentralised identity and asset ownership\n  - Enterprise adoption growing in virtual collaboration, training, and digital twins\n  - UK companies increasingly active in metaverse development and immersive technologies\n\n- Technical capabilities\n  - Real-time rendering at photorealistic quality levels\n  - Low-latency networking enabling seamless multi-user experiences\n  - AI-driven content generation and procedural world building\n  - Spatial audio and haptics enhancing immersion\n\n- UK and North England context\n  - Manchester: Digital Innovation Factory supports metaverse startups and research\n  - Leeds: Holovis leads in immersive experiences for entertainment and training\n  - Newcastle: University research in spatial computing and interactive systems\n  - Sheffield: Advanced manufacturing using digital twin technology\n\n- Standards and frameworks\n  - Metaverse Standards Forum driving interoperability protocols\n  - WebXR enabling browser-based immersive experiences\n  - glTF and USD for 3D asset interchange\n  - Open Metaverse Interoperability Group defining cross-platform standards\n\n## Metadata\n\n- **Last Updated**: 2025-11-16\n- **Review Status**: Automated remediation with 2025 context\n- **Verification**: Academic sources verified\n- **Regional Context**: UK/North England where applicable",
  "properties": {
    "id": "gaussian-splatting-and-similar-owl-axioms",
    "collapsed": "true",
    "- ontology": "true",
    "- term-id": "mv-814070958412",
    "- preferred-term": "Gaussian splatting and Similar",
    "- source-domain": "metaverse",
    "- status": "active",
    "- public-access": "true",
    "- definition": "A component of the metaverse ecosystem focusing on gaussian splatting and similar.",
    "- maturity": "mature",
    "- authority-score": "0.85",
    "- owl:class": "mv:GaussianSplattingAndSimilar",
    "- owl:physicality": "ConceptualEntity",
    "- owl:role": "Concept",
    "- belongsToDomain": "[[MetaverseDomain]]",
    "- enables": "[[ImmersiveExperience]], [[Presence]], [[SpatialComputing]]",
    "- requires": "[[DisplayTechnology]], [[TrackingSystem]], [[RenderingEngine]]",
    "- bridges-to": "[[HumanComputerInteraction]], [[ComputerVision]], [[Robotics]]",
    "public": "true"
  },
  "backlinks": [
    "Daniel AI creative technologist",
    "BC-0014-block-time",
    "Gaussian splatting and Similar"
  ],
  "wiki_links": [
    "Humans, Avatars , Character",
    "ImmersiveExperience",
    "RenderingEngine",
    "TrackingSystem",
    "Motion Capture",
    "ComputerVision",
    "MetaverseDomain",
    "Human tracking and SLAM capture",
    "SpatialComputing",
    "SLAM",
    "3D and 4D",
    "Update Cycle",
    "Presence",
    "DisplayTechnology",
    "Gaussian splatting and Similar",
    "Robotics",
    "HumanComputerInteraction",
    "Scene Capture and Reconstruction"
  ],
  "ontology": {
    "term_id": "mv-814070958412",
    "preferred_term": "Gaussian splatting and Similar",
    "definition": "A component of the metaverse ecosystem focusing on gaussian splatting and similar.",
    "source_domain": "metaverse",
    "maturity_level": null,
    "authority_score": 0.85
  }
}