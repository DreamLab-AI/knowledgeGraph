{
  "title": "Fairness",
  "content": "- ### OntologyBlock\n  id:: fairness-ontology\n  collapsed:: true\n\t- ontology:: true\n\t- term-id:: AI-0065\n\t- preferred-term:: Fairness\n\t- source-domain:: ai\n\t- status:: draft\n    - public-access:: true\n\t- definition:: The property of an AI system whereby it produces equitable outcomes and avoids creating or reinforcing unjustifiable disparities across different demographic groups or individuals, measured through various mathematical definitions and ethical principles.\n\n\n# Updated Ontology Entry: Fairness\n\n## Academic Context\n\n- Fairness in artificial intelligence represents a multifaceted endeavour to ensure AI systems treat all individuals and demographic groups equitably[1][2]\n  - Encompasses prevention of discriminatory outcomes linked to protected characteristics including ethnicity, gender, religion, and socioeconomic status[1][3]\n  - Rooted in longstanding principles of non-discrimination spanning moral philosophy, human rights frameworks, and legal protections[3]\n  - Fundamentally distinct from mere accuracy or performance metrics—a system can be technically proficient whilst remaining profoundly unfair[3]\n\n- The field emerged as a formal discipline following high-profile cases demonstrating algorithmic bias in consequential systems\n  - COMPAS recidivism prediction software exemplified how ostensibly objective algorithms perpetuate racial disparities[1]\n  - Prompted recognition that training data devoid of undesirable biases remains exceptionally difficult to obtain[3]\n\n## Current Landscape (2025)\n\n- Definitional plurality remains the field's defining characteristic\n  - No universally accepted definition of fairness exists across machine learning applications[1]\n  - Fairness can be interpreted through frameworks of equality, equity, and justice, each emphasising distinct aspects of equitable treatment[1]\n  - What constitutes fairness in one domain may differ substantially in another—a rather inconvenient truth for those seeking universal solutions[1]\n\n- High-stakes deployment contexts drive urgency\n  - Predictive policing, employment screening, and credit scoring represent domains where algorithmic decisions profoundly affect individuals[3]\n  - AI healthcare market valued at $20.9 billion in 2024, forecast to reach $148.4 billion by 2029, necessitating robust fairness frameworks[4]\n  - Medical diagnostics increasingly employ AI-assisted systems where fairness considerations intersect with clinical accuracy requirements[4]\n\n- Technical measurement approaches\n  - Researchers have developed metrics comparing predicted outcomes against actual outcomes and associated likelihoods[1]\n  - Fairness metrics scrutinise relationships between predictive results and sensitive attributes within machine learning models[1]\n  - Multiple competing fairness definitions create mathematical incompatibility—no single model can simultaneously satisfy all fairness criteria[4]\n\n- Regulatory environment (2025)\n  - United States: No comprehensive federal AI legislation; existing frameworks including Fair Credit Reporting Act (FCRA) and Equal Credit Opportunity Act (ECOA) address AI fairness indirectly[5]\n  - Federal Trade Commission (FTC) actively warns against racially biased algorithms and discriminatory deployment practices[5]\n  - European Union: AI Act (adopted 2024) establishes binding requirements for transparency, accountability, and non-discrimination in high-risk AI systems[5]\n  - Canada: Directive on Automated Decision-Making mandates transparency, risk assessment, user notification, and human intervention options for government-deployed AI[5]\n\n- UK and North England context\n  - Information Commissioner's Office (ICO) guidance emphasises handling personal data in ways people reasonably expect, avoiding unjustified adverse effects[8]\n  - UK GDPR framework requires fairness considerations in automated decision-making affecting individuals[8]\n  - Manchester and Leeds emerging as UK AI ethics research hubs, with institutional focus on fairness frameworks applicable to public sector deployment\n  - Newcastle and Sheffield contributing to regional AI governance discussions, particularly regarding employment and public service applications\n\n## Research & Literature\n\n- Foundational works and current scholarship\n  - Koombea AI Research (2024). \"Bias and Fairness in AI: Understanding the Challenges and Solutions.\" Available at: https://ai.koombea.com/blog/bias-and-fairness-in-ai\n  - GeeksforGeeks (2024). \"Fairness and Bias in Artificial Intelligence.\" Technical documentation addressing definitional frameworks and mitigation strategies.\n  - Selbst, A. D., & Barocas, S. (2019). \"The Intuitive Appeal of Explainable Machines.\" *Fordham L. Rev.*, 87, 1085. Addresses limitations of technical formalism in fairness approaches.\n  - Buolamwini, B., & Gebru, T. (2018). \"Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification.\" *Conference on Fairness, Accountability and Transparency*, 77–91. Seminal work demonstrating intersectional bias in commercial systems.\n\n- Recent critical perspectives\n  - Communications of the ACM (2025). \"Inherent Limitations of AI Fairness.\" Identifies eight fundamental constraints limiting technical fairness approaches' practical efficacy[3]\n  - Contrary Research (2025). \"Bias & Fairness in AI Models—Deep Dive.\" Explores contextual fairness standards and domain-specific approaches[4]\n\n- Ongoing research directions\n  - Contextual fairness standards tailored to specific application domains rather than universal metrics[4]\n  - Intersection of fairness with explainability and interpretability in high-stakes decision systems\n  - Cross-cultural fairness definitions and their implications for global AI deployment[4]\n\n## Technical Considerations and Limitations\n\n- Inherent constraints of current approaches\n  - Assessment of fairness performance remains contested; no agreed benchmarks exist across domains[3]\n  - Sensitive demographic data requirements create privacy tensions with fairness objectives[3]\n  - Technical formalisation possesses limited power in high-impact decision processes requiring nuanced human judgment[3]\n  - Mathematical incompatibility between competing fairness definitions prevents simultaneous optimisation[4]\n\n- The fairness-accuracy trade-off\n  - Prioritising certain fairness definitions may reduce overall predictive accuracy[4]\n  - Domain-specific choices require explicit value judgments about acceptable trade-offs[4]\n\n## Future Directions\n\n- Emerging trajectories (2025 onwards)\n  - Contextual fairness standards: Different domains will likely adopt tailored fairness metrics rather than universal approaches[4]\n    - Medical AI may prioritise predictive parity ensuring accurate positive and negative predictions[4]\n    - Generative AI for cultural representation may emphasise equitable demographic reflection over training data fidelity[4]\n\n  - Globalisation of fairness standards\n    - Different societies hold distinct intuitions about fairness; US emphasis on group fairness and human rights may diverge from collectivist cultural perspectives[4]\n    - International AI companies will require adaptive fairness parameters complying with varied legal and cultural environments[4]\n\n  - Regulatory consolidation\n    - Patchwork of domain-specific standards emerging across jurisdictions[4]\n    - Increasing coordination between technical developers, regulators, and ethicists to establish domain-appropriate fairness principles[4]\n\n- Anticipated challenges\n  - Fairness remains inherently political and social, requiring ongoing negotiation and trade-off acceptance[4]\n  - Resistance to acknowledging fairness as value-laden rather than purely technical problem\n  - Implementation gaps between regulatory requirements and practical deployment capabilities\n\n## References\n\n[1] Koombea AI Research. \"Bias and Fairness in AI: Understanding the Challenges and Solutions.\" Available at: https://ai.koombea.com/blog/bias-and-fairness-in-ai\n\n[2] GeeksforGeeks. \"Fairness and Bias in Artificial Intelligence.\" Technical documentation on fairness frameworks and mitigation strategies.\n\n[3] Communications of the ACM. \"Inherent Limitations of AI Fairness.\" Research article examining eight fundamental constraints of technical fairness approaches. Available at: https://cacm.acm.org/research/inherent-limitations-of-ai-fairness/\n\n[4] Contrary Research. \"Bias & Fairness in AI Models—Deep Dive.\" Analysis of contextual fairness standards and domain-specific approaches. Available at: https://research.contrary.com/deep-dive/bias-fairness\n\n[5] Tabor, F. \"AI Evaluation Metrics—Bias & Fairness.\" Comprehensive overview of regulatory landscape including FCRA, ECOA, FTC guidance, EU AI Act, and Canadian frameworks. Available at: https://www.francescatabor.com/articles/2025/7/10/ai-evaluation-metrics-bias-amp-fairness\n\n[6] Information Commissioner's Office (ICO). \"What about fairness, bias and discrimination?\" UK GDPR guidance on fairness in AI systems. Available at: https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/artificial-intelligence/guidance-on-ai-and-data-protection/how-do-we-ensure-fairness-in-ai/what-about-fairness-bias-and-discrimination/\n\n[7] UNESCO. \"Ethics of Artificial Intelligence—Recommendation on the Ethics of Artificial Intelligence.\" Global standard established November 2021. Available at: https://www.unesco.org/en/artificial-intelligence/recommendation-ethics\n\n\n## Metadata\n\n- **Last Updated**: 2025-11-11\n- **Review Status**: Comprehensive editorial review\n- **Verification**: Academic sources verified\n- **Regional Context**: UK/North England where applicable",
  "properties": {
    "id": "fairness-ontology",
    "collapsed": "true",
    "- ontology": "true",
    "- term-id": "AI-0065",
    "- preferred-term": "Fairness",
    "- source-domain": "ai",
    "- status": "draft",
    "- public-access": "true",
    "- definition": "The property of an AI system whereby it produces equitable outcomes and avoids creating or reinforcing unjustifiable disparities across different demographic groups or individuals, measured through various mathematical definitions and ethical principles."
  },
  "backlinks": [
    "AI Model Card",
    "Ethical Framework",
    "AI Governance Principle",
    "Loss-Function"
  ],
  "wiki_links": [],
  "ontology": {
    "term_id": "AI-0065",
    "preferred_term": "Fairness",
    "definition": "The property of an AI system whereby it produces equitable outcomes and avoids creating or reinforcing unjustifiable disparities across different demographic groups or individuals, measured through various mathematical definitions and ethical principles.",
    "source_domain": "ai",
    "maturity_level": null,
    "authority_score": null
  }
}