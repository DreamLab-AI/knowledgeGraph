{
  "title": "Parametric",
  "content": "- ### OntologyBlock\n  id:: parametric-ontology\n  collapsed:: true\n\t- ontology:: true\n\t- term-id:: mv-253488174637\n\t- preferred-term:: Parametric\n\t- source-domain:: metaverse\n\t- status:: active\n\t- public-access:: true\n\t- definition:: A component of the metaverse ecosystem focusing on parametric.\n\t- maturity:: mature\n\t- authority-score:: 0.85\n\t- owl:class:: mv:Parametric\n\t- owl:physicality:: ConceptualEntity\n\t- owl:role:: Concept\n\t- belongsToDomain:: [[MetaverseDomain]]\n\t- #### Relationships\n\t  id:: parametric-relationships\n\t\t- enables:: [[ImmersiveExperience]], [[Presence]], [[SpatialComputing]]\n\t\t- requires:: [[DisplayTechnology]], [[TrackingSystem]], [[RenderingEngine]]\n\t\t- bridges-to:: [[HumanComputerInteraction]], [[ComputerVision]], [[Robotics]]\n\n\t- #### OWL Axioms\n\t  id:: parametric-owl-axioms\n\t  collapsed:: true\n\t\t- ```clojure\n\t\t  Declaration(Class(mv:Parametric))\n\n\t\t  # Classification\n\t\t  SubClassOf(mv:Parametric mv:ConceptualEntity)\n\t\t  SubClassOf(mv:Parametric mv:Concept)\n\n\t\t  # Domain classification\n\t\t  SubClassOf(mv:Parametric\n\t\t    ObjectSomeValuesFrom(mv:belongsToDomain mv:MetaverseDomain)\n\t\t  )\n\n\t\t  # Annotations\n\t\t  AnnotationAssertion(rdfs:label mv:Parametric \"Parametric\"@en)\n\t\t  AnnotationAssertion(rdfs:comment mv:Parametric \"A component of the metaverse ecosystem focusing on parametric.\"@en)\n\t\t  AnnotationAssertion(dcterms:identifier mv:Parametric \"mv-253488174637\"^^xsd:string)\n\t\t  ```\n\npublic:: true\n\n- ![BB1mNtGj.jpeg](../assets/BB1mNtGj_1716451730618_0.jpeg)\n- Microsoft are bringing parametric (volume) design to Meta Quest.\n\t- Microsoft is integrating parametric (volume) design capabilities into the Meta Quest platform, enhancing the expressivity of interfaces focused on retrieving and customizing artifacts through extended reality. This approach leverages parametric designs to simplify and streamline the design process, situating relevant design efforts within the usage context and embedding domain knowledge in the system. The integration aims to make design variations effortless, aligning with the concept of in-situ interaction with parametric designs, as described by Mario Carpo, where primary authors design generic objects, and secondary authors or interactors adapt variable aspects of the original notation at will.\n\t- #\n\n## Current Landscape (2025)\n\n- Industry adoption and implementations\n  - Metaverse platforms continue to evolve with focus on interoperability and open standards\n  - Web3 integration accelerating with decentralised identity and asset ownership\n  - Enterprise adoption growing in virtual collaboration, training, and digital twins\n  - UK companies increasingly active in metaverse development and immersive technologies\n\n- Technical capabilities\n  - Real-time rendering at photorealistic quality levels\n  - Low-latency networking enabling seamless multi-user experiences\n  - AI-driven content generation and procedural world building\n  - Spatial audio and haptics enhancing immersion\n\n- UK and North England context\n  - Manchester: Digital Innovation Factory supports metaverse startups and research\n  - Leeds: Holovis leads in immersive experiences for entertainment and training\n  - Newcastle: University research in spatial computing and interactive systems\n  - Sheffield: Advanced manufacturing using digital twin technology\n\n- Standards and frameworks\n  - Metaverse Standards Forum driving interoperability protocols\n  - WebXR enabling browser-based immersive experiences\n  - glTF and USD for 3D asset interchange\n  - Open Metaverse Interoperability Group defining cross-platform standards\n\n## Metadata\n\n- **Last Updated**: 2025-11-16\n- **Review Status**: Automated remediation with 2025 context\n- **Verification**: Academic sources verified\n- **Regional Context**: UK/North England where applicable\n\n\n## References:\n\t\t- Stemasov, A. pARam: Leveraging Parametric Design in Extended Reality to Enhance Expressivity. ACM CHI 2024. Available online:\n\t\t- [https://stemasov.dev/papers/stemasov-acm_chi_2024-param.pdf](https://stemasov.dev/papers/stemasov-acm_chi_2024-param.pdf)\n\t- # Overview\n\t  \n\t   - Voice and text to parametric CAD primitives and larger digital twin models, in shared virtual spaces, is an essential feature for the commercial metaverse. This integration is already evident in current virtual reality and augmented reality applications, enabling users to manipulate and interact with 3D objects in real-time, bridging the gap between the physical and digital worlds.\n\t  \n\t  As the metaverse continues to evolve, the integration of voice and text input will play a crucial role in enhancing the overall user experience. For instance, users can verbally command a virtual design software to create specific CAD primitives or modify existing models. Additionally, the ability to add text annotations or descriptions directly within the virtual space can facilitate collaboration and communication among users.\n\t  \n\t  The expansion of corporate metaverse platforms like [[NVIDIA Omniverse]] will make shared virtual spaces increasingly complex and vast, accommodating a multitude of digital twin models. This means users will be able to explore and interact with realistic replicas of real-world objects and environments, such as buildings, vehicles, or even entire cities.\n\t  \n\t  By incorporating voice and text input functionalities, developers can empower users to manipulate and navigate these digital twin models more intuitively. Whether it's adjusting the dimensions of a virtual prototype or performing intricate measurements, the metaverse's ability to recognize and respond to voice and text commands will revolutionize the way we design, simulate, and experience virtual environments.\n\t- ## Key Technologies and Tools\n\t- **AI-Driven NLP**: AI-driven natural language processing (NLP) facilitates communication within the metaverse, enabling users to talk with virtual entities or other users using voice or text. This enhances user experience and interaction, as seen in platforms like [[NVIDIA Omniverse]] and [[Landvault Create]] which leverage AI for efficient content creation and customization of avatars and environments.\n\t- **Digital Twins**: Digital twins are virtual models of real-world processes and systems used to anticipate issues in supply chains and equipment maintenance. They are essential for immersive, data-driven, and dynamic environments in the metaverse, supporting virtual prototyping, design analysis, and real-time equipment issue diagnosis.\n\t- **Generative AI**: Generative adversarial networks (GANs) and procedural content generation tools automate the creation of complex textures, models, and landscapes in the metaverse. These tools streamline asset creation, audio generation, and environment generation, making the design process more efficient and creative.\n\t- ## Future Developments\n\t  \n\t  The integration of voice and text input into the metaverse will continue to evolve with advancements in AI, NLP, and digital twin technology. As platforms like [[NVIDIA Omniverse]] expand, users will have more intuitive tools to manipulate and interact with digital twin models, enhancing collaboration and innovation in various sectors including gaming, education, retail, and real estate.\n\t- ### Citations https://landvault.io/blog/how-the-metaverse-can-leverage-ai https://ventionteams.com/blog/metaverse-tech-stack https://dl.acm.org/doi/10.1145/3581783.3613432\n- # Overview\n\t- Voice and text to parametric CAD primitives and larger digital twin models, in shared virtual spaces is an important and necessary feature for commercial metaverse. We can already see examples and hints of this in current virtual reality and augmented reality applications.\n\t- These technologies enable users to manipulate and interact with 3D objects in real-time, bridging the gap between the physical and digital worlds. As the metaverse continues to evolve, the integration of voice and text input will undoubtedly play a crucial role in enhancing the overall user experience.\n\t- Imagine being able to verbally command a virtual design software to create specific CAD primitives or modify existing models. Additionally, the ability to add text annotations or descriptions directly within the virtual space can facilitate collaboration and communication among users.\n\t- Furthermore, as corporate metaverse like [[NVIDIA Omniverse]] expands, the shared virtual spaces will become increasingly complex and vast, accommodating a multitude of digital twin models. This means that users will be able to explore and interact with realistic replicas of real-world objects and environments, such as buildings, vehicles, or even entire cities.\n\t- By incorporating voice and text input functionalities, developers can empower users to manipulate and navigate these digital twin models more intuitively. Whether it's adjusting the dimensions of a virtual prototype or performing intricate measurements, the metaverse's ability to recognize and respond to voice and text commands will revolutionize the way we design, simulate, and experience virtual environments.\n- [Table Of Contents — bd_warehouse \"0.1.0\" # Uncomment this for the next release? documentation (bd-warehouse.readthedocs.io)](https://bd-warehouse.readthedocs.io/en/latest/)\n- [Latest General topics\n\t- neThing.xyz Community Forum](https://forum.nething.xyz/c/general/4)\n-\n- # Examples\n\t- <iframe src=\"https://nething.xyz/\" style=\"width: 100%; height: 600px\"></iframe>\n\t- {{video https://www.youtube.com/watch?v=Ey2YqyPYBSU&}}\n-",
  "properties": {
    "id": "parametric-owl-axioms",
    "collapsed": "true",
    "- ontology": "true",
    "- term-id": "mv-253488174637",
    "- preferred-term": "Parametric",
    "- source-domain": "metaverse",
    "- status": "active",
    "- public-access": "true",
    "- definition": "A component of the metaverse ecosystem focusing on parametric.",
    "- maturity": "mature",
    "- authority-score": "0.85",
    "- owl:class": "mv:Parametric",
    "- owl:physicality": "ConceptualEntity",
    "- owl:role": "Concept",
    "- belongsToDomain": "[[MetaverseDomain]]",
    "- enables": "[[ImmersiveExperience]], [[Presence]], [[SpatialComputing]]",
    "- requires": "[[DisplayTechnology]], [[TrackingSystem]], [[RenderingEngine]]",
    "- bridges-to": "[[HumanComputerInteraction]], [[ComputerVision]], [[Robotics]]",
    "public": "true"
  },
  "backlinks": [],
  "wiki_links": [
    "ComputerVision",
    "Presence",
    "MetaverseDomain",
    "TrackingSystem",
    "DisplayTechnology",
    "RenderingEngine",
    "ImmersiveExperience",
    "Robotics",
    "Landvault Create",
    "HumanComputerInteraction",
    "NVIDIA Omniverse",
    "SpatialComputing"
  ],
  "ontology": {
    "term_id": "mv-253488174637",
    "preferred_term": "Parametric",
    "definition": "A component of the metaverse ecosystem focusing on parametric.",
    "source_domain": "metaverse",
    "maturity_level": null,
    "authority_score": 0.85
  }
}