{
  "title": "üì∫¬†Youtube channels",
  "content": "- ### OntologyBlock\n  id:: üì∫¬†youtube-channels-ontology\n  collapsed:: true\n\t- ontology:: true\n\t- term-id:: mv-283942073263\n\t- preferred-term:: üì∫¬†Youtube channels\n\t- source-domain:: metaverse\n\t- status:: active\n\t- public-access:: true\n\t- definition:: A component of the metaverse ecosystem focusing on üì∫¬†youtube channels.\n\t- maturity:: mature\n\t- authority-score:: 0.85\n\t- owl:class:: mv:YoutubeChannels\n\t- owl:physicality:: ConceptualEntity\n\t- owl:role:: Concept\n\t- belongsToDomain:: [[MetaverseDomain]]\n\t- #### Relationships\n\t  id:: üì∫¬†youtube-channels-relationships\n\t\t- enables:: [[ImmersiveExperience]], [[Presence]], [[SpatialComputing]]\n\t\t- requires:: [[DisplayTechnology]], [[TrackingSystem]], [[RenderingEngine]]\n\t\t- bridges-to:: [[HumanComputerInteraction]], [[ComputerVision]], [[Robotics]]\n\n\t- #### OWL Axioms\n\t  id:: üì∫¬†youtube-channels-owl-axioms\n\t  collapsed:: true\n\t\t- ```clojure\n\t\t  Declaration(Class(mv:YoutubeChannels))\n\n\t\t  # Classification\n\t\t  SubClassOf(mv:YoutubeChannels mv:ConceptualEntity)\n\t\t  SubClassOf(mv:YoutubeChannels mv:Concept)\n\n\t\t  # Domain classification\n\t\t  SubClassOf(mv:YoutubeChannels\n\t\t    ObjectSomeValuesFrom(mv:belongsToDomain mv:MetaverseDomain)\n\t\t  )\n\n\t\t  # Annotations\n\t\t  AnnotationAssertion(rdfs:label mv:YoutubeChannels \"üì∫¬†Youtube channels\"@en)\n\t\t  AnnotationAssertion(rdfs:comment mv:YoutubeChannels \"A component of the metaverse ecosystem focusing on üì∫¬†youtube channels.\"@en)\n\t\t  AnnotationAssertion(dcterms:identifier mv:YoutubeChannels \"mv-283942073263\"^^xsd:string)\n\t\t  ```\n\n# üì∫¬†Youtube channels\n\nThis is a list of all the youtube videos which have contributed to my current interest in machine learning. Some of them go back years like [CGP Grey](https://www.notion.so/LLM-resources-fe118332b84f49c286b8045922c7f5a2?pvs=21), [Computerphile](https://www.notion.so/LLM-resources-fe118332b84f49c286b8045922c7f5a2?pvs=21), [Robert Miles](https://www.notion.so/LLM-resources-fe118332b84f49c286b8045922c7f5a2?pvs=21) and [3Blue1Brown](https://www.notion.so/LLM-resources-fe118332b84f49c286b8045922c7f5a2?pvs=21) whereas the rest are ~1 year but these are channels I keep coming back to over and over again because they‚Äôre extremely interesting and don‚Äôt feel like a class.\n- ### [CGP Grey](https://www.youtube.com/@CGPGrey)\n  \n  Probably one of my all time favourite youtube channels of all time. I watched his video [Humans need not apply](https://www.youtube.com/watch?v=7Pq-S557XQU) back in 2014 and it was the reason why I wanted to go into computer programming. His explanations on How Machines Learn which was released 6 years ago (renamed to ‚Äú[How AIs, like ChatGPT, Learn](https://www.youtube.com/watch?v=R9OHn5ZF4Uo)‚Äù in 2023) is the best beginner video that exists on the topic and I think everyone should watch. These two videos you should send to your parents when they‚Äôre asking about ‚ÄúAll this AI stuff‚Äù.\n- ### [Computerphile](https://www.youtube.com/@Computerphile)\n  \n  [Computerphile](https://www.youtube.com/@Computerphile), [Numberphile](https://www.youtube.com/@numberphile) and [Sixty Symbols](https://www.youtube.com/@sixtysymbols) created by [Brady Haran](http://www.bradyharan.com/) are also what got me interested in STEM around 10 years ago.\n  \n  The videos from [Mike Pound](https://www.youtube.com/watch?v=NxYEzbbpk-4&list=PLzH6n4zXuckpfMu_4Ff8E7Z1behQks5ba) and [Robert Miles](https://www.youtube.com/watch?v=tlS5Y2vm02c&list=PLzH6n4zXuckquVnQ0KlMDxyT5YE-sA8Ps) are great, and were my introduction to data analysis, ML, and AI.\n  \n  #TimsForLife\n-\n- ### [3Blue1Brown](https://www.youtube.com/@3blue1brown)\n  \n  3Blue1Brown has the best math educational content that exists. Grant is the reason why I passed any of my math courses in university.\n- [**Essence of linear algebra**](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)\n- [**Neural Networks](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) - Recently added a two videos [explaining transformers](https://www.youtube.com/watch?v=wjZofJX0v4M&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=5)**\n  \n  Grant‚Äôs [manim graphing library for python](https://github.com/3b1b/manim) (which also has a [community fork](https://www.manim.community/)) is also pretty important for STEM communication, and I‚Äôm planning on using it if I get to the data visualisation phase.\n- ### [Andrej Karpathy](https://www.youtube.com/@AndrejKarpathy)\n  \n  Probably one of the most important people in the field at the moment. His zero to hero playlist takes you through concrete examples and is really democratising language models through education: [ttps://karpathy.ai/zero-to-hero.html](https://karpathy.ai/zero-to-hero.html)\n  \n  Anrej's blogpost on [software 2.0](https://karpathy.medium.com/software-2-0-a64152b37c35) also holds up to reality pretty well and I think something similar is going to be where all software engineering is headed.\n  \n  I ported his project [llm.c](https://github.com/karpathy/llm.c/) to Go [https://github.com/joshcarp/llm.go](https://github.com/joshcarp/llm.go) and this is when everything really started to click for me. There‚Äôs also a history of this occurring with his project [llama2.c](https://github.com/karpathy/llama2.c) being forked into [llama.cpp](https://github.com/ggerganov/llama.cpp), which is currently the fastest and most optimised open source LLM runtime which many, many other projects rely on including [ollama](https://ollama.com/), [llamafile](https://ollama.com/), and [localllm](https://github.com/GoogleCloudPlatform/localllm) and many, many more.\n  \n  [The current work](https://github.com/karpathy/llm.c/discussions/481) he‚Äôs doing on creating a highly optimised library in [https://github.com/karpathy/llm.c/](https://github.com/karpathy/llm.c/) is fascinating, and recently the project was able to get to 29.3% on the [Hellaswag](https://arxiv.org/abs/1905.07830) benchmark with $20 of training, where the GPT-3 small model (124M) got 33%.\n- ### [Machine Learning Street Talk](https://www.youtube.com/@MachineLearningStreetTalk)\n  \n  A great technical podcast which interviews a very, very diverse set of people in the machine learning field. Some of my favourite episodes are:\n- [**This is why Deep Learning is really weird](https://www.youtube.com/watch?v=sJXn4Cl4oww) -** This is where I discovered the [Understanding Deep Learning textbook](https://www.notion.so/LLM-resources-fe118332b84f49c286b8045922c7f5a2?pvs=21)\n- [**ROBERT MILES - \"There is a good chance this kills everyone\"](https://www.youtube.com/watch?v=kMLKbhY0ji0&t=5437s) -** More Robert Miles Content is always good.\n- [**WE MUST ADD STRUCTURE TO DEEP LEARNING BECAUSE‚Ä¶](https://www.youtube.com/watch?v=rie-9AEhYdY) -** This is a category theory approach to LLM architecture. I find this quite interesting as I feel like a lot of the [category theory](https://www.notion.so/LLM-resources-fe118332b84f49c286b8045922c7f5a2?pvs=21) has been powerful but the cost benefit analysis didn‚Äôt favour being smart and formal about abstractions. IMO what we‚Äôve got today in the abstractions that we build as software engineers are often just throwing spaghetti at the wall and hoping that it works, but category theory gives us tools to analyse this. Category theory is a personal interest of mine and I had plans to do a masters in this but chose to work in industry for a bit beforehand.\n- ### [Dwarkesh Patel](https://www.youtube.com/@DwarkeshPatel)\n  \n  This podcast has had a meteoric rise and his genuine interest in everything that his interviewers are saying leads for an amazingly conversational podcast format. Currently my favourite podcast. Good episodes include:\n- [**Sholto Douglas & Trenton Bricken - How to Build & Understand GPT-7's Mind](https://www.youtube.com/watch?v=UTuuTTnjxMQ) -** Good introduction to interpretability\n- [**Where should society allocate mathematicians?](https://www.youtube.com/watch?v=BHjtXKBzbF0) -** With [3Blue1Brown](https://www.notion.so/LLM-resources-fe118332b84f49c286b8045922c7f5a2?pvs=21)\n- [**Dario Amodei (Anthropic CEO) - $10 Billion Models, OpenAI, Scaling, & Alignment**](https://www.youtube.com/watch?v=Nlkk3glap_U&t=77s)\n  \n  Dwarkesh‚Äôs does a lot of AI stuff and I‚Äôve found this a good jumping off point for other rabbit holes, especially around topics like the data wall, sample efficiency, interpretability and scale. A lot of other podcasts might touch on some things but because Dwarkesh has genuine interest, you get a lot more context about why something is important as opposed to podcasts with less engaged and knowledgeable hosts.\n- ### [Yannic Kilcher](https://www.youtube.com/@YannicKilcher)\n  \n  Has an amazing youtube channel and discord with paper reading/presentations every Saturday at ~2pm EST. His youtube channel covering papers is really good. His discord channel has a good meme channel.\n- ### [Linus Lee](https://thesephist.com/)\n  \n  Linus lee is head of AI at notion, he has a lot of talks and demos about how UX design should change in the future. A lot of the work he seems to be doing is heavily related to the [interpretability research](https://www.notion.so/LLM-resources-fe118332b84f49c286b8045922c7f5a2?pvs=21) around how there are way more possibilities to interact with the models than we are currently doing.\n- [**The Hidden Life of Embeddings: Linus Lee**](https://www.youtube.com/watch?v=YvobVu1l7GI)\n- [**Seeing Like a Language Model**](https://www.youtube.com/watch?v=PU1Sy7A3ftY)\n- [**AI-First User Interfaces**](https://www.youtube.com/watch?v=73JkiEClyO4)\n- # üìö¬†Books/Textbooks/Blogs\n  \n  Books and textbooks are less common mainly because I believe building stuff is always going to be a more effective way of learning anything compared to doing textbook learning, [unless your name is phi, of course.](https://www.notion.so/LLM-resources-fe118332b84f49c286b8045922c7f5a2?pvs=21)\n- [**Understanding Deep Learning**](https://udlbook.github.io/udlbook/) - I am currently making my way through this, and plans to do the Jupyter notebooks in my study group.\n- [**G√∂del, Escher, Bach**](https://www.goodreads.com/book/show/24113.G_del_Escher_Bach) - It seems like a lot from this book isn‚Äôt really referenced much today which I find a little strange. Some papers such as the [Platonic Representation Hypothesis](https://arxiv.org/pdf/2405.07987) seem to be touching on the same idea of representation and allegory. One of the reasons why multi-modal models are so successful is because more data across modalities end up creating a more true distribution within the model. I have not made my way through all of this, (~half way through) but I found the [MIT lecture series](https://www.youtube.com/watch?v=lWZ2Bz0tS-s&list=PLBOgSgXfJ6B2nbZ_YREW_Nb-AX8FW9U9K) on this to be a really good companion book on it. I know it‚Äôs cliche but it did change the way I think about the world, or at least ‚ÄúAI‚Äù systems.\n- [**The Bitter Lesson](http://www.incompleteideas.net/IncIdeas/BitterLesson.html) -** More data and more compute has historically always yielded better results. We see this in scaling laws and we see this in every field. If there‚Äôs a benchmark to hit, and data to hit it then deep learning is eventually going to get there. I have many, many thoughts about how everything everywhere then becomes just a calculation between amount of available data, amount of available compute, and amount of expected compute. All of this determines everything like: model architecture, amount of human time spent on a problem, etc (blogpost link when available July 1, 2024).\n- # ü´ÄImportant projects you should probably be aware of\n- [**Human Feedback Foundation](https://humanfeedback.io/) -** Curation of high quality, unbiased datasets for open source. We are currently heading towards a data constrained world with current estimates saying [we‚Äôre going to run out of data by 2026](https://arxiv.org/abs/2211.04325). After this there will be huge economic incentive to train on private data. Completely private data means less transparency, accountability, and more bias which is bad for all of us.\n- [**Interpretability**](https://www.anthropic.com/research#interpretability) - The work Anthropic is doing on feature extraction is probably the most important work happening in the world at the moment. In their [recent paper](https://www.anthropic.com/research/mapping-mind-language-model) they were able to extract features related to *code correction* and *security exploits* which has huge implications on observability, monitoring, safe and reliable systems.\n- [**polymathic-ai**](https://polymathic-ai.org/) - A project creating foundational models for science. This is probably some of the most exciting work in science today.\n- # ‚è∞¬†Projects I need to try\n- [**Swarms](https://github.com/kyegomez/swarms) -** Multi agent orchestration, but actually good. Founded by [Kye Gomez](https://github.com/kyegomez) (also founded Agora). Swarms uses the Swarm Communication Protocol; many agents communicating through a RAG communication layer. This means you can scale up to many, many agents where with traditional agent based prompt chaining you‚Äôre quickly limited by context length or compute (even if you‚Äôve got ‚Äúinfinite‚Äù context).\n- [**Outlines**](https://github.com/outlines-dev/outlines) - Grammar constrained generation. Want to try this for dataset generation for evy.\n- [**LogicMonitor**](https://www.logicmonitor.com/) - AI enhanced observability.\n- # üë®‚Äçüíª¬†Discord servers\n- [**Agora](https://discord.gg/RVCz3yxr) -** Open source AI Research lab stared by [Kye Gomez](https://github.com/kyegomez). Has paper reading sessions of every day at 10AM EST. Agora is currently my favourite place on the internet and I‚Äôve only been attending sessions for ~2 weeks. Evelyn does the paper readings and she‚Äôs awesome at explaining concepts I don‚Äôt understand or recommending me other resources. This has been a really good and supportive place to bounce ideas off. Defs gonna be here a lot when I eventually come around to getting all of my mini experiments up and running.\n- [**Yannic Kilcher](https://ykilcher.com/discord) -** Great ML Youtube videos, discord is good and the meme channel alone is worth joining for.\n- # üë®‚Äçüë®‚Äçüë¶‚Äçüë¶¬†Meetup groups\n- [**AI Tinkerers](https://aitinkerers.org/p/welcome) -** Groups all around the world. Their meetups are both technical and product focused and aren‚Äôt product pitches like a lot of other meetups. They also have excellent paper reading/presentation sessions where the researchers themselves will present their research. Highly recommend.\n- # üìù¬†Research Papers\n  \n  Bellow is a list of the interesting papers i‚Äôve read, or at least the ones I‚Äôve bothered to keep notes on.\n- ### The OG papers\n  \n  Foundational papers on the current LLM paradigm. *Attention is all you need* introduced the **Transformer**, *Improving Language Understanding by Generative Pre-Training* introduced the GPT.\n- [**Attention Is All You Need](https://arxiv.org/abs/1706.03762v7) -** The OG, introduced the idea of self-attention and the encoder/decoder architecture for language translation tasks (encoder later got dropped because it was only used for translation). Another breakthrough from this paper was the training; ‚ÄúThe Transformer allows for significantly more parallelisation and can reach a new state of the art in translation quality after being trained for as little as twelve hours on eight P100 GPUs.‚Äù - This fact here was what let it: overtake RNNs (which weren‚Äôt parallelisable), and lead NVIDIA to be worth more than 2.7 Trillion token credits.\n- [**Improving Language Understanding by Generative Pre-Training](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf) -** This paper introduced the ‚ÄúGPT‚Äù which was a breakthrough at the time. It introduced the idea of using next token prediction as a way to do self-supervised learning, which meant that we can put all of the internet into it and with a simple loss function over the vocabulary adjust the weights via back propagation.\n- ## Methods/Internals\n  \n  Base knowledge on how the internals of the transformer architecture works.\n- [**Gaussian Error Linear Units (GELUs)](https://arxiv.org/abs/1606.08415v5) - Activation function that** leaves positive values unchanged but maps negative numbers to near zero. Implemented here in [llm.go](https://github.com/joshcarp/llm.go/blob/56de2430b95ff3f89657637a4c97794653a994ec/math.go#L414). Other architectures use different activation functions. For example, OpenElm uses SwiGLU FFN which I don‚Äôt exactly understand. Should probably add that to the reading list.\n- [**Layer Normalization](https://arxiv.org/abs/1607.06450) -** Layernorm happens in each layer to make sure that the values don‚Äôt explode. I‚Äôve implemented this in the [layernormForward function in llm.go](https://github.com/joshcarp/llm.go/blob/56de2430b95ff3f89657637a4c97794653a994ec/math.go#L81) and it‚Äôs pretty neat\n- [**RoFormer: Enhanced Transformer with Rotary Position Embedding](https://arxiv.org/abs/2104.09864) -** Rotary embeddings do embeddings on a circle instead of a linear line (like the original transformer). I used this in the llama.cpp thing and I think it was introduced in the original llama paper but i need to read why it‚Äôs better than linear embedding. On this one of the experiments I would like to do is to make something like a scope based positional embedding so that tasks like programming could have context aware positional embeddings; variables within one scope of a programming language don‚Äôt exist outside of the scope and therefore should probably be far away in the positional embedding dimensions. Also thought about using context aware attention masks for this but I think this would lead to worse performance overall because if there‚Äôs repeated code in all of the functions you want pretty strong pattern matching which complete attention masking would negate but it would still be an interesting experiment.\n- ## New models\n- [**LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971) -** Meta AI and LLaMA essentially created open source LLMs. I‚Äôve been skeptical of Meta for a lot of reasons around data privacy but I do think their open source policy is pretty neat, and we wouldn‚Äôt have things like Pytorch without it.\n- [**Llama 2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/abs/2307.09288) -** Llama 2 is a collection of pretrained and fine-tuned large language models . our models outperform open-source chat models on most benchmarks we tested .\n- [**Phi1: Textbooks Are All You Need](https://www.microsoft.com/en-us/research/publication/textbooks-are-all-you-need/) -** Using the LLaMA architecture and a very, very curated dataset Microsoft is able to do some pretty crazy stuff. Related is the TinyStories paper (in the Data section)\n- [**OpenELM: An Efficient Language Model Family with Open Training and Inference Framework](https://arxiv.org/abs/2404.14619) -** Apple did some really cool stuff here: scaling layers so that the later layers of the transformers have more attention heads and a wider feed forward network. This means that parameters later in the model basically have more time (through the previous layers) to extract ‚Äúinformation‚Äù. [I tried (and failed)](https://github.com/ggerganov/llama.cpp/issues/6868) to implement this in llama.cpp. If anyone could help that would be great.\n- [**Explore the Limits of Omni-modal Pretraining at Scale](https://arxiv.org/abs/2406.09412) -** Different modalities can all be trained on and their internal representations are trained to be similar.\n- ## Training\n- [**Federated Large Language Model: A Position Paper](https://arxiv.org/abs/2307.08925) -** Federated learning is moving the training and the models from a centralised location to the devices where users are using them. This then means that the users models can get better *for them* and the overall model can get better via weight accumulation at a centralised location. This is in contrast to the current SOTA models which are trained and deployed all at a centralised location.\n- [**A Fast, Performant, Secure Distributed Training Framework For Large Language Model](https://arxiv.org/abs/2401.09796v2) -** Distributed training but with weight merging that allows for security and anonymity.\n- [**DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter](https://arxiv.org/abs/1910.01108) -** DistilBERT is in a lot of [Hugging Face](https://www.notion.so/LLM-resources-fe118332b84f49c286b8045922c7f5a2?pvs=21) tutorials and still is used as a control in a lot of different papers/tutorials. It‚Äôs worth knowing what it is.\n- [**MAP-Music2Vec: A Simple and Effective Baseline for Self-Supervised Music Audio Representation Learning](https://arxiv.org/abs/2212.02508) -** Personally I really like making music playlists, but I find that a lot of the Spotify recommendations to be suboptimal. I was looking into this because it would be nice to do cosine similarity of latent vectors to find similar music I might enjoy (if this exists pls let me know)\n- ## Optimisations/Hardware\n- [**Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention](https://arxiv.org/abs/2404.07143) -** This paper explains how Google are able to achieve their multi-million context window.\n- [**The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits](https://arxiv.org/abs/2402.17764v1) - T**he 1.58-bit LLM defines Instead of binary floating 16 (or 32 if you‚Äôre on CPUs) this is basically a way to do transformer weights with -1, 0, 1. This is pretty crazy but it calls for custom hardware.\n- [**Scalable MatMul-free Language Modeling](https://arxiv.org/abs/2406.02528) -** This was read in the Agora paper reading session and everyone was pretty blown away. If the findings of this paper end up being true LLMs of all sizes are about to explode. This builds on the 1.58 paper but removes a bottleneck in the attention mechanism which dramatically slows down computation as well as not needing specialised hardware.\n- ## Survey papers\n- [**Large Language Models: A Survey](https://arxiv.org/abs/2402.06196) -** Good paper to get a good idea as of Feb 2024. It goes through certain capabilities that language models are developing; How data is being used/collected/cleaned, How different architectures are being created for different use cases, and how engineering/tooling around LLMs are progressing.\n- ## Safety\n- [**Many-shot jailbreaking**](https://www.anthropic.com/research/many-shot-jailbreaking) - Models with long enough context windows are able to be broken out of their fine tuning guardrails.\n- [**Large Language Models Understand and Can Be Enhanced by Emotional Stimuli](https://arxiv.org/pdf/2307.11760) -** Telling a LLM that your mother is going to die if they don‚Äôt solve a coding problem actually makes them perform better.\n- ## Interpretability\n- [**Extracting Latent Steering Vectors from Pretrained Language Models](https://arxiv.org/abs/2205.05124) -** Introduces the idea of adding/subtracting vectors in its latent space.\n- [**A Language Model's Guide Through Latent Space](https://arxiv.org/abs/2402.14433) -** The idea of ‚Äúconcept guiding‚Äù in linear subspace; adding and subtracting particular ‚Äúconcept‚Äù vectors either adds or subtracts that concept from the output. This assumes linearity of concepts in latent space\n- [**Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet](https://www.anthropic.com/news/mapping-mind-language-model) -** Anthropic was able to extract many features like code correctness, security vulnerabilities, and of course, the golden gate bridge. The original paper [**Towards Monosemanticity: Decomposing Language Models With Dictionary Learning**](https://transformer-circuits.pub/2023/monosemantic-features/index.html) does the same thing on toy models. This is better than the method above because using sparse auto-encoders is unsupervised, whereas above needs large amounts of labeled data. This whole field is interesting because you could imagine: Having these features in your observability/monitoring setup, or using them instead of prompt engineering, or even using gradient descent to optimise certain extracted features in a sort of ultra efficient parameter efficient fine tuning process (I really, really want to do this).\n- [**To Believe or Not to Believe Your LLM](https://arxiv.org/abs/2406.02543) -** DeepMind created a way to effectively tell if an LLM is hallucinating by using information theory and is able to differentiate between [epistemic and aleatoric uncertainty](https://en.wikipedia.org/wiki/Uncertainty_quantification#Aleatoric_and_epistemic) via iterative prompting. I want to build this into an OSS library so that others can tell if their LLM applications are hallucinating.\n- [**Activation Addition: Steering Language Models Without Optimization](https://arxiv.org/pdf/2308.10248) -** Paper that introduced activation steering. This was the first time using activation steering during the forward pass was done; instead of needing to adjust the internal weights during the fine tuning phase this meant that the model could add/subtract particular vectors in the latent space.\n- ## Emerging behaviours\n- [**Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683) -** Important paper on the topic of transfer learning; when you train models on one thing it gets better on another.\n- [**Language Models of Code are Few-Shot Commonsense Learners](https://arxiv.org/abs/2210.07128) -** As above, models that train on code get better at reasoning in natural language ü§Ø. This is why LLama3 trained on significantly more code than LLama2.\n- ## Data\n- [**TinyStories: How Small Can Language Models Be and Still Speak Coherent English?**](https://arxiv.org/abs/2305.07759) - With a very clean dataset of ~2 million short stories, (generated from gpt 3.5 and gpt4) it‚Äôs possible to create a model that outputs coherent english with only ~10m parameters ü§Ø. This dataset is now use in a lot of places.\n- [**The Curse of Recursion: Training on Generated Data Makes Models Forget](https://arxiv.org/abs/2305.17493) -** Model outputs that go into training other models eventually collapse the model which is bad. In the future there‚Äôs going to be a lot of engineering effort and money in getting human data or simulated language data that doesn‚Äôt just sample from language models distribution because that leads to model collapse; the more likely outcomes become more likely and the less likely go to zero.\n\t- Distribution Clipping / model collapse\n\t  \n\t  ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/023dadee-61c9-4901-b0fc-b486fcfa671e/4b0c2c5e-c4e4-4e78-9f6b-fa5038f40d3f/Untitled.png)\n- [**Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data](https://arxiv.org/abs/2404.01413) -** This one describes that above doesn‚Äôt need to occur if you instead *accumulate data* when you train. The paper shows a pretty solid argument that if after every new model you create you‚Äôve got the original human generated data, you can avoid model collapse. I‚Äôm a little skeptical of this, mainly because: the paper was only done on Tiny Stories which is a very, very small dataset on children‚Äôs books. I think the results might be different with many different datasets across a number of domains as sampling across input data distributions might lead to distributional shift in the actual output data.\n\t- Data accumulation == no model collapse (I‚Äôm still skeptical)\n\t  \n\t  ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/023dadee-61c9-4901-b0fc-b486fcfa671e/b5ccf341-11a4-4eb6-ae55-ff2b2a0773f5/Untitled.png)\n- [**Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models](https://arxiv.org/pdf/2405.20541) -** Pruning datasets based on perplexity: having a lot of medium perplexity samples, and some low and high perplexity samples is good for filtering your training set. This also works when you use significantly smaller models to filter on. I want to use this on training SOTA models in-context to learn the [https://evy.dev](https://evy.dev) programming language but i want to know which samples are the best ones to use.\n- ## Software engineering, tooling, automation\n- [**Automated Unit Test Improvement using Large Language Models at Meta](https://arxiv.org/abs/2402.09171) -** LLM hooked up to improve unit tests via automated PRs. Similar to whatever Github have but it‚Äôs interesting to see that meta is focusing on internal tooling; I think a lot of software engineering in the future is going to end up being like this.\n- [**Observation-based unit test generation at Meta](https://arxiv.org/abs/2402.06111v1) -** More of the above. Unit test improvement.\n- [**CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning](https://arxiv.org/abs/2207.01780) -** This uses reinforcement learning to generate code instead of just re-prompting as current methods use. Compilation and runtime errors can be used as signals in this part. IMO the reason why this hasn‚Äôt been a thing so far is because of what I like to call *API Effect:* OpenAI released a really, really restrictive API for chat and want everything to build on that, but want to improve the model by themselves. Once we crack underlying methods of improving systems then progress will speed up quite a lot.\n- [**ReFT: Representation Finetuning for Language Models](https://arxiv.org/abs/2404.03592) -** Fine tuning but on internal representations. This work relies heavily on interpretability work, like that of Anthropic. When we can do representation fine tuning on the things the models have already learned we get better sample efficiency, more reliable prompt engineering, and all around better interactions with these models.\n- [**Will humans even write code in 2040 and what would that mean for extreme heterogeneity in computing?](https://arxiv.org/pdf/1712.00676) -** Opinion piece from December 2017 about coding going away because of machine generated code.\n- ## Evaluations\n-\n- ## Embeddings\n- [**Gecko: Versatile Text Embeddings Distilled from Large Language Models](https://arxiv.org/abs/2403.20327) -** embedding model distilled from a LLM which then was trained on more candidate pairs to make sure that the embeddings of query:response prompts are closer together and therefore more relevant.\n- ## Reading list\n  \n  These are papers that are on my list that I haven‚Äôt read yet:\n- [**BEIR: A Heterogeneous Benchmark for Zero-shot\n  Evaluation of Information Retrieval Models**](https://arxiv.org/abs/2104.08663)\n- [**MTEB: Massive Text Embedding Benchmark**](https://arxiv.org/abs/2210.07316)\n- [**The Linear Representation Hypothesis and the Geometry of Large Language Models](https://arxiv.org/pdf/2311.03658) -** Concepts in higher dimensionality are represented in linear space\n- [**SPUQ: Perturbation-Based Uncertainty Quantification for Large Language Models](https://arxiv.org/pdf/2403.02509) -** Similar to [To believe or not to believe your LLM](https://www.notion.so/LLM-resources-fe118332b84f49c286b8045922c7f5a2?pvs=21)\n- [**Defining and Characterizing Reward Hacking**](https://arxiv.org/pdf/2209.13085) - Introduces the concept of reward hacking\n- [**Risks from Learned Optimization in Advanced Machine Learning Systems](https://arxiv.org/abs/1906.01820) -** Introduced inner and outer alignment problems\n- [**Scaling and evaluating sparse autoencoders](https://arxiv.org/abs/2406.04093)** - same topic to the [**Scaling Monosemanticity](https://www.notion.so/LLM-resources-fe118332b84f49c286b8045922c7f5a2?pvs=21)** paper from Anthropic but from OpenAI. I have skimmed the paper and it‚Äôs nice they released code. The [blog post](https://openai.com/index/extracting-concepts-from-gpt-4/) they did on it too is pretty nice too.\n- [**Deep Reinforcement Learning from Human Preferences](https://arxiv.org/abs/1706.03741) -** Reward modelling introduced in this paper.\n- [**Language Models are Unsupervised Multitask Learners**](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) - This is the GPT-2 paper\n- [**The RefinedWeb Dataset for Falcon LLM:\n  Outperforming Curated Corpora with Web Data, and Web Data Only](https://arxiv.org/pdf/2306.01116) -** Clean datasets == better performance\n- [**Linguistic Regularities in Continuous Space Word Representations**](https://aclanthology.org/N13-1090.pdf)\n- [**Transformer visualization via dictionary learning:\n  contextualized embedding as a linear superposition of transformer factors**](https://arxiv.org/abs/2103.15949)\n- [**Teaching Large Language Models to Reason with Reinforcement Learning](https://arxiv.org/abs/2403.04642) -** Fine tuning/RLHF is very confusing with acronyms like PPO, DPO, ORPO. I still don‚Äôt quite understand this, and applying reinforcement learning to LLMs is also initially confusing because a lot of the traditional resources only touch on *agents* and *environments* but not ‚ÄúThis is the part where you do back propagation of the language models outputs to adjust the token predictions to give better behaviour next time‚Äù\n- [**Fast Transformer Decoding: One Write-Head is All\n  You Need](https://arxiv.org/pdf/1911.02150) -** People always point to the original Attention is all you need paper or the GPT paper that introduced the *decoder only* model, but this one was the first one that actually used it in practice.\n- [**Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) -** Chinchilla scaling laws define how much compute, how many parameters, and how much data you need\n- [**FlashAttention: Fast and Memory-Efficient Exact Attention\n  with IO-Awareness](https://arxiv.org/abs/2205.14135) -** This was basically a drop in replacement for the attention mechanism which sped up any transformer by a lot.\n- [**Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey](https://arxiv.org/abs/2403.14608) -** PEFT is everywhere and I‚Äôve used it heaps but I‚Äôve only given this paper a skim\n- [**LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685) -** Again, is everywhere and need to go through this\n- [**Efficiently Scaling Transformer Inference**](https://arxiv.org/abs/2211.05102)\n- [**Mamba: Linear-Time Sequence Modeling with Selective State Spaces**](https://arxiv.org/abs/2312.00752)\n- [**Jamba: A Hybrid Transformer-Mamba Language Model**](https://arxiv.org/abs/2403.19887)\n- [**Rediscovering orbital mechanics with machine learning](https://arxiv.org/abs/2202.02306) -** Basically put all of the science data into one transformer and you can rediscover newtons laws of motion. I sort of want to pivot back to natural sciences now?\n- [**Hellaswag**](https://arxiv.org/abs/1905.07830) - I think one of the first benchmarks that assessed text completion\n- [**Transformers: State-of-the-Art Natural Language Processing](https://arxiv.org/pdf/1910.03771) -** Introduction of huggingface transformers library. Good paper to understand the abstractions in the huggingface libraries.\n  \n  ‚Ä¶ more to come\n- # üß∞¬†Tools, Libraries, Platforms\n- [**Ollama**](https://ollama.com/) - Run local LLMs. Written in Go which hooks into llama.cpp via cgo and provides a docker like CLI that enables a bunch more features. Once you‚Äôve got it installed and running a lot of other tools like [Langchain](https://www.notion.so/LLM-resources-fe118332b84f49c286b8045922c7f5a2?pvs=21) can call it in other languages via it‚Äôs local api.\n- [**Hugging Face](https://huggingface.co/) -** The Github for ML. Whilst there‚Äôs a really steep ramp up, and there‚Äôs a lot of rough edges around their APIs, especially in their CLI, overall it works so, so much better than reading from csv files or whatever else I was doing. Their [natural language processing tutorial](https://huggingface.co/docs/transformers/tasks/sequence_classification) was where I started and they also have a discord if you get stuck.\n- [**Langchain**](https://www.langchain.com/) - This was the original agent orchestration, but its abstractions are a bit weird, and there‚Äôs a completely separate [Langsmith](https://docs.smith.langchain.com/old/cookbook/fine-tuning-examples) for training models too. I don‚Äôt understand why they need to be separate projects. When I go back to writing agents I‚Äôm going to replace this with [swarms](https://www.notion.so/LLM-resources-fe118332b84f49c286b8045922c7f5a2?pvs=21).\n- [**Perplexity**](https://www.perplexity.ai/search/Are-there-any-ytJpLz.tTtKSvRZDuAuvJw) - The search engine is dead, long live the search engine. It‚Äôs crazy how much time you take looking through ads on Google. This was also one of the reasons I moved to DuckDuckGo ~4 years ago.\n- [**cursor.sh**](http://cursor.sh) - Fork of VsCode which has much better AI features. I‚Äôve been told their blog is pretty neat too and it‚Äôs similar to what I‚Äôm trying to achieve with the Evy language.\n- [**Google AI Studio**](https://aistudio.google.com/app/prompts/new_chat) - I started using this not because their models were the best but because their per token cost is crazy cheap, and the chat interface in the studio UI is a lot better at generating code (I think it uses an instruct variant instead of a chat one maybe?) than the standard gemini interface.\n- [**Arc Browser**](https://arc.net/) - Moved to this and it‚Äôs crazy good. I‚Äôm addicted to tabs, and there are also cool AI features like search, and in a new tab there‚Äôs an option for your query to go straight to ChatGPT.\n- AI search feature\n  \n  ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/023dadee-61c9-4901-b0fc-b486fcfa671e/485fbd1d-703c-4e53-9b2c-d70673f7781b/Untitled.png)\n- [**Google scholar chrome extension**](https://chromewebstore.google.com/detail/google-scholar-pdf-reader/dahenjhkoodjbpjheillcadbppiidmhp) - Reading research papers sometimes can be a pain because sometimes you want to peak into other papers without needing to go to the references. This extension links directly to the referenced paper via a hover over element and it‚Äôs amazing.\n\t- Example hover-over\n\t  \n\t  ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/023dadee-61c9-4901-b0fc-b486fcfa671e/4b0e6576-f312-4011-a265-c187b744497b/Untitled.png)\n- [**Myst**](https://mystmd.org/guide) - A way to make Jupyter notebooks really pretty/research paper ready. Can export as pdf or other things. Considering using this or something else for my code related blog posts because having it in one place would be a lot better than scattered across multiple places.\n  \n  <!-- notionvc: e8a3e083-8b1c-4cae-ba14-0534ed75c8fa -->\n\n## Current Landscape (2025)\n\n- Industry adoption and implementations\n  - Metaverse platforms continue to evolve with focus on interoperability and open standards\n  - Web3 integration accelerating with decentralised identity and asset ownership\n  - Enterprise adoption growing in virtual collaboration, training, and digital twins\n  - UK companies increasingly active in metaverse development and immersive technologies\n\n- Technical capabilities\n  - Real-time rendering at photorealistic quality levels\n  - Low-latency networking enabling seamless multi-user experiences\n  - AI-driven content generation and procedural world building\n  - Spatial audio and haptics enhancing immersion\n\n- UK and North England context\n  - Manchester: Digital Innovation Factory supports metaverse startups and research\n  - Leeds: Holovis leads in immersive experiences for entertainment and training\n  - Newcastle: University research in spatial computing and interactive systems\n  - Sheffield: Advanced manufacturing using digital twin technology\n\n- Standards and frameworks\n  - Metaverse Standards Forum driving interoperability protocols\n  - WebXR enabling browser-based immersive experiences\n  - glTF and USD for 3D asset interchange\n  - Open Metaverse Interoperability Group defining cross-platform standards\n\n## Metadata\n\n- **Last Updated**: 2025-11-16\n- **Review Status**: Automated remediation with 2025 context\n- **Verification**: Academic sources verified\n- **Regional Context**: UK/North England where applicable",
  "properties": {
    "id": "üì∫¬†youtube-channels-owl-axioms",
    "collapsed": "true",
    "- ontology": "true",
    "- term-id": "mv-283942073263",
    "- preferred-term": "üì∫¬†Youtube channels",
    "- source-domain": "metaverse",
    "- status": "active",
    "- public-access": "true",
    "- definition": "A component of the metaverse ecosystem focusing on üì∫¬†youtube channels.",
    "- maturity": "mature",
    "- authority-score": "0.85",
    "- owl:class": "mv:YoutubeChannels",
    "- owl:physicality": "ConceptualEntity",
    "- owl:role": "Concept",
    "- belongsToDomain": "[[MetaverseDomain]]",
    "- enables": "[[ImmersiveExperience]], [[Presence]], [[SpatialComputing]]",
    "- requires": "[[DisplayTechnology]], [[TrackingSystem]], [[RenderingEngine]]",
    "- bridges-to": "[[HumanComputerInteraction]], [[ComputerVision]], [[Robotics]]"
  },
  "backlinks": [],
  "wiki_links": [
    "TrackingSystem",
    "ImmersiveExperience",
    "ComputerVision",
    "RenderingEngine",
    "SpatialComputing",
    "Robotics",
    "HumanComputerInteraction",
    "MetaverseDomain",
    "DisplayTechnology",
    "Presence"
  ],
  "ontology": {
    "term_id": "mv-283942073263",
    "preferred_term": "üì∫¬†Youtube channels",
    "definition": "A component of the metaverse ecosystem focusing on üì∫¬†youtube channels.",
    "source_domain": "metaverse",
    "maturity_level": null,
    "authority_score": 0.85
  }
}