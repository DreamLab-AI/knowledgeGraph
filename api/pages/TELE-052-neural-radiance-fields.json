{
  "title": "Neural Radiance Fields",
  "content": "# Neural Radiance Fields\n\n- ### OntologyBlock\n  id:: nerf-ontology\n  collapsed:: true\n  - ontology:: true\n  - term-id:: TELE-052\n  - preferred-term:: Neural Radiance Fields\n  - alternate-terms::\n  - NeRF\n  - Neural Volumetric Rendering\n  - Implicit Neural Representation\n  - source-domain:: tele\n  - status:: active\n  - public-access:: true\n  - definition:: \"A neural rendering technique representing 3D scenes as continuous volumetric functions encoded by multilayer perceptrons, mapping 5D coordinates (3D position + 2D viewing direction) to colour and density, enabling photorealistic novel view synthesis from sparse input photographs through volumetric ray marching and gradient-based optimisation.\"\n  - maturity:: developing\n  - authority-score:: 0.89\n  - owl:class:: tele:NeuralRadianceFields\n  - owl:physicality:: ConceptualEntity\n  - owl:role:: Process\n  - belongsToDomain::\n  - [[TELE-0000-telepresence-domain]]\n  - [[NeuralRenderingTelepresence]]\n  - bridges-to::\n  - [[AIDomain]]\n\n\n## Definition\n\n**Neural Radiance Fields** (NeRF), introduced by Mildenhall et al. (ECCV 2020), revolutionised 3D scene reconstruction by representing scenes as continuous neural functions rather than discrete meshes or voxels. A NeRF encodes a scene's geometry and appearance in the weights of a multilayer perceptron (MLP) that, given a 3D position (x, y, z) and viewing direction (θ, φ), outputs colour (RGB) and volume density (σ). Novel viewpoints are rendered by marching rays through the volume, sampling the neural function, and integrating colour/density via volumetric rendering equations, producing photorealistic images without explicit 3D geometry.\n\n## Current Landscape (2025)\n\nNeRF has spawned 1,000+ research papers and commercial applications in telepresence [[TELE-053-volumetric-video-conferencing]], virtual production, and VR [[TELE-020-virtual-reality-telepresence]].\n\n**Technology Capabilities (2025)**:\n- **Training Time**: 30 minutes for room-scale scenes (Instant-NGP [[TELE-060-instant-ngp]])\n- **Rendering Speed**: 30 FPS real-time variants (Mobile-NeRF, TensoRF)\n- **Quality**: 32-36 dB PSNR (exceeding mesh-based methods)\n\n## Comparison to Gaussian Splatting\n\nNeRF slower but more memory-efficient than [[TELE-051-3d-gaussian-splatting]]. Gaussian splatting now preferred for real-time telepresence.\n\n## Related Concepts\n\n- [[TELE-050-neural-rendering-telepresence]]\n- [[TELE-051-3d-gaussian-splatting]]\n- [[TELE-053-volumetric-video-conferencing]]\n\n## Academic References\n\n1. Mildenhall, B., et al. (2020). \"NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis\". *ECCV 2020*.\n\n## Metadata\n\n- **Term-ID**: TELE-052\n- **Last Updated**: 2025-11-16\n- **Maturity**: Developing\n- **Authority Score**: 0.89",
  "properties": {},
  "backlinks": [
    "TELE-051-3d-gaussian-splatting",
    "TELE-100-ai-avatars"
  ],
  "wiki_links": [
    "TELE-020-virtual-reality-telepresence",
    "AIDomain",
    "TELE-0000-telepresence-domain",
    "TELE-060-instant-ngp",
    "TELE-050-neural-rendering-telepresence",
    "TELE-051-3d-gaussian-splatting",
    "NeuralRenderingTelepresence",
    "TELE-053-volumetric-video-conferencing"
  ],
  "ontology": {
    "term_id": "TELE-052",
    "preferred_term": "Neural Radiance Fields",
    "definition": "\"A neural rendering technique representing 3D scenes as continuous volumetric functions encoded by multilayer perceptrons, mapping 5D coordinates (3D position + 2D viewing direction) to colour and density, enabling photorealistic novel view synthesis from sparse input photographs through volumetric ray marching and gradient-based optimisation.\"",
    "source_domain": "tele",
    "maturity_level": null,
    "authority_score": 0.89
  }
}