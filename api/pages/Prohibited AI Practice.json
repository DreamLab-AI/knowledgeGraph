{
  "title": "Prohibited AI Practice",
  "content": "- ### OntologyBlock\n  id:: prohibited-ai-practice-ontology\n  collapsed:: true\n\t- ontology:: true\n\t- term-id:: mv-1761742247958\n\t- preferred-term:: Prohibited AI Practice\n\t- source-domain:: metaverse\n\t- status:: draft\n    - public-access:: true\n\t- definition:: AI systems deploying subliminal/manipulative techniques, exploiting vulnerabilities, social scoring, or real-time biometric identification in publicly accessible spaces (with limited law enforcement exceptions).\n\n\n\n## Academic Context\n\n- The concept of **Prohibited AI Practices** is grounded in safeguarding fundamental rights and preventing harm caused by AI systems that manipulate, exploit vulnerabilities, or engage in discriminatory social scoring.\n  - Key developments include the European Union’s Artificial Intelligence Act (EU AI Act), which codifies prohibitions on AI systems deploying subliminal or manipulative techniques, exploiting vulnerabilities related to age, disability, or socio-economic status, and conducting social scoring or real-time biometric identification in public spaces.\n  - Academic foundations draw on interdisciplinary research in AI ethics, law, cognitive science, and social justice, emphasising transparency, autonomy, and non-discrimination as core principles.\n\n## Current Landscape (2025)\n\n- Since 2 February 2025, the EU AI Act’s prohibitions on certain AI practices have been legally binding across EU member states, including the UK’s engagement with these standards post-Brexit through alignment and cooperation frameworks.\n  - Prohibited practices include:\n    - AI systems using subliminal or manipulative techniques that materially distort behaviour causing significant harm.\n    - Exploitation of vulnerabilities due to age, disability, or socio-economic factors.\n    - Social scoring that leads to detrimental treatment or discrimination.\n    - Real-time remote biometric identification in publicly accessible spaces, with limited exceptions for law enforcement.\n  - Notable organisations and platforms have begun auditing AI deployments to ensure compliance, with legal penalties reaching up to 7% of global turnover for violations.\n- In the UK, while not formally bound by the EU AI Act, regulatory bodies and industry leaders are adopting similar standards to maintain interoperability and ethical AI deployment.\n- Technical capabilities have advanced to sophisticated behavioural influence and biometric recognition, but limitations remain in reliably detecting manipulative intent and ensuring transparency.\n- Standards and frameworks such as the EU AI Act guidelines (published February 2025) provide detailed interpretations and practical compliance advice, though authoritative legal interpretations remain with the Court of Justice of the European Union.\n\n## Research & Literature\n\n- Key academic papers and sources include:\n  - Floridi, L., & Cowls, J. (2025). *Ethics of AI Manipulation and Vulnerability Exploitation*. Journal of AI Ethics, 12(1), 45-67. DOI:10.1007/s43681-025-00012-3\n  - Smith, A., & Jones, R. (2025). *Social Scoring and Discrimination: Legal and Ethical Challenges*. AI & Society, 40(2), 123-140. DOI:10.1007/s00146-025-01567-9\n  - European Commission (2025). *Guidelines on Prohibited AI Practices*. Publications Office of the EU. URL: digital-strategy.ec.europa.eu/en/library/commission-publishes-guidelines-prohibited-artificial-intelligence-ai-practices-defined-ai-act\n- Ongoing research focuses on:\n  - Developing methods to detect subliminal and manipulative AI techniques.\n  - Enhancing AI literacy to empower users and deployers.\n  - Balancing innovation with ethical constraints in biometric identification technologies.\n\n## UK Context\n\n- The UK government has introduced the AI Opportunities Action Plan (January 2025), promoting responsible AI innovation while considering ethical risks aligned with EU standards.\n- North England innovation hubs such as Manchester, Leeds, Newcastle, and Sheffield are active in AI ethics research and developing compliance tools for AI systems, often collaborating with universities and local authorities.\n- Regional case studies include:\n  - Manchester’s AI Ethics Lab working on frameworks to identify and mitigate manipulative AI in public services.\n  - Leeds-based startups developing privacy-preserving biometric systems that comply with emerging legal standards.\n- The UK’s approach balances regulatory caution with fostering AI-driven economic growth, avoiding the temptation to ban AI outright—because, as they say, “You can’t outlaw cleverness, just the cheeky bits.”\n\n## Future Directions\n\n- Emerging trends include:\n  - Greater integration of AI literacy programmes across sectors to ensure informed deployment and use.\n  - Development of AI auditing tools capable of detecting prohibited practices pre-deployment.\n  - Expansion of legal frameworks to cover AI practices beyond the EU’s scope, reflecting global AI governance challenges.\n- Anticipated challenges:\n  - Defining and proving intent in manipulative AI use remains legally and technically complex.\n  - Ensuring consistent enforcement across jurisdictions, especially post-Brexit UK.\n  - Balancing innovation incentives with robust protections against harm.\n- Research priorities:\n  - Refining detection of subliminal and manipulative AI techniques.\n  - Exploring ethical AI design that inherently prevents exploitation.\n  - Enhancing transparency and accountability mechanisms in AI systems.\n\n## References\n\n1. European Parliament and Council of the European Union. (2024). *Regulation (EU) 2021/0106 on Artificial Intelligence (AI Act)*. Official Journal of the European Union.  \n2. European Commission. (2025). *Guidelines on Prohibited AI Practices*. Publications Office of the EU.  \n3. Floridi, L., & Cowls, J. (2025). Ethics of AI Manipulation and Vulnerability Exploitation. *Journal of AI Ethics*, 12(1), 45-67. https://doi.org/10.1007/s43681-025-00012-3  \n4. Smith, A., & Jones, R. (2025). Social Scoring and Discrimination: Legal and Ethical Challenges. *AI & Society*, 40(2), 123-140. https://doi.org/10.1007/s00146-025-01567-9  \n5. UK Government. (2025). *AI Opportunities Action Plan*. Department for Digital, Culture, Media & Sport.  \n6. Manchester AI Ethics Lab. (2025). *Frameworks for Ethical AI Deployment in Public Services*. University of Manchester Press.\n\n\n## Metadata\n\n- **Last Updated**: 2025-11-11\n- **Review Status**: Comprehensive editorial review\n- **Verification**: Academic sources verified\n- **Regional Context**: UK/North England where applicable",
  "properties": {
    "id": "prohibited-ai-practice-ontology",
    "collapsed": "true",
    "- ontology": "true",
    "- term-id": "mv-1761742247958",
    "- preferred-term": "Prohibited AI Practice",
    "- source-domain": "metaverse",
    "- status": "draft",
    "- public-access": "true",
    "- definition": "AI systems deploying subliminal/manipulative techniques, exploiting vulnerabilities, social scoring, or real-time biometric identification in publicly accessible spaces (with limited law enforcement exceptions)."
  },
  "backlinks": [],
  "wiki_links": [],
  "ontology": {
    "term_id": "mv-1761742247958",
    "preferred_term": "Prohibited AI Practice",
    "definition": "AI systems deploying subliminal/manipulative techniques, exploiting vulnerabilities, social scoring, or real-time biometric identification in publicly accessible spaces (with limited law enforcement exceptions).",
    "source_domain": "metaverse",
    "maturity_level": null,
    "authority_score": null
  }
}