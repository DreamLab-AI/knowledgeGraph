{
  "title": "Light Node",
  "content": "- ### OntologyBlock\n  id:: light-node-ontology\n  collapsed:: true\n\n  - **Identification**\n    - public-access:: true\n    - ontology:: true\n    - term-id:: BC-0074\n    - preferred-term:: Light Node\n    - source-domain:: blockchain\n    - status:: complete\n    - version:: 1.0.0\n    - last-updated:: 2025-10-28\n\n  - **Definition**\n    - definition:: Partial blockchain data node within blockchain systems, providing essential functionality for distributed ledger technology operations and properties.\n    - maturity:: mature\n    - source:: [[ISO/IEC 23257:2021]], [[IEEE 2418.1]], [[NIST NISTIR]]\n    - authority-score:: 0.95\n\n  - **Semantic Classification**\n    - owl:class:: bc:LightNode\n    - owl:physicality:: VirtualEntity\n    - owl:role:: Object\n    - owl:inferred-class:: bc:VirtualObject\n    - belongsToDomain:: [[CryptographicDomain]]\n    - implementedInLayer:: [[SecurityLayer]]\n\n  - #### Relationships\n    id:: light-node-relationships\n    - is-subclass-of:: [[Blockchain Entity]], [[NetworkComponent]]\n\n  - #### OWL Axioms\n    id:: light-node-owl-axioms\n    collapsed:: true\n    - ```clojure\n      Prefix(:=<http://metaverse-ontology.org/blockchain#>)\nPrefix(owl:=<http://www.w3.org/2002/07/owl#>)\nPrefix(rdf:=<http://www.w3.org/1999/02/22-rdf-syntax-ns#>)\nPrefix(xml:=<http://www.w3.org/XML/1998/namespace>)\nPrefix(xsd:=<http://www.w3.org/2001/XMLSchema#>)\nPrefix(rdfs:=<http://www.w3.org/2000/01/rdf-schema#>)\nPrefix(dct:=<http://purl.org/dc/terms/>)\n\nOntology(<http://metaverse-ontology.org/blockchain/BC-0074>\n  Import(<http://metaverse-ontology.org/blockchain/core>)\n\n  ## Class Declaration\n  Declaration(Class(:LightNode))\n\n  ## Subclass Relationships\n  SubClassOf(:LightNode :NetworkComponent)\n  SubClassOf(:LightNode :BlockchainEntity)\n\n  ## Essential Properties\n  SubClassOf(:LightNode\n    (ObjectSomeValuesFrom :partOf :Blockchain))\n\n  SubClassOf(:LightNode\n    (ObjectSomeValuesFrom :hasProperty :Property))\n\n  ## Data Properties\n  DataPropertyAssertion(:hasIdentifier :LightNode \"BC-0074\"^^xsd:string)\n  DataPropertyAssertion(:hasAuthorityScore :LightNode \"1.0\"^^xsd:decimal)\n  DataPropertyAssertion(:isFoundational :LightNode \"true\"^^xsd:boolean)\n\n  ## Object Properties\n  ObjectPropertyAssertion(:enablesFeature :LightNode :BlockchainFeature)\n  ObjectPropertyAssertion(:relatesTo :LightNode :RelatedConcept)\n\n  ## Annotations\n  AnnotationAssertion(rdfs:label :LightNode \"Light Node\"@en)\n  AnnotationAssertion(rdfs:comment :LightNode\n    \"Partial blockchain data node\"@en)\n  AnnotationAssertion(dct:description :LightNode\n    \"Foundational blockchain concept with formal ontological definition\"@en)\n  AnnotationAssertion(:termID :LightNode \"BC-0074\")\n  AnnotationAssertion(:priority :LightNode \"1\"^^xsd:integer)\n  AnnotationAssertion(:category :LightNode \"network-security\"@en)\n)\n      ```\n\n- ## About Light Node\n  id:: light-node-about\n\n  - Partial blockchain data node within blockchain systems, providing essential functionality for distributed ledger technology operations and properties.\n  -\n  - ### Key Characteristics\n    id:: light-node-characteristics\n    - 1. **Definitional Property**: Core defining characteristic\n    - 2. **Functional Property**: Operational behavior\n    - 3. **Structural Property**: Compositional elements\n    - 4. **Security Property**: Security guarantees provided\n    - 5. **Performance Property**: Efficiency considerations\n  -\n  - ### Technical Components\n    id:: light-node-components\n    - **Implementation**: How concept is realized technically\n    - **Verification**: Methods for validating correctness\n    - **Interaction**: Relationships with other components\n    - **Constraints**: Technical limitations and requirements\n  -\n  - ### Use Cases\n    id:: light-node-use-cases\n    - **1. Core Blockchain Operation**\n    - **Application**: Fundamental blockchain functionality\n    - **Example**: Practical implementation in major blockchains\n    - **Requirements**: Technical prerequisites\n    - **Benefits**: Value provided to blockchain systems\n  -\n  - ### Standards & References\n    id:: light-node-standards\n    - [[ISO/IEC 23257:2021]] - Blockchain and distributed ledger technologies\n    - [[IEEE 2418.1]] - Blockchain and distributed ledger technologies\n    - [[NIST NISTIR]] - Blockchain and distributed ledger technologies\n  -\n\n\t- ### Lightning\n\t\t- It is possible to log into a website using only Lighting, as in [StackerNews](https://stacker.news/login?callbackUrl=https://stacker.news/).\n\n\t- ##### Background\n\t\t- Ubiquitous display technology, which allows different personalized views\n\t\t  for multiple people on the same screen, has the potential to disrupt the\n\t\t  way visitors interact and experience venues and exhibits. The displays\n\t\t  can use techniques like lenticular lenses, or other steerable light, to\n\t\t  send different light to viewers’ eyes, allowing for discrete, customized\n\t\t  views.\n\npublic:: true\n\n- [[Global lighting | Image Based Lighting]] [[ComfyUI]] [lllyasviel/IC-Light: More relighting! (github.com)](https://github.com/lllyasviel/IC-Light)\n- Relighting [Relight Better than Magnific - Relighting v5 (better UX) | ComfyUI Workflow (openart.ai)](https://openart.ai/workflows/risunobushi/relight-better-than-magnific---relighting-v5-better-ux/nSqO2P2ZmDQGwohEbgl3)\n\t- [Magnific AI Relight is Worse than Open Source - YouTube](https://www.youtube.com/watch?v=GsJaqesboTo) [[relighting]]\n- https://zju3dv.github.io/IntrinsicAnything/ relighting model\n- [[Apple]] [facial relighting](https://machinelearning.apple.com/research/neural-3d-relightable)\n- [Apple facial relighting](https://machinelearning.apple.com/research/neural-3d-relightable)\n- Relighting [[AI Video]] [[2402.18848] SwitchLight: Co-design of Physics-driven Architecture and Pre-training Framework for Human Portrait Relighting (arxiv.org)](https://arxiv.org/abs/2402.18848)\n\t- [Beeble AI Lighting for Filmmakers](https://www.beeble.ai/)\n- Relighting [Relight Better than Magnific - Relighting v5 (better UX) | ComfyUI Workflow (openart.ai)](https://openart.ai/workflows/risunobushi/relight-better-than-magnific---relighting-v5-better-ux/nSqO2P2ZmDQGwohEbgl3)\n\t- [Magnific AI Relight is Worse than Open Source - YouTube](https://www.youtube.com/watch?v=GsJaqesboTo) [[relighting]]\n-\n\n\t- ### Lightning\n\t\t- It is possible to log into a website using only Lighting, as in [StackerNews](https://stacker.news/login?callbackUrl=https://stacker.news/).\n\n\t- ##### Background\n\t\t- Ubiquitous display technology, which allows different personalized views\n\t\t  for multiple people on the same screen, has the potential to disrupt the\n\t\t  way visitors interact and experience venues and exhibits. The displays\n\t\t  can use techniques like lenticular lenses, or other steerable light, to\n\t\t- Parallax barriers: These displays have a layer of opaque and transparent slits over the LCD matrix that directs different pixel columns to each eye, creating a stereoscopic 3D image without glasses. Alioscopy is known to use this approach, along with eye tracking technology. They have been in business for decades and are a good case study, but engaging with a research partner in China is likely the best medium terms approach.\n\t\t- These display consists of a large lenticular lens sheet or array of smaller tiled lenticular lenses mounted in front of a high-resolution LED. The lenticular lenses are cylindrical and arranged vertically, with each lens covering multiple pixel columns of the display.\n\t\t- Behind the lens array, the display content is formatted into vertical interleaved channels, with each channel containing a slightly different perspective view of the 3D stereoscopic image. The different perspective views are calculated in real-time based on the tracked head positions of multiple viewers in front of the display.\n\t\t- As light from the display pixels passes through the cylindrical lenses, it is refracted into multiple viewing zones in front of the screen. Each viewing zone contains a specific view channel, so each eye of each viewer sees the perspective that matches their position. This creates a glasses-free 3D effect with motion parallax as viewers move their heads.\n\t\t- The viewer head tracking system uses camera and computer vision techniques to determine the 3D positions of each viewer’s eyes in the space in front of the display. The changing viewer positions are fed to the display rendering system to compute the proper perspective views and adjust the lenticular flaps as needed.\n\t\t- This lenticular 3D display with dynamic view steering provides illusion of depth for multiple viewers simultaneously, creating an immersive large-screen 3D experience without the need for special glasses. The real-time tracking and rendering system updates the content smoothly as the viewers move around, maintaining the stereo 3D perspectives tailored individually to each viewer’s changing position.\n\t- Starting with a small-scale proof of concept for up to 5 people would allow for demonstration of the capabilities and building stakeholder confidence. This would also provide valuable insights into the technical and logistical challenges that may arise during larger-scale implementation.\n\n\t- ### Lightning\n\t\t- It is possible to log into a website using only Lighting, as in [StackerNews](https://stacker.news/login?callbackUrl=https://stacker.news/).\n\n\t- ### Lightning\n\t\t- Web5.\n\n\t- ### Lightning\n\t\t- Web5.\n\n- ## NeRFs\n\t- **Early Foundations of NeRF:**\n\t\t- **Early Photography and Photosculpture (ca 1850):** Pioneers in photography began experimenting with aerial photogrammetry and photosculptures, creating 3D representations from multiple 2D photographs, laying groundwork for future 3D capture technologies.\n\t\t\t- [More on early photography](https://hackaday.com/2022/10/02/in-a-way-3d-scanning-is-over-a-century-old/)\n\t- **Plenoptic Function and Light Fields (1908 & 1936):**\n\t\t- Gabriel Lippmann introduces the concept of the **plenoptic function** which evolves into the **light field** concept, simplifying the capture and representation of light as it travels through space.\n\t- **Advances in Computing and Graphics (1960-1980s):**\n\t\t- The development of lasers, holograms, and computer graphics sets the stage for more advanced 3D representations and the capture of light fields.\n\t- **Lightfield Camera Arrays and Image-Based Rendering (2000):**\n\t\t- The introduction of lightfield camera arrays and image-based rendering techniques brings light fields into practical use, although it remains complex and niche.\n\t\t\t- [Stanford light field camera array 2004](http://graphics.stanford.edu/projects/lightfield/)\n\t- **Generative AI and Inverse Rendering Birth of NeRF (2020):**\n\t\t- **Neural Radiance Fields (NeRF):** A breakthrough in 2020 with the introduction of NeRF, offering an efficient way to recreate 3D scenes from 2D images using neural networks.\n\t\t\t- [First NeRF paper, 2020](https://www.matthewtancik.com/nerf)\n\t- **Realtime NeRF and Commercial Applications (2022):**\n\t\t- **NVIDIA's Instant-NGP:** Accelerates NeRF processing, enabling real-time rendering on consumer-grade hardware and facilitating wider adoption and practical applications in various fields.\n\t\t\t- [NVIDIA instant-ngp 2022](https://github.com/NVlabs/instant-ngp)\n\t- **The Future of NeRF:**\n\t\t- The continuous development of NeRF is expected to integrate more seamlessly with web browsers, game engines, and potentially transform large-scale mapping, video conferencing, and real-time interactive applications.\n\t\t\t- [Google's Project Starline](https://blog.google/technology/research/project-starline-expands-testing/)\n- <iframe src=\"https://mohamad-shahbazi.github.io/inserf/\" style=\"width: 100%; height: 600px\"></iframe>\n- **Links and Image Sources:**\n\t- [SceneScript: Reconstructing Scenes With An Autoregressive Structured Language Model | Research AI at Meta](https://ai.meta.com/research/publications/scenescript-reconstructing-scenes-with-an-autoregressive-structured-language-model/)\n\t\t- ![Screenshot 2024-03-22 192251.png](assets/Screenshot_2024-03-22_192251_1711135500802_0.png)\n\t- [RealityCapture 3D Models from Photos and/or Laser Scans (capturingreality.com)](https://www.capturingreality.com/)  **FREE**\n\t- [A Short 170 Year History Of Neural Radiance Fields (NeRF), Holograms, And Light Fields](radiancefields.com/history-of-neural-radiance-fields/)\n\t- [ProNeRF: Learning Efficient Projection-Aware Ray Sampling for Fine-Grained Implicit Neural Radiance Fields (kaist-viclab.github.io)](https://kaist-viclab.github.io/pronerf-site/)\n\t- [Zip-NeRF: Anti-Aliased Grid-Based Neural Radiance Fields](https://jonbarron.info/zipnerf)\n\t- [Home](https://github.com/3a1b2c3/seeingSpace/wiki/Hands-on:-Getting-started-and-Nerf-frameworks)\n\t- [InseRF: Text-Driven Generative Object Insertion in Neural 3D Scenes (mohamad-shahbazi.github.io)](https://mohamad-shahbazi.github.io/inserf/)\n\t- [NeRFLiX: Increased NeRF Quality And Floater Removal | Neural Radiance Fields](https://neuralradiancefields.io/nerflix-increased-nerf-quality-and-floater-removal)\n\t- [A Short 170 Year History Of Neural Radiance Fields (NeRF), Holograms, And Light Fields | Neural Radiance Fields](https://neuralradiancefields.io/history-of-neural-radiance-fields)\n\t- [Home | MMLab@NTU](https://www.mmlab-ntu.com/project/vtoonify)\n\t- [RecolorNeRF](https://sites.google.com/view/recolornerf)\n\t- [Rob Sloan on LinkedIn: #nerfstudio #nerfstudio #polycam #nerf #nerfacto #polycam #neuralnetworks… | 11 comments](https://www.linkedin.com/posts/robcsloan_nerfstudio-nerfstudio-polycam-activity-6999169160379297792-SN4F)\n\t- [MoyGcc/vid2avatar: Vid2Avatar: 3D Avatar Reconstruction from Videos in the Wild via Self-supervised Scene Decomposition (CVPR2023)](https://github.com/MoyGcc/vid2avatar)\n\t- [HumanNeRF: Free-viewpoint Rendering of Moving People from Monocular Video](https://grail.cs.washington.edu/projects/humannerf)\n\t- [Axie Infinity: Infinite Opportunity or Infinite Peril?](https://naavik.co/business-breakdowns/axie-infinity)\n\t- [NVlabs/instant-ngp](https://github.com/NVlabs/instant-ngp)\n\t- [SpecNeRF (limacv.github.io)](https://limacv.github.io/SpecNeRF_web/)\n\t- [UniSDF (fangjinhuawang.github.io)](https://fangjinhuawang.github.io/UniSDF/)\n\t- [SIGNeRF (jdihlmann.com)](https://signerf.jdihlmann.com/) fast nerf scene editing\n\t- [GARField: Group Anything with Radiance Fields](https://www.garfield.studio/)\n\t- [Byplay](https://www.byplay.io/) is camera motion tracking for mobile\n\t-\n- The neural radiance field Wikipedia is very good [Neural radiance field Wikipedia](https://en.wikipedia.org/wiki/Neural_radiance_field)\n\n- #### Lightning\n- It is possible to log into a website using only Lighting, as in [StackerNews](https://stacker.news/login?callbackUrl=https://stacker.news/).\n\n- ## NeRFs\n\t- **Early Foundations of NeRF:**\n\t\t- **Early Photography and Photosculpture (ca 1850):** Pioneers in photography began experimenting with aerial photogrammetry and photosculptures, creating 3D representations from multiple 2D photographs, laying groundwork for future 3D capture technologies.\n\t\t\t- [More on early photography](https://hackaday.com/2022/10/02/in-a-way-3d-scanning-is-over-a-century-old/)\n\t- **Plenoptic Function and Light Fields (1908 & 1936):**\n\t\t- Gabriel Lippmann introduces the concept of the **plenoptic function** which evolves into the **light field** concept, simplifying the capture and representation of light as it travels through space.\n\t- **Advances in Computing and Graphics (1960-1980s):**\n\t\t- The development of lasers, holograms, and computer graphics sets the stage for more advanced 3D representations and the capture of light fields.\n\t- **Lightfield Camera Arrays and Image-Based Rendering (2000):**\n\t\t- The introduction of lightfield camera arrays and image-based rendering techniques brings light fields into practical use, although it remains complex and niche.\n\t\t\t- [Stanford light field camera array 2004](http://graphics.stanford.edu/projects/lightfield/)\n\t- **Generative AI and Inverse Rendering Birth of NeRF (2020):**\n\t\t- **Neural Radiance Fields (NeRF):** A breakthrough in 2020 with the introduction of NeRF, offering an efficient way to recreate 3D scenes from 2D images using neural networks.\n\t\t\t- [First NeRF paper, 2020](https://www.matthewtancik.com/nerf)\n\t- **Realtime NeRF and Commercial Applications (2022):**\n\t\t- **NVIDIA's Instant-NGP:** Accelerates NeRF processing, enabling real-time rendering on consumer-grade hardware and facilitating wider adoption and practical applications in various fields.\n\t\t\t- [NVIDIA instant-ngp 2022](https://github.com/NVlabs/instant-ngp)\n\t- **The Future of NeRF:**\n\t\t- The continuous development of NeRF is expected to integrate more seamlessly with web browsers, game engines, and potentially transform large-scale mapping, video conferencing, and real-time interactive applications.\n\t\t\t- [Google's Project Starline](https://blog.google/technology/research/project-starline-expands-testing/)\n- <iframe src=\"https://mohamad-shahbazi.github.io/inserf/\" style=\"width: 100%; height: 600px\"></iframe>\n- **Links and Image Sources:**\n\t- [SceneScript: Reconstructing Scenes With An Autoregressive Structured Language Model | Research AI at Meta](https://ai.meta.com/research/publications/scenescript-reconstructing-scenes-with-an-autoregressive-structured-language-model/)\n\t\t- ![Screenshot 2024-03-22 192251.png](assets/Screenshot_2024-03-22_192251_1711135500802_0.png)\n\t- [RealityCapture 3D Models from Photos and/or Laser Scans (capturingreality.com)](https://www.capturingreality.com/)  **FREE**\n\t- [A Short 170 Year History Of Neural Radiance Fields (NeRF), Holograms, And Light Fields](radiancefields.com/history-of-neural-radiance-fields/)\n\t- [ProNeRF: Learning Efficient Projection-Aware Ray Sampling for Fine-Grained Implicit Neural Radiance Fields (kaist-viclab.github.io)](https://kaist-viclab.github.io/pronerf-site/)\n\t- [Zip-NeRF: Anti-Aliased Grid-Based Neural Radiance Fields](https://jonbarron.info/zipnerf)\n\t- [Home](https://github.com/3a1b2c3/seeingSpace/wiki/Hands-on:-Getting-started-and-Nerf-frameworks)\n\t- [InseRF: Text-Driven Generative Object Insertion in Neural 3D Scenes (mohamad-shahbazi.github.io)](https://mohamad-shahbazi.github.io/inserf/)\n\t- [NeRFLiX: Increased NeRF Quality And Floater Removal | Neural Radiance Fields](https://neuralradiancefields.io/nerflix-increased-nerf-quality-and-floater-removal)\n\t- [A Short 170 Year History Of Neural Radiance Fields (NeRF), Holograms, And Light Fields | Neural Radiance Fields](https://neuralradiancefields.io/history-of-neural-radiance-fields)\n\t- [Home | MMLab@NTU](https://www.mmlab-ntu.com/project/vtoonify)\n\t- [RecolorNeRF](https://sites.google.com/view/recolornerf)\n\t- [Rob Sloan on LinkedIn: #nerfstudio #nerfstudio #polycam #nerf #nerfacto #polycam #neuralnetworks… | 11 comments](https://www.linkedin.com/posts/robcsloan_nerfstudio-nerfstudio-polycam-activity-6999169160379297792-SN4F)\n\t- [MoyGcc/vid2avatar: Vid2Avatar: 3D Avatar Reconstruction from Videos in the Wild via Self-supervised Scene Decomposition (CVPR2023)](https://github.com/MoyGcc/vid2avatar)\n\t- [HumanNeRF: Free-viewpoint Rendering of Moving People from Monocular Video](https://grail.cs.washington.edu/projects/humannerf)\n\t- [Axie Infinity: Infinite Opportunity or Infinite Peril?](https://naavik.co/business-breakdowns/axie-infinity)\n\t- [NVlabs/instant-ngp](https://github.com/NVlabs/instant-ngp)\n\t- [SpecNeRF (limacv.github.io)](https://limacv.github.io/SpecNeRF_web/)\n\t- [UniSDF (fangjinhuawang.github.io)](https://fangjinhuawang.github.io/UniSDF/)\n\t- [SIGNeRF (jdihlmann.com)](https://signerf.jdihlmann.com/) fast nerf scene editing\n\t- [GARField: Group Anything with Radiance Fields](https://www.garfield.studio/)\n\t- [Byplay](https://www.byplay.io/) is camera motion tracking for mobile\n\t-\n- The neural radiance field Wikipedia is very good [Neural radiance field Wikipedia](https://en.wikipedia.org/wiki/Neural_radiance_field)\n\n- #### Lightning\n- It is possible to log into a website using only Lighting, as in [StackerNews](https://stacker.news/login?callbackUrl=https://stacker.news/).\n\n\n## Current Landscape (2025)\n\n- Industry adoption and implementations\n  - Metaverse platforms continue to evolve with focus on interoperability and open standards\n  - Web3 integration accelerating with decentralised identity and asset ownership\n  - Enterprise adoption growing in virtual collaboration, training, and digital twins\n  - UK companies increasingly active in metaverse development and immersive technologies\n\n- Technical capabilities\n  - Real-time rendering at photorealistic quality levels\n  - Low-latency networking enabling seamless multi-user experiences\n  - AI-driven content generation and procedural world building\n  - Spatial audio and haptics enhancing immersion\n\n- UK and North England context\n  - Manchester: Digital Innovation Factory supports metaverse startups and research\n  - Leeds: Holovis leads in immersive experiences for entertainment and training\n  - Newcastle: University research in spatial computing and interactive systems\n  - Sheffield: Advanced manufacturing using digital twin technology\n\n- Standards and frameworks\n  - Metaverse Standards Forum driving interoperability protocols\n  - WebXR enabling browser-based immersive experiences\n  - glTF and USD for 3D asset interchange\n  - Open Metaverse Interoperability Group defining cross-platform standards\n\n## Metadata\n\n- **Last Updated**: 2025-11-16\n- **Review Status**: Automated remediation with 2025 context\n- **Verification**: Academic sources verified\n- **Regional Context**: UK/North England where applicable",
  "properties": {
    "id": "light-node-standards",
    "collapsed": "true",
    "- public-access": "true",
    "- ontology": "true",
    "- term-id": "BC-0074",
    "- preferred-term": "Light Node",
    "- source-domain": "blockchain",
    "- status": "complete",
    "- version": "1.0.0",
    "- last-updated": "2025-10-28",
    "- definition": "Partial blockchain data node within blockchain systems, providing essential functionality for distributed ledger technology operations and properties.",
    "- maturity": "mature",
    "- source": "[[ISO/IEC 23257:2021]], [[IEEE 2418.1]], [[NIST NISTIR]]",
    "- authority-score": "0.95",
    "- owl:class": "bc:LightNode",
    "- owl:physicality": "VirtualEntity",
    "- owl:role": "Object",
    "- owl:inferred-class": "bc:VirtualObject",
    "- belongsToDomain": "[[CryptographicDomain]]",
    "- implementedInLayer": "[[SecurityLayer]]",
    "- is-subclass-of": "[[Blockchain Entity]], [[NetworkComponent]]",
    "public": "true"
  },
  "backlinks": [],
  "wiki_links": [
    "AI Video",
    "relighting",
    "SecurityLayer",
    "NIST NISTIR",
    "Blockchain Entity",
    "CryptographicDomain",
    "ComfyUI",
    "Global lighting | Image Based Lighting",
    "ISO/IEC 23257:2021",
    "IEEE 2418.1",
    "Apple",
    "NetworkComponent"
  ],
  "ontology": {
    "term_id": "BC-0074",
    "preferred_term": "Light Node",
    "definition": "Partial blockchain data node within blockchain systems, providing essential functionality for distributed ledger technology operations and properties.",
    "source_domain": "blockchain",
    "maturity_level": null,
    "authority_score": 0.95
  }
}